{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from google.colab import drive\n",
        "from array import array\n",
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "drive.mount('/content/gdrive') # 此處需要登入google帳號\n",
        "data = pd.read_csv(\"/content/gdrive/My Drive/thesis/thesisdataset/millan_average13_629_final.csv\")#讀取資料集1\n",
        "data.shape"
      ],
      "metadata": {
        "id": "y8NQr-L000Ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = pd.read_csv(\"/content/gdrive/My Drive/thesis/thesisdataset/taiwan_average37_83_final.csv\")#讀取資料集2\n",
        "data2.shape"
      ],
      "metadata": {
        "id": "-msGeIqs085_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data3 = pd.read_csv(\"/content/gdrive/My Drive/thesis/thesisdataset/finland_average_47_786_final.csv\")#讀取資料集3\n",
        "data3.shape"
      ],
      "metadata": {
        "id": "vNQ040hn1Ax4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install learn2learn"
      ],
      "metadata": {
        "id": "lQ4tUf2B1Cie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "zjqQWWC-1ENM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-G6HNxymideM"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data)\n",
        "dataset = df.internet.values.astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.DataFrame(data2)\n",
        "dataset2 = df2.load.values.astype(float)"
      ],
      "metadata": {
        "id": "WPcIcdUE93iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = pd.DataFrame(data3)\n",
        "dataset4 = df4.Internet.values.astype(float)"
      ],
      "metadata": {
        "id": "Xh1gYsAgurPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1000=np.append(dataset2, dataset4)"
      ],
      "metadata": {
        "id": "awZUErp59-4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1000=np.append(dataset1000, dataset) #聚合三個資料集"
      ],
      "metadata": {
        "id": "7dTSCuIyvHNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataset1000.shape"
      ],
      "metadata": {
        "id": "1lzgwS7m1GB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSVIgZjf48pD"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataset1000=dataset1000.reshape(-1,1)#reshape以利放入模型"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1000.shape"
      ],
      "metadata": {
        "id": "xGAmdk6p1Hm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e44j-Ux74Mgp"
      },
      "outputs": [],
      "source": [
        "#訓練集測試集產生\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "def sliding_windows(data, seq_length):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-seq_length):\n",
        "        _x = data[i:(i+seq_length)]\n",
        "        _y = data[i+seq_length]\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return np.array(x),np.array(y)\n",
        "\n",
        "sc = MinMaxScaler()\n",
        "dataset1000 = sc.fit_transform(dataset1000)\n",
        "\n",
        "seq_length = 1\n",
        "x, y = sliding_windows(dataset1000, seq_length)\n",
        "train_size = 1516090\n",
        "#test_size = 898761\n",
        "#train_size = int(len(y) * 0.6)\n",
        "test_size = len(y) - train_size\n",
        "\n",
        "dataX = Variable(torch.Tensor(np.array(x)))\n",
        "dataY = Variable(torch.Tensor(np.array(y)))\n",
        "\n",
        "trainX = Variable(torch.Tensor(np.array(x[0:train_size])))\n",
        "trainY = Variable(torch.Tensor(np.array(y[0:train_size])))\n",
        "\n",
        "testX = Variable(torch.Tensor(np.array(x[train_size:len(x)])))\n",
        "testY = Variable(torch.Tensor(np.array(y[train_size:len(y)])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReG82s-misSg"
      },
      "outputs": [],
      "source": [
        "print(trainX.shape)\n",
        "print(trainY.shape)\n",
        "print(testX.shape)\n",
        "print(testY.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w3uLq63YkRgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ht0iAK_He-X"
      },
      "outputs": [],
      "source": [
        "#形成元窗格\n",
        "trainX=trainX.reshape(10,151609,1,1)\n",
        "trainY=trainY.reshape(10,151609,1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainX.shape)\n",
        "print(trainY.shape)\n",
        "print(testX.shape)\n",
        "print(testY.shape)"
      ],
      "metadata": {
        "id": "N3zkq6LR2njg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tFSGRaqX2UBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXz37vSL5m9E"
      },
      "outputs": [],
      "source": [
        "#LSTM宣告\n",
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "        super(LSTM, self).__init__()\n",
        "        \n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.seq_length = seq_length\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                            num_layers=num_layers, batch_first=True)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_0 = Variable(torch.zeros(\n",
        "            self.num_layers, x.size(0), self.hidden_size))\n",
        "        \n",
        "        c_0 = Variable(torch.zeros(\n",
        "            self.num_layers, x.size(0), self.hidden_size))\n",
        "        \n",
        "        # Propagate input through LSTM\n",
        "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
        "        \n",
        "        h_out = h_out.view(-1, self.hidden_size)\n",
        "        \n",
        "        out = self.fc(h_out)\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "torch.manual_seed(0)\n",
        "\n",
        "seed=0\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# Remove randomness (may be slower on Tesla GPUs) \n",
        "# https://pytorch.org/docs/stable/notes/randomness.html\n",
        "if seed ==0 :\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NT8P7vhjGfWc",
        "outputId": "b7b83e7d-a10f-4d0f-eb68-17fe4f32f504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fe29eb9f270>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#訓練過程\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import learn2learn as l2l\n",
        "epochs = 1000\n",
        "learning_rate = 0.01\n",
        "input_size = 1\n",
        "hidden_size = 2\n",
        "num_layers = 1\n",
        "num_classes = 1\n",
        "meta_learning_rate = 0.01\n",
        "adaptation_steps = 1\n",
        "encoder = LSTM(num_classes, input_size, hidden_size, num_layers)\n",
        "output_layer = nn.Linear(1, 1)\n",
        "maml = l2l.algorithms.MAML(output_layer, lr=learning_rate, first_order=False)\n",
        "opt = optim.Adam(list(maml.parameters()) + list(encoder.parameters()), lr=meta_learning_rate)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "for iteration in range(epochs):\n",
        "    opt.zero_grad()\n",
        "    iteration_error = 0.0\n",
        "    for task in range(9):\n",
        "        learner = maml.clone()\n",
        "        x_spt = trainX[task]\n",
        "        y_spt = trainY[task]\n",
        "        x_qry = trainX[task+1]\n",
        "        y_qry = trainY[task+1]\n",
        "        # Fast adapt\n",
        "        for _ in range(adaptation_steps):\n",
        "            pred = learner(encoder(x_spt))\n",
        "            error = loss_fn(pred, y_spt)\n",
        "            learner.adapt(error)\n",
        "            print(\"Epoch: %d, Task: %d, loss: %1.5f\" % (iteration, task, error.item()))\n",
        "\n",
        "        pred = learner(encoder(x_qry))\n",
        "        evaluation_error = loss_fn(pred, y_qry)\n",
        "        print(evaluation_error)\n",
        "        iteration_error += evaluation_error\n",
        "    # Meta-update the model parameters\n",
        "    iteration_error /= 10\n",
        "    print(iteration_error)\n",
        "    iteration_error.backward()   \n",
        "    opt.step()\n"
      ],
      "metadata": {
        "id": "ouWWaAxv2sd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testXall=testX.reshape(-1,1,1)\n",
        "testYall=testY.reshape(-1,1)"
      ],
      "metadata": {
        "id": "ro8WbpwbD0AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#結果測試\n",
        "learner.eval()\n",
        "test_predict = learner(encoder(testXall))\n",
        "test_predict = test_predict.data.numpy()\n",
        "testY_plot = testYall.data.numpy()\n",
        "#data_predict=data_predict.reshape(1, -1)\n",
        "test_predict = sc.inverse_transform(test_predict)\n",
        "testY_plot = sc.inverse_transform(testY_plot)\n",
        "\n",
        "#plt.axvline(x=train_size, c='r', linestyle='--')\n",
        "\n",
        "\n",
        "plt.plot(testY_plot,color='blue',label='True Value')\n",
        "plt.plot(test_predict,color='red',label='Predicted Value')\n",
        "plt.suptitle('MAML-LSTM Internet Traffic Prediction')\n",
        "plt.show()\n",
        "import math\n",
        "testScore = math.sqrt(mean_squared_error(testY_plot, test_predict))\n",
        "print('Train Score: %.2f RMSE' % (testScore))\n",
        "#testScore = math.sqrt(mean_squared_error(testY, test_predict))\n",
        "#print('Test Score: %.2f RMSE' % (testScore))\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "\n",
        "print(\"mean_absolute_error:\",mean_absolute_error(testY_plot, test_predict))\n",
        "\n",
        "print(\"mean_squared_error:\",mean_squared_error(testY_plot,test_predict))\n",
        "\n",
        "print(\"rmse:\",sqrt(mean_squared_error(testY_plot, test_predict)))\n",
        "\n",
        "print(\"r2 score:\",r2_score(testY_plot, test_predict))\n",
        "print(\"mape_sk\", mean_absolute_percentage_error(testY_plot, test_predict))"
      ],
      "metadata": {
        "id": "bhtR_dV-3RkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#儲存模型\n",
        "import joblib\n",
        "joblib.dump(learner,\"/content/gdrive/My Drive/re_thesis/re_thesis_test/model_test_2/lstmlearner.pkl\")\n",
        "joblib.dump(encoder,\"/content/gdrive/My Drive/re_thesis/re_thesis_test/model_test_2/lstmencoder.pkl\")"
      ],
      "metadata": {
        "id": "YgV3RwQpTPKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc38758-077b-4ccc-ad9c-4a8e8b5ebec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/My Drive/re_thesis/re_thesis_test/model_test_2/lstmencoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PkvJyQHybZ70"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "MAML-LSTM＿re_thesis",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

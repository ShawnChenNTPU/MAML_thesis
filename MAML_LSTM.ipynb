{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijZFtBJPgqkU",
        "outputId": "1e8685e0-712c-4fa3-c6c8-794ff71fe05c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1679994, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from google.colab import drive\n",
        "from array import array\n",
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "drive.mount('/content/gdrive') # 此處需要登入google帳號\n",
        "data = pd.read_csv(\"/content/gdrive/My Drive/thesis/thesisdataset/millan_average7_396.csv\")\n",
        "#data = pd.read_csv(\"1101-1107sorted4.csv\")\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nwdaf_data = pd.read_csv(\"/content/gdrive/My Drive/thesis/thesisdataset/germany_average3_41.csv\")\n",
        "nwdaf_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc712H5z9pJl",
        "outputId": "f06abde1-1a85-41dc-a009-d626be690f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1296000, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uk_data = pd.read_csv(\"/content/gdrive/My Drive/thesis/thesisdataset/uk_data_average5_69_v1.csv\")\n",
        "uk_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOkFzVj6tC6T",
        "outputId": "5fd18b78-ae2a-4a3e-a5b5-fbd87a7cd1cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19888, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0pC7hRsvSBuM",
        "outputId": "a159b678-504c-4ac9-9eea-f25b208ade85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting learn2learn\n",
            "  Downloading learn2learn-0.1.7.tar.gz (841 kB)\n",
            "\u001b[K     |████████████████████████████████| 841 kB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from learn2learn) (1.21.5)\n",
            "Requirement already satisfied: gym>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from learn2learn) (0.17.3)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from learn2learn) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from learn2learn) (0.11.1+cu111)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from learn2learn) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from learn2learn) (2.23.0)\n",
            "Collecting gsutil\n",
            "  Downloading gsutil-5.8.tar.gz (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 52.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from learn2learn) (4.63.0)\n",
            "Collecting qpth>=0.0.15\n",
            "  Downloading qpth-0.0.15.tar.gz (11 kB)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.14.0->learn2learn) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.14.0->learn2learn) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.14.0->learn2learn) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->learn2learn) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3.0->learn2learn) (7.1.2)\n",
            "Collecting argcomplete>=1.9.4\n",
            "  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.7/dist-packages (from gsutil->learn2learn) (1.7)\n",
            "Collecting fasteners>=0.14.1\n",
            "  Downloading fasteners-0.17.3-py3-none-any.whl (18 kB)\n",
            "Collecting gcs-oauth2-boto-plugin>=3.0\n",
            "  Downloading gcs-oauth2-boto-plugin-3.0.tar.gz (20 kB)\n",
            "Collecting google-apitools>=0.5.32\n",
            "  Downloading google_apitools-0.5.32-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 64.2 MB/s \n",
            "\u001b[?25hCollecting httplib2>=0.20.4\n",
            "  Downloading httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting google-reauth>=0.1.0\n",
            "  Downloading google_reauth-0.1.1-py2.py3-none-any.whl (17 kB)\n",
            "Collecting monotonic>=1.4\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting pyOpenSSL>=0.13\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting retry_decorator>=1.0.0\n",
            "  Downloading retry_decorator-1.1.1.tar.gz (3.9 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from gsutil->learn2learn) (1.15.0)\n",
            "Collecting google-auth[aiohttp]>=2.5.0\n",
            "  Downloading google_auth-2.6.2-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 78.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata<5,>=0.23 in /usr/local/lib/python3.7/dist-packages (from argcomplete>=1.9.4->gsutil->learn2learn) (4.11.3)\n",
            "Collecting rsa==4.7.2\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Collecting boto>=2.29.1\n",
            "  Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 68.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil->learn2learn) (4.1.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa==4.7.2->gcs-oauth2-boto-plugin>=3.0->gsutil->learn2learn) (0.4.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (0.2.8)\n",
            "Collecting aiohttp<4.0.0dev,>=3.6.2\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 61.7 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 65.8 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (21.4.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 67.4 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (2.0.12)\n",
            "Collecting pyu2f\n",
            "  Downloading pyu2f-0.1.5.tar.gz (27 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.7/dist-packages (from httplib2>=0.20.4->gsutil->learn2learn) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5,>=0.23->argcomplete>=1.9.4->gsutil->learn2learn) (3.7.0)\n",
            "Collecting cryptography>=35.0\n",
            "  Downloading cryptography-36.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 71.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=35.0->pyOpenSSL>=0.13->gsutil->learn2learn) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=35.0->pyOpenSSL>=0.13->gsutil->learn2learn) (2.21)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->learn2learn) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->learn2learn) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->learn2learn) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->learn2learn) (2.10)\n",
            "Building wheels for collected packages: learn2learn, qpth, gsutil, gcs-oauth2-boto-plugin, retry-decorator, pyu2f\n",
            "  Building wheel for learn2learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for learn2learn: filename=learn2learn-0.1.7-cp37-cp37m-linux_x86_64.whl size=938548 sha256=ae970862e8d0294a52c9fe6f91888ec97b35c3e8519f4b14fd55bdb38f8baaa4\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/29/ac/1d46fdb88fb1fb02491123ef3fcec13d5363eb14fec6f8af05\n",
            "  Building wheel for qpth (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qpth: filename=qpth-0.0.15-py3-none-any.whl size=15379 sha256=68b3b3cef682915f8179a3753ef151585bc5a9c85c6643538c33333f22dcbed7\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/bb/0f/3af358159c8cfc56654d85ba5069b53ab351dee72f5a57c2ff\n",
            "  Building wheel for gsutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gsutil: filename=gsutil-5.8-py3-none-any.whl size=3742629 sha256=273bc1d7a933e51a9e58ccc9a836420d6157fa2b1507bc4a4952055b7104c14f\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/6a/11/148f5c318da3bc44d0b2be91b35e6b94ac8dbd62feb8b99413\n",
            "  Building wheel for gcs-oauth2-boto-plugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gcs-oauth2-boto-plugin: filename=gcs_oauth2_boto_plugin-3.0-py3-none-any.whl size=23221 sha256=0a0b0a82ad22bdda768f2903c26aaaf5d917aa3c1eee87d80afb2d554fd0f144\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/93/86/cb2140365b10150dbdba338da385c7c18c7cbd9e592e3421db\n",
            "  Building wheel for retry-decorator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for retry-decorator: filename=retry_decorator-1.1.1-py2.py3-none-any.whl size=3658 sha256=41ac8d1eb55886aa5317f6e58524bf4906472ec95057833d37f7c566c789574c\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/39/dc/7359c639e34d9c388a1b3e1dc444363905194afc70f57eb9a5\n",
            "  Building wheel for pyu2f (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyu2f: filename=pyu2f-0.1.5-py3-none-any.whl size=39404 sha256=11ada63802b3b776f8b7b827d6ab8e6f0ab56f3e6af6f7aece1b0236955c00fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/84/c6/ee8093bf96e2224aca3a9bfa074aa3c86c39208f91055fd60f\n",
            "Successfully built learn2learn qpth gsutil gcs-oauth2-boto-plugin retry-decorator pyu2f\n",
            "Installing collected packages: multidict, frozenlist, yarl, rsa, pyu2f, httplib2, cryptography, asynctest, async-timeout, aiosignal, retry-decorator, pyOpenSSL, google-reauth, google-auth, fasteners, boto, aiohttp, monotonic, google-apitools, gcs-oauth2-boto-plugin, argcomplete, qpth, gsutil, learn2learn\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.8\n",
            "    Uninstalling rsa-4.8:\n",
            "      Successfully uninstalled rsa-4.8\n",
            "  Attempting uninstall: httplib2\n",
            "    Found existing installation: httplib2 0.17.4\n",
            "    Uninstalling httplib2-0.17.4:\n",
            "      Successfully uninstalled httplib2-0.17.4\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 1.35.0\n",
            "    Uninstalling google-auth-1.35.0:\n",
            "      Successfully uninstalled google-auth-1.35.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-api-core 1.26.3 requires google-auth<2.0dev,>=1.21.1, but you have google-auth 2.6.2 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 argcomplete-2.0.0 async-timeout-4.0.2 asynctest-0.13.0 boto-2.49.0 cryptography-36.0.2 fasteners-0.17.3 frozenlist-1.3.0 gcs-oauth2-boto-plugin-3.0 google-apitools-0.5.32 google-auth-2.6.2 google-reauth-0.1.1 gsutil-5.8 httplib2-0.20.4 learn2learn-0.1.7 monotonic-1.6 multidict-6.0.2 pyOpenSSL-22.0.0 pyu2f-0.1.5 qpth-0.0.15 retry-decorator-1.1.1 rsa-4.7.2 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "httplib2",
                  "rsa"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install learn2learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVenwNg89v4z",
        "outputId": "92b510ea-5e98-4e52-da53-c72a5bca1aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr  2 13:24:30 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-G6HNxymideM"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data)\n",
        "dataset = df.internet.values.astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.DataFrame(nwdaf_data)\n",
        "dataset2 = df2.load.values.astype(float)"
      ],
      "metadata": {
        "id": "WPcIcdUE93iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = pd.DataFrame(uk_data)\n",
        "dataset4 = df4.internet.values.astype(float)"
      ],
      "metadata": {
        "id": "Xh1gYsAgurPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1000=np.append(dataset2, dataset4)"
      ],
      "metadata": {
        "id": "awZUErp59-4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1000=np.append(dataset1000, dataset)"
      ],
      "metadata": {
        "id": "7dTSCuIyvHNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0Y18hDI4npC",
        "outputId": "373b1a63-1486-41ee-f07f-02ecc6d9f95c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2995882,)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\n",
        "dataset1000.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSVIgZjf48pD"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataset1000=dataset1000.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPsSWiFF5J4d",
        "outputId": "ec72b2d8-d576-469d-bc8e-708f2449c9b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2995882, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "dataset1000.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2995890*0.66"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8brVSCqjLfc",
        "outputId": "db75f2b4-c2ed-4194-855c-485511d3d324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1977287.4000000001"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2995890-1977290"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLlcW9TZjQpI",
        "outputId": "73f3d03e-5d8e-49f9-8d4b-bbaec3b12db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1018600"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e44j-Ux74Mgp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "def sliding_windows(data, seq_length):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-seq_length):\n",
        "        _x = data[i:(i+seq_length)]\n",
        "        _y = data[i+seq_length]\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return np.array(x),np.array(y)\n",
        "\n",
        "sc = MinMaxScaler()\n",
        "dataset1000 = sc.fit_transform(dataset1000)\n",
        "\n",
        "seq_length = 1\n",
        "\n",
        "dataset1000 = sc.fit_transform(dataset1000)\n",
        "x, y = sliding_windows(dataset1000, seq_length)\n",
        "\n",
        "train_size = 2097120\n",
        "test_size = 898761\n",
        "#train_size = 1200000\n",
        "#test_size = 480000\n",
        "#train_size = 2000000\n",
        "#test_size = 976000\n",
        "#train_size = 1977290\n",
        "#test_size = 1018600\n",
        "dataX = Variable(torch.Tensor(np.array(x)))\n",
        "dataY= Variable(torch.Tensor(np.array(y)))\n",
        "\n",
        "trainX = Variable(torch.Tensor(np.array(x[0:train_size])))\n",
        "trainY = Variable(torch.Tensor(np.array(y[0:train_size])))\n",
        "\n",
        "testX = Variable(torch.Tensor(np.array(x[train_size:len(x)])))\n",
        "testY = Variable(torch.Tensor(np.array(y[train_size:len(y)])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReG82s-misSg"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc-fr6DNF_yq",
        "outputId": "3f5fabb0-2a86-4224-b9dc-639d51b62cd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2097120, 1, 1])\n",
            "torch.Size([2097120, 1])\n",
            "torch.Size([898761, 1, 1])\n",
            "torch.Size([898761, 1])\n"
          ]
        }
      ],
      "source": [
        "print(trainX.shape)\n",
        "print(trainY.shape)\n",
        "print(testX.shape)\n",
        "print(testY.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indexes = [898760]\n",
        "testX=np.delete(testX, indexes)\n",
        "testY=np.delete(testY, indexes)"
      ],
      "metadata": {
        "id": "VvKzj5y2jFgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(testX.shape)\n",
        "print(testY.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxWjEGlFkMx-",
        "outputId": "00689727-40dd-4e5f-b829-3a800624b427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([898760])\n",
            "torch.Size([898760])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w3uLq63YkRgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ht0iAK_He-X"
      },
      "outputs": [],
      "source": [
        "trainX=trainX.reshape(10,209712,1,1)\n",
        "trainY=trainY.reshape(10,209712,1)\n",
        "testX=testX.reshape(10,89876,1,1)\n",
        "testY=testY.reshape(10,89876,1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainX.shape)\n",
        "print(trainY.shape)\n",
        "print(testX.shape)\n",
        "print(testY.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lguz9WKQkbL2",
        "outputId": "125b22be-f798-4651-9f6d-21f1937dc7c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 209712, 1, 1])\n",
            "torch.Size([10, 209712, 1])\n",
            "torch.Size([10, 89876, 1, 1])\n",
            "torch.Size([10, 89876, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXz37vSL5m9E"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "        super(LSTM, self).__init__()\n",
        "        \n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.seq_length = seq_length\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                            num_layers=num_layers, batch_first=True)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_0 = Variable(torch.zeros(\n",
        "            self.num_layers, x.size(0), self.hidden_size))\n",
        "        \n",
        "        c_0 = Variable(torch.zeros(\n",
        "            self.num_layers, x.size(0), self.hidden_size))\n",
        "        \n",
        "        # Propagate input through LSTM\n",
        "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
        "        \n",
        "        h_out = h_out.view(-1, self.hidden_size)\n",
        "        \n",
        "        out = self.fc(h_out)\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0gJxk1Ov-eP",
        "outputId": "49ead7be-93f4-489b-bb98-b53c92600514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m串流輸出內容已截斷至最後 5000 行。\u001b[0m\n",
            "Epoch: 1736, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1655e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1737, Task: 0, loss: 0.00009\n",
            "tensor(9.4849e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1737, Task: 1, loss: 0.00009\n",
            "tensor(9.4483e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1737, Task: 2, loss: 0.00009\n",
            "tensor(9.4660e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1737, Task: 3, loss: 0.00009\n",
            "tensor(9.4591e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1737, Task: 4, loss: 0.00009\n",
            "tensor(9.4893e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1737, Task: 5, loss: 0.00009\n",
            "tensor(2.1277e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1737, Task: 6, loss: 0.00002\n",
            "tensor(7.2012e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1737, Task: 7, loss: 0.00001\n",
            "tensor(6.9593e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1737, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1648e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1738, Task: 0, loss: 0.00009\n",
            "tensor(9.4845e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1738, Task: 1, loss: 0.00009\n",
            "tensor(9.4479e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1738, Task: 2, loss: 0.00009\n",
            "tensor(9.4656e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1738, Task: 3, loss: 0.00009\n",
            "tensor(9.4587e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1738, Task: 4, loss: 0.00009\n",
            "tensor(9.4889e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1738, Task: 5, loss: 0.00009\n",
            "tensor(2.1277e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1738, Task: 6, loss: 0.00002\n",
            "tensor(7.2021e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1738, Task: 7, loss: 0.00001\n",
            "tensor(6.9605e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1738, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1641e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1739, Task: 0, loss: 0.00009\n",
            "tensor(9.4842e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1739, Task: 1, loss: 0.00009\n",
            "tensor(9.4475e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1739, Task: 2, loss: 0.00009\n",
            "tensor(9.4652e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1739, Task: 3, loss: 0.00009\n",
            "tensor(9.4583e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1739, Task: 4, loss: 0.00009\n",
            "tensor(9.4886e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1739, Task: 5, loss: 0.00009\n",
            "tensor(2.1277e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1739, Task: 6, loss: 0.00002\n",
            "tensor(7.2029e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1739, Task: 7, loss: 0.00001\n",
            "tensor(6.9616e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1739, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1634e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1740, Task: 0, loss: 0.00009\n",
            "tensor(9.4838e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1740, Task: 1, loss: 0.00009\n",
            "tensor(9.4472e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1740, Task: 2, loss: 0.00009\n",
            "tensor(9.4649e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1740, Task: 3, loss: 0.00009\n",
            "tensor(9.4580e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1740, Task: 4, loss: 0.00009\n",
            "tensor(9.4882e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1740, Task: 5, loss: 0.00009\n",
            "tensor(2.1278e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1740, Task: 6, loss: 0.00002\n",
            "tensor(7.2037e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1740, Task: 7, loss: 0.00001\n",
            "tensor(6.9628e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1740, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1627e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1741, Task: 0, loss: 0.00009\n",
            "tensor(9.4834e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1741, Task: 1, loss: 0.00009\n",
            "tensor(9.4468e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1741, Task: 2, loss: 0.00009\n",
            "tensor(9.4645e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1741, Task: 3, loss: 0.00009\n",
            "tensor(9.4576e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1741, Task: 4, loss: 0.00009\n",
            "tensor(9.4878e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1741, Task: 5, loss: 0.00009\n",
            "tensor(2.1278e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1741, Task: 6, loss: 0.00002\n",
            "tensor(7.2046e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1741, Task: 7, loss: 0.00001\n",
            "tensor(6.9639e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1741, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1620e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1742, Task: 0, loss: 0.00009\n",
            "tensor(9.4831e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1742, Task: 1, loss: 0.00009\n",
            "tensor(9.4464e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1742, Task: 2, loss: 0.00009\n",
            "tensor(9.4641e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1742, Task: 3, loss: 0.00009\n",
            "tensor(9.4572e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1742, Task: 4, loss: 0.00009\n",
            "tensor(9.4874e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1742, Task: 5, loss: 0.00009\n",
            "tensor(2.1278e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1742, Task: 6, loss: 0.00002\n",
            "tensor(7.2055e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1742, Task: 7, loss: 0.00001\n",
            "tensor(6.9651e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1742, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1613e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1743, Task: 0, loss: 0.00009\n",
            "tensor(9.4827e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1743, Task: 1, loss: 0.00009\n",
            "tensor(9.4460e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1743, Task: 2, loss: 0.00009\n",
            "tensor(9.4637e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1743, Task: 3, loss: 0.00009\n",
            "tensor(9.4568e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1743, Task: 4, loss: 0.00009\n",
            "tensor(9.4871e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1743, Task: 5, loss: 0.00009\n",
            "tensor(2.1278e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1743, Task: 6, loss: 0.00002\n",
            "tensor(7.2065e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1743, Task: 7, loss: 0.00001\n",
            "tensor(6.9663e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1743, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1606e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1744, Task: 0, loss: 0.00009\n",
            "tensor(9.4823e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1744, Task: 1, loss: 0.00009\n",
            "tensor(9.4457e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1744, Task: 2, loss: 0.00009\n",
            "tensor(9.4634e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1744, Task: 3, loss: 0.00009\n",
            "tensor(9.4564e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1744, Task: 4, loss: 0.00009\n",
            "tensor(9.4867e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1744, Task: 5, loss: 0.00009\n",
            "tensor(2.1278e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1744, Task: 6, loss: 0.00002\n",
            "tensor(7.2075e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1744, Task: 7, loss: 0.00001\n",
            "tensor(6.9675e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1744, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1599e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1745, Task: 0, loss: 0.00009\n",
            "tensor(9.4819e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1745, Task: 1, loss: 0.00009\n",
            "tensor(9.4453e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1745, Task: 2, loss: 0.00009\n",
            "tensor(9.4630e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1745, Task: 3, loss: 0.00009\n",
            "tensor(9.4561e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1745, Task: 4, loss: 0.00009\n",
            "tensor(9.4863e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1745, Task: 5, loss: 0.00009\n",
            "tensor(2.1279e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1745, Task: 6, loss: 0.00002\n",
            "tensor(7.2084e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1745, Task: 7, loss: 0.00001\n",
            "tensor(6.9687e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1745, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1592e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1746, Task: 0, loss: 0.00009\n",
            "tensor(9.4815e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1746, Task: 1, loss: 0.00009\n",
            "tensor(9.4449e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1746, Task: 2, loss: 0.00009\n",
            "tensor(9.4626e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1746, Task: 3, loss: 0.00009\n",
            "tensor(9.4557e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1746, Task: 4, loss: 0.00009\n",
            "tensor(9.4859e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1746, Task: 5, loss: 0.00009\n",
            "tensor(2.1279e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1746, Task: 6, loss: 0.00002\n",
            "tensor(7.2093e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1746, Task: 7, loss: 0.00001\n",
            "tensor(6.9699e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1746, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1585e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1747, Task: 0, loss: 0.00009\n",
            "tensor(9.4811e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1747, Task: 1, loss: 0.00009\n",
            "tensor(9.4445e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1747, Task: 2, loss: 0.00009\n",
            "tensor(9.4622e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1747, Task: 3, loss: 0.00009\n",
            "tensor(9.4553e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1747, Task: 4, loss: 0.00009\n",
            "tensor(9.4855e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1747, Task: 5, loss: 0.00009\n",
            "tensor(2.1279e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1747, Task: 6, loss: 0.00002\n",
            "tensor(7.2103e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1747, Task: 7, loss: 0.00001\n",
            "tensor(6.9712e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1747, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1578e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1748, Task: 0, loss: 0.00009\n",
            "tensor(9.4807e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1748, Task: 1, loss: 0.00009\n",
            "tensor(9.4441e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1748, Task: 2, loss: 0.00009\n",
            "tensor(9.4618e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1748, Task: 3, loss: 0.00009\n",
            "tensor(9.4549e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1748, Task: 4, loss: 0.00009\n",
            "tensor(9.4851e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1748, Task: 5, loss: 0.00009\n",
            "tensor(2.1279e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1748, Task: 6, loss: 0.00002\n",
            "tensor(7.2113e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1748, Task: 7, loss: 0.00001\n",
            "tensor(6.9724e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1748, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1571e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1749, Task: 0, loss: 0.00009\n",
            "tensor(9.4803e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1749, Task: 1, loss: 0.00009\n",
            "tensor(9.4437e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1749, Task: 2, loss: 0.00009\n",
            "tensor(9.4614e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1749, Task: 3, loss: 0.00009\n",
            "tensor(9.4545e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1749, Task: 4, loss: 0.00009\n",
            "tensor(9.4847e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1749, Task: 5, loss: 0.00009\n",
            "tensor(2.1279e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1749, Task: 6, loss: 0.00002\n",
            "tensor(7.2122e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1749, Task: 7, loss: 0.00001\n",
            "tensor(6.9737e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1749, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1564e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1750, Task: 0, loss: 0.00009\n",
            "tensor(9.4799e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1750, Task: 1, loss: 0.00009\n",
            "tensor(9.4433e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1750, Task: 2, loss: 0.00009\n",
            "tensor(9.4610e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1750, Task: 3, loss: 0.00009\n",
            "tensor(9.4541e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1750, Task: 4, loss: 0.00009\n",
            "tensor(9.4843e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1750, Task: 5, loss: 0.00009\n",
            "tensor(2.1279e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1750, Task: 6, loss: 0.00002\n",
            "tensor(7.2131e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1750, Task: 7, loss: 0.00001\n",
            "tensor(6.9749e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1750, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1557e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1751, Task: 0, loss: 0.00009\n",
            "tensor(9.4795e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1751, Task: 1, loss: 0.00009\n",
            "tensor(9.4429e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1751, Task: 2, loss: 0.00009\n",
            "tensor(9.4606e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1751, Task: 3, loss: 0.00009\n",
            "tensor(9.4537e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1751, Task: 4, loss: 0.00009\n",
            "tensor(9.4839e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1751, Task: 5, loss: 0.00009\n",
            "tensor(2.1279e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1751, Task: 6, loss: 0.00002\n",
            "tensor(7.2141e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1751, Task: 7, loss: 0.00001\n",
            "tensor(6.9762e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1751, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1550e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1752, Task: 0, loss: 0.00009\n",
            "tensor(9.4791e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1752, Task: 1, loss: 0.00009\n",
            "tensor(9.4425e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1752, Task: 2, loss: 0.00009\n",
            "tensor(9.4602e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1752, Task: 3, loss: 0.00009\n",
            "tensor(9.4533e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1752, Task: 4, loss: 0.00009\n",
            "tensor(9.4835e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1752, Task: 5, loss: 0.00009\n",
            "tensor(2.1280e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1752, Task: 6, loss: 0.00002\n",
            "tensor(7.2152e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1752, Task: 7, loss: 0.00001\n",
            "tensor(6.9775e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1752, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1543e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1753, Task: 0, loss: 0.00009\n",
            "tensor(9.4787e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1753, Task: 1, loss: 0.00009\n",
            "tensor(9.4421e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1753, Task: 2, loss: 0.00009\n",
            "tensor(9.4598e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1753, Task: 3, loss: 0.00009\n",
            "tensor(9.4528e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1753, Task: 4, loss: 0.00009\n",
            "tensor(9.4831e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1753, Task: 5, loss: 0.00009\n",
            "tensor(2.1280e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1753, Task: 6, loss: 0.00002\n",
            "tensor(7.2164e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1753, Task: 7, loss: 0.00001\n",
            "tensor(6.9788e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1753, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1536e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1754, Task: 0, loss: 0.00009\n",
            "tensor(9.4783e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1754, Task: 1, loss: 0.00009\n",
            "tensor(9.4417e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1754, Task: 2, loss: 0.00009\n",
            "tensor(9.4594e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1754, Task: 3, loss: 0.00009\n",
            "tensor(9.4524e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1754, Task: 4, loss: 0.00009\n",
            "tensor(9.4827e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1754, Task: 5, loss: 0.00009\n",
            "tensor(2.1280e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1754, Task: 6, loss: 0.00002\n",
            "tensor(7.2174e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1754, Task: 7, loss: 0.00001\n",
            "tensor(6.9801e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1754, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1529e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1755, Task: 0, loss: 0.00009\n",
            "tensor(9.4779e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1755, Task: 1, loss: 0.00009\n",
            "tensor(9.4412e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1755, Task: 2, loss: 0.00009\n",
            "tensor(9.4589e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1755, Task: 3, loss: 0.00009\n",
            "tensor(9.4520e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1755, Task: 4, loss: 0.00009\n",
            "tensor(9.4822e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1755, Task: 5, loss: 0.00009\n",
            "tensor(2.1280e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1755, Task: 6, loss: 0.00002\n",
            "tensor(7.2184e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1755, Task: 7, loss: 0.00001\n",
            "tensor(6.9814e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1755, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1522e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1756, Task: 0, loss: 0.00009\n",
            "tensor(9.4775e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1756, Task: 1, loss: 0.00009\n",
            "tensor(9.4408e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1756, Task: 2, loss: 0.00009\n",
            "tensor(9.4585e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1756, Task: 3, loss: 0.00009\n",
            "tensor(9.4516e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1756, Task: 4, loss: 0.00009\n",
            "tensor(9.4818e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1756, Task: 5, loss: 0.00009\n",
            "tensor(2.1281e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1756, Task: 6, loss: 0.00002\n",
            "tensor(7.2195e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1756, Task: 7, loss: 0.00001\n",
            "tensor(6.9827e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1756, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1515e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1757, Task: 0, loss: 0.00009\n",
            "tensor(9.4770e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1757, Task: 1, loss: 0.00009\n",
            "tensor(9.4404e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1757, Task: 2, loss: 0.00009\n",
            "tensor(9.4581e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1757, Task: 3, loss: 0.00009\n",
            "tensor(9.4512e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1757, Task: 4, loss: 0.00009\n",
            "tensor(9.4814e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1757, Task: 5, loss: 0.00009\n",
            "tensor(2.1281e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1757, Task: 6, loss: 0.00002\n",
            "tensor(7.2205e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1757, Task: 7, loss: 0.00001\n",
            "tensor(6.9840e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1757, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1508e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1758, Task: 0, loss: 0.00009\n",
            "tensor(9.4766e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1758, Task: 1, loss: 0.00009\n",
            "tensor(9.4400e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1758, Task: 2, loss: 0.00009\n",
            "tensor(9.4577e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1758, Task: 3, loss: 0.00009\n",
            "tensor(9.4507e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1758, Task: 4, loss: 0.00009\n",
            "tensor(9.4810e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1758, Task: 5, loss: 0.00009\n",
            "tensor(2.1281e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1758, Task: 6, loss: 0.00002\n",
            "tensor(7.2215e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1758, Task: 7, loss: 0.00001\n",
            "tensor(6.9853e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1758, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1501e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1759, Task: 0, loss: 0.00009\n",
            "tensor(9.4762e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1759, Task: 1, loss: 0.00009\n",
            "tensor(9.4395e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1759, Task: 2, loss: 0.00009\n",
            "tensor(9.4572e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1759, Task: 3, loss: 0.00009\n",
            "tensor(9.4503e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1759, Task: 4, loss: 0.00009\n",
            "tensor(9.4805e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1759, Task: 5, loss: 0.00009\n",
            "tensor(2.1281e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1759, Task: 6, loss: 0.00002\n",
            "tensor(7.2224e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1759, Task: 7, loss: 0.00001\n",
            "tensor(6.9866e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1759, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1494e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1760, Task: 0, loss: 0.00009\n",
            "tensor(9.4757e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1760, Task: 1, loss: 0.00009\n",
            "tensor(9.4391e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1760, Task: 2, loss: 0.00009\n",
            "tensor(9.4568e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1760, Task: 3, loss: 0.00009\n",
            "tensor(9.4499e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1760, Task: 4, loss: 0.00009\n",
            "tensor(9.4801e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1760, Task: 5, loss: 0.00009\n",
            "tensor(2.1281e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1760, Task: 6, loss: 0.00002\n",
            "tensor(7.2235e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1760, Task: 7, loss: 0.00001\n",
            "tensor(6.9880e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1760, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1487e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1761, Task: 0, loss: 0.00009\n",
            "tensor(9.4753e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1761, Task: 1, loss: 0.00009\n",
            "tensor(9.4387e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1761, Task: 2, loss: 0.00009\n",
            "tensor(9.4563e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1761, Task: 3, loss: 0.00009\n",
            "tensor(9.4494e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1761, Task: 4, loss: 0.00009\n",
            "tensor(9.4797e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1761, Task: 5, loss: 0.00009\n",
            "tensor(2.1281e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1761, Task: 6, loss: 0.00002\n",
            "tensor(7.2246e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1761, Task: 7, loss: 0.00001\n",
            "tensor(6.9893e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1761, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1480e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1762, Task: 0, loss: 0.00009\n",
            "tensor(9.4749e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1762, Task: 1, loss: 0.00009\n",
            "tensor(9.4382e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1762, Task: 2, loss: 0.00009\n",
            "tensor(9.4559e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1762, Task: 3, loss: 0.00009\n",
            "tensor(9.4490e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1762, Task: 4, loss: 0.00009\n",
            "tensor(9.4792e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1762, Task: 5, loss: 0.00009\n",
            "tensor(2.1282e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1762, Task: 6, loss: 0.00002\n",
            "tensor(7.2258e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1762, Task: 7, loss: 0.00001\n",
            "tensor(6.9907e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1762, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1473e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1763, Task: 0, loss: 0.00009\n",
            "tensor(9.4744e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1763, Task: 1, loss: 0.00009\n",
            "tensor(9.4378e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1763, Task: 2, loss: 0.00009\n",
            "tensor(9.4555e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1763, Task: 3, loss: 0.00009\n",
            "tensor(9.4486e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1763, Task: 4, loss: 0.00009\n",
            "tensor(9.4788e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1763, Task: 5, loss: 0.00009\n",
            "tensor(2.1282e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1763, Task: 6, loss: 0.00002\n",
            "tensor(7.2269e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1763, Task: 7, loss: 0.00001\n",
            "tensor(6.9921e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1763, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1466e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1764, Task: 0, loss: 0.00009\n",
            "tensor(9.4740e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1764, Task: 1, loss: 0.00009\n",
            "tensor(9.4373e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1764, Task: 2, loss: 0.00009\n",
            "tensor(9.4550e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1764, Task: 3, loss: 0.00009\n",
            "tensor(9.4481e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1764, Task: 4, loss: 0.00009\n",
            "tensor(9.4783e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1764, Task: 5, loss: 0.00009\n",
            "tensor(2.1282e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1764, Task: 6, loss: 0.00002\n",
            "tensor(7.2281e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1764, Task: 7, loss: 0.00001\n",
            "tensor(6.9935e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1764, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1459e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1765, Task: 0, loss: 0.00009\n",
            "tensor(9.4735e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1765, Task: 1, loss: 0.00009\n",
            "tensor(9.4369e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1765, Task: 2, loss: 0.00009\n",
            "tensor(9.4546e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1765, Task: 3, loss: 0.00009\n",
            "tensor(9.4477e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1765, Task: 4, loss: 0.00009\n",
            "tensor(9.4779e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1765, Task: 5, loss: 0.00009\n",
            "tensor(2.1283e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1765, Task: 6, loss: 0.00002\n",
            "tensor(7.2293e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1765, Task: 7, loss: 0.00001\n",
            "tensor(6.9949e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1765, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1452e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1766, Task: 0, loss: 0.00009\n",
            "tensor(9.4731e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1766, Task: 1, loss: 0.00009\n",
            "tensor(9.4364e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1766, Task: 2, loss: 0.00009\n",
            "tensor(9.4541e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1766, Task: 3, loss: 0.00009\n",
            "tensor(9.4472e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1766, Task: 4, loss: 0.00009\n",
            "tensor(9.4774e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1766, Task: 5, loss: 0.00009\n",
            "tensor(2.1283e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1766, Task: 6, loss: 0.00002\n",
            "tensor(7.2305e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1766, Task: 7, loss: 0.00001\n",
            "tensor(6.9963e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1766, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1445e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1767, Task: 0, loss: 0.00009\n",
            "tensor(9.4726e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1767, Task: 1, loss: 0.00009\n",
            "tensor(9.4360e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1767, Task: 2, loss: 0.00009\n",
            "tensor(9.4537e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1767, Task: 3, loss: 0.00009\n",
            "tensor(9.4468e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1767, Task: 4, loss: 0.00009\n",
            "tensor(9.4770e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1767, Task: 5, loss: 0.00009\n",
            "tensor(2.1283e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1767, Task: 6, loss: 0.00002\n",
            "tensor(7.2316e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1767, Task: 7, loss: 0.00001\n",
            "tensor(6.9977e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1767, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1438e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1768, Task: 0, loss: 0.00009\n",
            "tensor(9.4722e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1768, Task: 1, loss: 0.00009\n",
            "tensor(9.4355e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1768, Task: 2, loss: 0.00009\n",
            "tensor(9.4532e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1768, Task: 3, loss: 0.00009\n",
            "tensor(9.4463e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1768, Task: 4, loss: 0.00009\n",
            "tensor(9.4765e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1768, Task: 5, loss: 0.00009\n",
            "tensor(2.1283e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1768, Task: 6, loss: 0.00002\n",
            "tensor(7.2327e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1768, Task: 7, loss: 0.00001\n",
            "tensor(6.9991e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1768, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1431e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1769, Task: 0, loss: 0.00009\n",
            "tensor(9.4717e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1769, Task: 1, loss: 0.00009\n",
            "tensor(9.4351e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1769, Task: 2, loss: 0.00009\n",
            "tensor(9.4528e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1769, Task: 3, loss: 0.00009\n",
            "tensor(9.4458e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1769, Task: 4, loss: 0.00009\n",
            "tensor(9.4761e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1769, Task: 5, loss: 0.00009\n",
            "tensor(2.1283e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1769, Task: 6, loss: 0.00002\n",
            "tensor(7.2338e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1769, Task: 7, loss: 0.00001\n",
            "tensor(7.0005e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1769, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1424e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1770, Task: 0, loss: 0.00009\n",
            "tensor(9.4712e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1770, Task: 1, loss: 0.00009\n",
            "tensor(9.4346e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1770, Task: 2, loss: 0.00009\n",
            "tensor(9.4523e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1770, Task: 3, loss: 0.00009\n",
            "tensor(9.4454e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1770, Task: 4, loss: 0.00009\n",
            "tensor(9.4756e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1770, Task: 5, loss: 0.00009\n",
            "tensor(2.1283e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1770, Task: 6, loss: 0.00002\n",
            "tensor(7.2348e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1770, Task: 7, loss: 0.00001\n",
            "tensor(7.0019e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1770, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1417e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1771, Task: 0, loss: 0.00009\n",
            "tensor(9.4708e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1771, Task: 1, loss: 0.00009\n",
            "tensor(9.4341e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1771, Task: 2, loss: 0.00009\n",
            "tensor(9.4518e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1771, Task: 3, loss: 0.00009\n",
            "tensor(9.4449e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1771, Task: 4, loss: 0.00009\n",
            "tensor(9.4751e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1771, Task: 5, loss: 0.00009\n",
            "tensor(2.1283e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1771, Task: 6, loss: 0.00002\n",
            "tensor(7.2359e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1771, Task: 7, loss: 0.00001\n",
            "tensor(7.0033e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1771, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1410e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1772, Task: 0, loss: 0.00009\n",
            "tensor(9.4703e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1772, Task: 1, loss: 0.00009\n",
            "tensor(9.4337e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1772, Task: 2, loss: 0.00009\n",
            "tensor(9.4514e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1772, Task: 3, loss: 0.00009\n",
            "tensor(9.4444e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1772, Task: 4, loss: 0.00009\n",
            "tensor(9.4747e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1772, Task: 5, loss: 0.00009\n",
            "tensor(2.1284e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1772, Task: 6, loss: 0.00002\n",
            "tensor(7.2372e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1772, Task: 7, loss: 0.00001\n",
            "tensor(7.0047e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1772, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1403e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1773, Task: 0, loss: 0.00009\n",
            "tensor(9.4698e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1773, Task: 1, loss: 0.00009\n",
            "tensor(9.4332e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1773, Task: 2, loss: 0.00009\n",
            "tensor(9.4509e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1773, Task: 3, loss: 0.00009\n",
            "tensor(9.4440e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1773, Task: 4, loss: 0.00009\n",
            "tensor(9.4742e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1773, Task: 5, loss: 0.00009\n",
            "tensor(2.1284e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1773, Task: 6, loss: 0.00002\n",
            "tensor(7.2384e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1773, Task: 7, loss: 0.00001\n",
            "tensor(7.0062e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1773, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1396e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1774, Task: 0, loss: 0.00009\n",
            "tensor(9.4694e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1774, Task: 1, loss: 0.00009\n",
            "tensor(9.4327e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1774, Task: 2, loss: 0.00009\n",
            "tensor(9.4504e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1774, Task: 3, loss: 0.00009\n",
            "tensor(9.4435e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1774, Task: 4, loss: 0.00009\n",
            "tensor(9.4737e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1774, Task: 5, loss: 0.00009\n",
            "tensor(2.1284e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1774, Task: 6, loss: 0.00002\n",
            "tensor(7.2397e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1774, Task: 7, loss: 0.00001\n",
            "tensor(7.0077e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1774, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1389e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1775, Task: 0, loss: 0.00009\n",
            "tensor(9.4689e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1775, Task: 1, loss: 0.00009\n",
            "tensor(9.4322e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1775, Task: 2, loss: 0.00009\n",
            "tensor(9.4499e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1775, Task: 3, loss: 0.00009\n",
            "tensor(9.4430e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1775, Task: 4, loss: 0.00009\n",
            "tensor(9.4732e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1775, Task: 5, loss: 0.00009\n",
            "tensor(2.1284e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1775, Task: 6, loss: 0.00002\n",
            "tensor(7.2409e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1775, Task: 7, loss: 0.00001\n",
            "tensor(7.0092e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1775, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1382e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1776, Task: 0, loss: 0.00009\n",
            "tensor(9.4684e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1776, Task: 1, loss: 0.00009\n",
            "tensor(9.4318e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1776, Task: 2, loss: 0.00009\n",
            "tensor(9.4495e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1776, Task: 3, loss: 0.00009\n",
            "tensor(9.4425e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1776, Task: 4, loss: 0.00009\n",
            "tensor(9.4728e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1776, Task: 5, loss: 0.00009\n",
            "tensor(2.1285e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1776, Task: 6, loss: 0.00002\n",
            "tensor(7.2421e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1776, Task: 7, loss: 0.00001\n",
            "tensor(7.0106e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1776, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1375e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1777, Task: 0, loss: 0.00009\n",
            "tensor(9.4679e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1777, Task: 1, loss: 0.00009\n",
            "tensor(9.4313e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1777, Task: 2, loss: 0.00009\n",
            "tensor(9.4490e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1777, Task: 3, loss: 0.00009\n",
            "tensor(9.4421e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1777, Task: 4, loss: 0.00009\n",
            "tensor(9.4723e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1777, Task: 5, loss: 0.00009\n",
            "tensor(2.1285e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1777, Task: 6, loss: 0.00002\n",
            "tensor(7.2434e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1777, Task: 7, loss: 0.00001\n",
            "tensor(7.0121e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1777, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1368e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1778, Task: 0, loss: 0.00009\n",
            "tensor(9.4674e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1778, Task: 1, loss: 0.00009\n",
            "tensor(9.4308e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1778, Task: 2, loss: 0.00009\n",
            "tensor(9.4485e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1778, Task: 3, loss: 0.00009\n",
            "tensor(9.4416e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1778, Task: 4, loss: 0.00009\n",
            "tensor(9.4718e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1778, Task: 5, loss: 0.00009\n",
            "tensor(2.1285e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1778, Task: 6, loss: 0.00002\n",
            "tensor(7.2446e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1778, Task: 7, loss: 0.00001\n",
            "tensor(7.0136e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1778, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1361e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1779, Task: 0, loss: 0.00009\n",
            "tensor(9.4669e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1779, Task: 1, loss: 0.00009\n",
            "tensor(9.4303e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1779, Task: 2, loss: 0.00009\n",
            "tensor(9.4480e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1779, Task: 3, loss: 0.00009\n",
            "tensor(9.4411e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1779, Task: 4, loss: 0.00009\n",
            "tensor(9.4713e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1779, Task: 5, loss: 0.00009\n",
            "tensor(2.1285e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1779, Task: 6, loss: 0.00002\n",
            "tensor(7.2459e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1779, Task: 7, loss: 0.00001\n",
            "tensor(7.0151e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1779, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1354e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1780, Task: 0, loss: 0.00009\n",
            "tensor(9.4665e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1780, Task: 1, loss: 0.00009\n",
            "tensor(9.4298e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1780, Task: 2, loss: 0.00009\n",
            "tensor(9.4475e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1780, Task: 3, loss: 0.00009\n",
            "tensor(9.4406e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1780, Task: 4, loss: 0.00009\n",
            "tensor(9.4708e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1780, Task: 5, loss: 0.00009\n",
            "tensor(2.1286e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1780, Task: 6, loss: 0.00002\n",
            "tensor(7.2471e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1780, Task: 7, loss: 0.00001\n",
            "tensor(7.0166e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1780, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1347e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1781, Task: 0, loss: 0.00009\n",
            "tensor(9.4660e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1781, Task: 1, loss: 0.00009\n",
            "tensor(9.4293e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1781, Task: 2, loss: 0.00009\n",
            "tensor(9.4470e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1781, Task: 3, loss: 0.00009\n",
            "tensor(9.4401e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1781, Task: 4, loss: 0.00009\n",
            "tensor(9.4703e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1781, Task: 5, loss: 0.00009\n",
            "tensor(2.1286e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1781, Task: 6, loss: 0.00002\n",
            "tensor(7.2484e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1781, Task: 7, loss: 0.00001\n",
            "tensor(7.0181e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1781, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1340e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1782, Task: 0, loss: 0.00009\n",
            "tensor(9.4655e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1782, Task: 1, loss: 0.00009\n",
            "tensor(9.4288e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1782, Task: 2, loss: 0.00009\n",
            "tensor(9.4465e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1782, Task: 3, loss: 0.00009\n",
            "tensor(9.4396e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1782, Task: 4, loss: 0.00009\n",
            "tensor(9.4698e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1782, Task: 5, loss: 0.00009\n",
            "tensor(2.1286e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1782, Task: 6, loss: 0.00002\n",
            "tensor(7.2497e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1782, Task: 7, loss: 0.00001\n",
            "tensor(7.0196e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1782, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1333e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1783, Task: 0, loss: 0.00009\n",
            "tensor(9.4650e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1783, Task: 1, loss: 0.00009\n",
            "tensor(9.4283e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1783, Task: 2, loss: 0.00009\n",
            "tensor(9.4460e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1783, Task: 3, loss: 0.00009\n",
            "tensor(9.4391e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1783, Task: 4, loss: 0.00009\n",
            "tensor(9.4693e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1783, Task: 5, loss: 0.00009\n",
            "tensor(2.1286e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1783, Task: 6, loss: 0.00002\n",
            "tensor(7.2511e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1783, Task: 7, loss: 0.00001\n",
            "tensor(7.0212e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1783, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1326e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1784, Task: 0, loss: 0.00009\n",
            "tensor(9.4645e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1784, Task: 1, loss: 0.00009\n",
            "tensor(9.4278e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1784, Task: 2, loss: 0.00009\n",
            "tensor(9.4455e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1784, Task: 3, loss: 0.00009\n",
            "tensor(9.4386e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1784, Task: 4, loss: 0.00009\n",
            "tensor(9.4688e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1784, Task: 5, loss: 0.00009\n",
            "tensor(2.1287e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1784, Task: 6, loss: 0.00002\n",
            "tensor(7.2523e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1784, Task: 7, loss: 0.00001\n",
            "tensor(7.0227e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1784, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1319e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1785, Task: 0, loss: 0.00009\n",
            "tensor(9.4640e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1785, Task: 1, loss: 0.00009\n",
            "tensor(9.4273e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1785, Task: 2, loss: 0.00009\n",
            "tensor(9.4450e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1785, Task: 3, loss: 0.00009\n",
            "tensor(9.4381e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1785, Task: 4, loss: 0.00009\n",
            "tensor(9.4683e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1785, Task: 5, loss: 0.00009\n",
            "tensor(2.1287e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1785, Task: 6, loss: 0.00002\n",
            "tensor(7.2537e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1785, Task: 7, loss: 0.00001\n",
            "tensor(7.0243e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1785, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1312e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1786, Task: 0, loss: 0.00009\n",
            "tensor(9.4635e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1786, Task: 1, loss: 0.00009\n",
            "tensor(9.4268e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1786, Task: 2, loss: 0.00009\n",
            "tensor(9.4445e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1786, Task: 3, loss: 0.00009\n",
            "tensor(9.4376e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1786, Task: 4, loss: 0.00009\n",
            "tensor(9.4678e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1786, Task: 5, loss: 0.00009\n",
            "tensor(2.1287e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1786, Task: 6, loss: 0.00002\n",
            "tensor(7.2549e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1786, Task: 7, loss: 0.00001\n",
            "tensor(7.0258e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1786, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1305e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1787, Task: 0, loss: 0.00009\n",
            "tensor(9.4630e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1787, Task: 1, loss: 0.00009\n",
            "tensor(9.4263e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1787, Task: 2, loss: 0.00009\n",
            "tensor(9.4440e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1787, Task: 3, loss: 0.00009\n",
            "tensor(9.4371e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1787, Task: 4, loss: 0.00009\n",
            "tensor(9.4673e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1787, Task: 5, loss: 0.00009\n",
            "tensor(2.1287e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1787, Task: 6, loss: 0.00002\n",
            "tensor(7.2562e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1787, Task: 7, loss: 0.00001\n",
            "tensor(7.0274e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1787, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1298e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1788, Task: 0, loss: 0.00009\n",
            "tensor(9.4624e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1788, Task: 1, loss: 0.00009\n",
            "tensor(9.4258e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1788, Task: 2, loss: 0.00009\n",
            "tensor(9.4435e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1788, Task: 3, loss: 0.00009\n",
            "tensor(9.4366e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1788, Task: 4, loss: 0.00009\n",
            "tensor(9.4668e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1788, Task: 5, loss: 0.00009\n",
            "tensor(2.1287e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1788, Task: 6, loss: 0.00002\n",
            "tensor(7.2574e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1788, Task: 7, loss: 0.00001\n",
            "tensor(7.0289e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1788, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1291e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1789, Task: 0, loss: 0.00009\n",
            "tensor(9.4619e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1789, Task: 1, loss: 0.00009\n",
            "tensor(9.4253e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1789, Task: 2, loss: 0.00009\n",
            "tensor(9.4430e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1789, Task: 3, loss: 0.00009\n",
            "tensor(9.4361e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1789, Task: 4, loss: 0.00009\n",
            "tensor(9.4663e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1789, Task: 5, loss: 0.00009\n",
            "tensor(2.1287e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1789, Task: 6, loss: 0.00002\n",
            "tensor(7.2586e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1789, Task: 7, loss: 0.00001\n",
            "tensor(7.0305e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1789, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1284e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1790, Task: 0, loss: 0.00009\n",
            "tensor(9.4614e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1790, Task: 1, loss: 0.00009\n",
            "tensor(9.4248e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1790, Task: 2, loss: 0.00009\n",
            "tensor(9.4425e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1790, Task: 3, loss: 0.00009\n",
            "tensor(9.4356e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1790, Task: 4, loss: 0.00009\n",
            "tensor(9.4658e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1790, Task: 5, loss: 0.00009\n",
            "tensor(2.1288e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1790, Task: 6, loss: 0.00002\n",
            "tensor(7.2598e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1790, Task: 7, loss: 0.00001\n",
            "tensor(7.0320e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1790, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1277e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1791, Task: 0, loss: 0.00009\n",
            "tensor(9.4609e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1791, Task: 1, loss: 0.00009\n",
            "tensor(9.4243e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1791, Task: 2, loss: 0.00009\n",
            "tensor(9.4420e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1791, Task: 3, loss: 0.00009\n",
            "tensor(9.4350e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1791, Task: 4, loss: 0.00009\n",
            "tensor(9.4653e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1791, Task: 5, loss: 0.00009\n",
            "tensor(2.1288e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1791, Task: 6, loss: 0.00002\n",
            "tensor(7.2612e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1791, Task: 7, loss: 0.00001\n",
            "tensor(7.0336e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1791, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1270e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1792, Task: 0, loss: 0.00009\n",
            "tensor(9.4604e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1792, Task: 1, loss: 0.00009\n",
            "tensor(9.4237e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1792, Task: 2, loss: 0.00009\n",
            "tensor(9.4414e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1792, Task: 3, loss: 0.00009\n",
            "tensor(9.4345e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1792, Task: 4, loss: 0.00009\n",
            "tensor(9.4647e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1792, Task: 5, loss: 0.00009\n",
            "tensor(2.1288e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1792, Task: 6, loss: 0.00002\n",
            "tensor(7.2625e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1792, Task: 7, loss: 0.00001\n",
            "tensor(7.0352e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1792, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1263e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1793, Task: 0, loss: 0.00009\n",
            "tensor(9.4598e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1793, Task: 1, loss: 0.00009\n",
            "tensor(9.4232e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1793, Task: 2, loss: 0.00009\n",
            "tensor(9.4409e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1793, Task: 3, loss: 0.00009\n",
            "tensor(9.4340e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1793, Task: 4, loss: 0.00009\n",
            "tensor(9.4642e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1793, Task: 5, loss: 0.00009\n",
            "tensor(2.1288e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1793, Task: 6, loss: 0.00002\n",
            "tensor(7.2640e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1793, Task: 7, loss: 0.00001\n",
            "tensor(7.0368e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1793, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1256e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1794, Task: 0, loss: 0.00009\n",
            "tensor(9.4593e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1794, Task: 1, loss: 0.00009\n",
            "tensor(9.4227e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1794, Task: 2, loss: 0.00009\n",
            "tensor(9.4404e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1794, Task: 3, loss: 0.00009\n",
            "tensor(9.4335e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1794, Task: 4, loss: 0.00009\n",
            "tensor(9.4637e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1794, Task: 5, loss: 0.00009\n",
            "tensor(2.1289e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1794, Task: 6, loss: 0.00002\n",
            "tensor(7.2655e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1794, Task: 7, loss: 0.00001\n",
            "tensor(7.0385e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1794, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1249e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1795, Task: 0, loss: 0.00009\n",
            "tensor(9.4588e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1795, Task: 1, loss: 0.00009\n",
            "tensor(9.4222e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1795, Task: 2, loss: 0.00009\n",
            "tensor(9.4399e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1795, Task: 3, loss: 0.00009\n",
            "tensor(9.4330e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1795, Task: 4, loss: 0.00009\n",
            "tensor(9.4632e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1795, Task: 5, loss: 0.00009\n",
            "tensor(2.1289e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1795, Task: 6, loss: 0.00002\n",
            "tensor(7.2670e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1795, Task: 7, loss: 0.00001\n",
            "tensor(7.0401e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1795, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1242e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1796, Task: 0, loss: 0.00009\n",
            "tensor(9.4583e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1796, Task: 1, loss: 0.00009\n",
            "tensor(9.4217e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1796, Task: 2, loss: 0.00009\n",
            "tensor(9.4393e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1796, Task: 3, loss: 0.00009\n",
            "tensor(9.4324e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1796, Task: 4, loss: 0.00009\n",
            "tensor(9.4626e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1796, Task: 5, loss: 0.00009\n",
            "tensor(2.1289e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1796, Task: 6, loss: 0.00002\n",
            "tensor(7.2684e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1796, Task: 7, loss: 0.00001\n",
            "tensor(7.0417e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1796, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1235e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1797, Task: 0, loss: 0.00009\n",
            "tensor(9.4577e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1797, Task: 1, loss: 0.00009\n",
            "tensor(9.4211e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1797, Task: 2, loss: 0.00009\n",
            "tensor(9.4388e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1797, Task: 3, loss: 0.00009\n",
            "tensor(9.4319e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1797, Task: 4, loss: 0.00009\n",
            "tensor(9.4621e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1797, Task: 5, loss: 0.00009\n",
            "tensor(2.1290e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1797, Task: 6, loss: 0.00002\n",
            "tensor(7.2698e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1797, Task: 7, loss: 0.00001\n",
            "tensor(7.0434e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1797, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1228e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1798, Task: 0, loss: 0.00009\n",
            "tensor(9.4572e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1798, Task: 1, loss: 0.00009\n",
            "tensor(9.4206e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1798, Task: 2, loss: 0.00009\n",
            "tensor(9.4383e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1798, Task: 3, loss: 0.00009\n",
            "tensor(9.4314e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1798, Task: 4, loss: 0.00009\n",
            "tensor(9.4616e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1798, Task: 5, loss: 0.00009\n",
            "tensor(2.1290e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1798, Task: 6, loss: 0.00002\n",
            "tensor(7.2712e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1798, Task: 7, loss: 0.00001\n",
            "tensor(7.0450e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1798, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1221e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1799, Task: 0, loss: 0.00009\n",
            "tensor(9.4567e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1799, Task: 1, loss: 0.00009\n",
            "tensor(9.4201e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1799, Task: 2, loss: 0.00009\n",
            "tensor(9.4377e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1799, Task: 3, loss: 0.00009\n",
            "tensor(9.4308e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1799, Task: 4, loss: 0.00009\n",
            "tensor(9.4610e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1799, Task: 5, loss: 0.00009\n",
            "tensor(2.1290e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1799, Task: 6, loss: 0.00002\n",
            "tensor(7.2725e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1799, Task: 7, loss: 0.00001\n",
            "tensor(7.0466e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1799, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1214e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1800, Task: 0, loss: 0.00009\n",
            "tensor(9.4561e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1800, Task: 1, loss: 0.00009\n",
            "tensor(9.4195e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1800, Task: 2, loss: 0.00009\n",
            "tensor(9.4372e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1800, Task: 3, loss: 0.00009\n",
            "tensor(9.4303e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1800, Task: 4, loss: 0.00009\n",
            "tensor(9.4605e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1800, Task: 5, loss: 0.00009\n",
            "tensor(2.1290e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1800, Task: 6, loss: 0.00002\n",
            "tensor(7.2738e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1800, Task: 7, loss: 0.00001\n",
            "tensor(7.0482e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1800, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1207e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1801, Task: 0, loss: 0.00009\n",
            "tensor(9.4556e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1801, Task: 1, loss: 0.00009\n",
            "tensor(9.4190e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1801, Task: 2, loss: 0.00009\n",
            "tensor(9.4367e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1801, Task: 3, loss: 0.00009\n",
            "tensor(9.4297e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1801, Task: 4, loss: 0.00009\n",
            "tensor(9.4600e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1801, Task: 5, loss: 0.00009\n",
            "tensor(2.1290e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1801, Task: 6, loss: 0.00002\n",
            "tensor(7.2752e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1801, Task: 7, loss: 0.00001\n",
            "tensor(7.0499e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1801, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1200e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1802, Task: 0, loss: 0.00009\n",
            "tensor(9.4550e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1802, Task: 1, loss: 0.00009\n",
            "tensor(9.4184e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1802, Task: 2, loss: 0.00009\n",
            "tensor(9.4361e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1802, Task: 3, loss: 0.00009\n",
            "tensor(9.4292e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1802, Task: 4, loss: 0.00009\n",
            "tensor(9.4594e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1802, Task: 5, loss: 0.00009\n",
            "tensor(2.1290e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1802, Task: 6, loss: 0.00002\n",
            "tensor(7.2765e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1802, Task: 7, loss: 0.00001\n",
            "tensor(7.0515e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1802, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1193e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1803, Task: 0, loss: 0.00009\n",
            "tensor(9.4545e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1803, Task: 1, loss: 0.00009\n",
            "tensor(9.4179e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1803, Task: 2, loss: 0.00009\n",
            "tensor(9.4356e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1803, Task: 3, loss: 0.00009\n",
            "tensor(9.4287e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1803, Task: 4, loss: 0.00009\n",
            "tensor(9.4589e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1803, Task: 5, loss: 0.00009\n",
            "tensor(2.1291e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1803, Task: 6, loss: 0.00002\n",
            "tensor(7.2778e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1803, Task: 7, loss: 0.00001\n",
            "tensor(7.0532e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1803, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1186e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1804, Task: 0, loss: 0.00009\n",
            "tensor(9.4539e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1804, Task: 1, loss: 0.00009\n",
            "tensor(9.4173e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1804, Task: 2, loss: 0.00009\n",
            "tensor(9.4350e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1804, Task: 3, loss: 0.00009\n",
            "tensor(9.4281e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1804, Task: 4, loss: 0.00009\n",
            "tensor(9.4583e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1804, Task: 5, loss: 0.00009\n",
            "tensor(2.1291e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1804, Task: 6, loss: 0.00002\n",
            "tensor(7.2792e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1804, Task: 7, loss: 0.00001\n",
            "tensor(7.0549e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1804, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1179e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1805, Task: 0, loss: 0.00009\n",
            "tensor(9.4534e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1805, Task: 1, loss: 0.00009\n",
            "tensor(9.4168e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1805, Task: 2, loss: 0.00009\n",
            "tensor(9.4345e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1805, Task: 3, loss: 0.00009\n",
            "tensor(9.4276e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1805, Task: 4, loss: 0.00009\n",
            "tensor(9.4578e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1805, Task: 5, loss: 0.00009\n",
            "tensor(2.1291e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1805, Task: 6, loss: 0.00002\n",
            "tensor(7.2807e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1805, Task: 7, loss: 0.00001\n",
            "tensor(7.0566e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1805, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1172e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1806, Task: 0, loss: 0.00009\n",
            "tensor(9.4528e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1806, Task: 1, loss: 0.00009\n",
            "tensor(9.4162e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1806, Task: 2, loss: 0.00009\n",
            "tensor(9.4339e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1806, Task: 3, loss: 0.00009\n",
            "tensor(9.4270e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1806, Task: 4, loss: 0.00009\n",
            "tensor(9.4572e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1806, Task: 5, loss: 0.00009\n",
            "tensor(2.1292e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1806, Task: 6, loss: 0.00002\n",
            "tensor(7.2823e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1806, Task: 7, loss: 0.00001\n",
            "tensor(7.0583e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1806, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1165e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1807, Task: 0, loss: 0.00009\n",
            "tensor(9.4523e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1807, Task: 1, loss: 0.00009\n",
            "tensor(9.4157e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1807, Task: 2, loss: 0.00009\n",
            "tensor(9.4334e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1807, Task: 3, loss: 0.00009\n",
            "tensor(9.4265e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1807, Task: 4, loss: 0.00009\n",
            "tensor(9.4567e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1807, Task: 5, loss: 0.00009\n",
            "tensor(2.1292e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1807, Task: 6, loss: 0.00002\n",
            "tensor(7.2838e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1807, Task: 7, loss: 0.00001\n",
            "tensor(7.0600e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1807, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1158e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1808, Task: 0, loss: 0.00009\n",
            "tensor(9.4517e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1808, Task: 1, loss: 0.00009\n",
            "tensor(9.4151e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1808, Task: 2, loss: 0.00009\n",
            "tensor(9.4328e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1808, Task: 3, loss: 0.00009\n",
            "tensor(9.4259e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1808, Task: 4, loss: 0.00009\n",
            "tensor(9.4561e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1808, Task: 5, loss: 0.00009\n",
            "tensor(2.1292e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1808, Task: 6, loss: 0.00002\n",
            "tensor(7.2854e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1808, Task: 7, loss: 0.00001\n",
            "tensor(7.0617e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1808, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1151e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1809, Task: 0, loss: 0.00009\n",
            "tensor(9.4512e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1809, Task: 1, loss: 0.00009\n",
            "tensor(9.4146e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1809, Task: 2, loss: 0.00009\n",
            "tensor(9.4323e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1809, Task: 3, loss: 0.00009\n",
            "tensor(9.4254e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1809, Task: 4, loss: 0.00009\n",
            "tensor(9.4555e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1809, Task: 5, loss: 0.00009\n",
            "tensor(2.1293e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1809, Task: 6, loss: 0.00002\n",
            "tensor(7.2869e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1809, Task: 7, loss: 0.00001\n",
            "tensor(7.0634e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1809, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1144e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1810, Task: 0, loss: 0.00009\n",
            "tensor(9.4506e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1810, Task: 1, loss: 0.00009\n",
            "tensor(9.4140e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1810, Task: 2, loss: 0.00009\n",
            "tensor(9.4317e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1810, Task: 3, loss: 0.00009\n",
            "tensor(9.4248e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1810, Task: 4, loss: 0.00009\n",
            "tensor(9.4550e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1810, Task: 5, loss: 0.00009\n",
            "tensor(2.1293e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1810, Task: 6, loss: 0.00002\n",
            "tensor(7.2884e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1810, Task: 7, loss: 0.00001\n",
            "tensor(7.0651e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1810, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1137e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1811, Task: 0, loss: 0.00009\n",
            "tensor(9.4501e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1811, Task: 1, loss: 0.00009\n",
            "tensor(9.4135e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1811, Task: 2, loss: 0.00009\n",
            "tensor(9.4311e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1811, Task: 3, loss: 0.00009\n",
            "tensor(9.4242e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1811, Task: 4, loss: 0.00009\n",
            "tensor(9.4544e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1811, Task: 5, loss: 0.00009\n",
            "tensor(2.1293e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1811, Task: 6, loss: 0.00002\n",
            "tensor(7.2898e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1811, Task: 7, loss: 0.00001\n",
            "tensor(7.0669e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1811, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1130e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1812, Task: 0, loss: 0.00009\n",
            "tensor(9.4495e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1812, Task: 1, loss: 0.00009\n",
            "tensor(9.4129e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1812, Task: 2, loss: 0.00009\n",
            "tensor(9.4306e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1812, Task: 3, loss: 0.00009\n",
            "tensor(9.4237e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1812, Task: 4, loss: 0.00009\n",
            "tensor(9.4539e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1812, Task: 5, loss: 0.00009\n",
            "tensor(2.1293e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1812, Task: 6, loss: 0.00002\n",
            "tensor(7.2913e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1812, Task: 7, loss: 0.00001\n",
            "tensor(7.0686e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1812, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1123e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1813, Task: 0, loss: 0.00009\n",
            "tensor(9.4489e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1813, Task: 1, loss: 0.00009\n",
            "tensor(9.4123e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1813, Task: 2, loss: 0.00009\n",
            "tensor(9.4300e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1813, Task: 3, loss: 0.00009\n",
            "tensor(9.4231e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1813, Task: 4, loss: 0.00009\n",
            "tensor(9.4533e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1813, Task: 5, loss: 0.00009\n",
            "tensor(2.1293e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1813, Task: 6, loss: 0.00002\n",
            "tensor(7.2927e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1813, Task: 7, loss: 0.00001\n",
            "tensor(7.0703e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1813, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1116e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1814, Task: 0, loss: 0.00009\n",
            "tensor(9.4483e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1814, Task: 1, loss: 0.00009\n",
            "tensor(9.4118e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1814, Task: 2, loss: 0.00009\n",
            "tensor(9.4294e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1814, Task: 3, loss: 0.00009\n",
            "tensor(9.4225e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1814, Task: 4, loss: 0.00009\n",
            "tensor(9.4527e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1814, Task: 5, loss: 0.00009\n",
            "tensor(2.1294e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1814, Task: 6, loss: 0.00002\n",
            "tensor(7.2940e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1814, Task: 7, loss: 0.00001\n",
            "tensor(7.0720e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1814, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1109e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1815, Task: 0, loss: 0.00009\n",
            "tensor(9.4478e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1815, Task: 1, loss: 0.00009\n",
            "tensor(9.4112e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1815, Task: 2, loss: 0.00009\n",
            "tensor(9.4289e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1815, Task: 3, loss: 0.00009\n",
            "tensor(9.4219e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1815, Task: 4, loss: 0.00009\n",
            "tensor(9.4521e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1815, Task: 5, loss: 0.00009\n",
            "tensor(2.1294e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1815, Task: 6, loss: 0.00002\n",
            "tensor(7.2954e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1815, Task: 7, loss: 0.00001\n",
            "tensor(7.0737e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1815, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1102e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1816, Task: 0, loss: 0.00009\n",
            "tensor(9.4472e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1816, Task: 1, loss: 0.00009\n",
            "tensor(9.4106e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1816, Task: 2, loss: 0.00009\n",
            "tensor(9.4283e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1816, Task: 3, loss: 0.00009\n",
            "tensor(9.4214e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1816, Task: 4, loss: 0.00009\n",
            "tensor(9.4516e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1816, Task: 5, loss: 0.00009\n",
            "tensor(2.1294e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1816, Task: 6, loss: 0.00002\n",
            "tensor(7.2969e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1816, Task: 7, loss: 0.00001\n",
            "tensor(7.0755e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1816, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1095e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1817, Task: 0, loss: 0.00009\n",
            "tensor(9.4466e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1817, Task: 1, loss: 0.00009\n",
            "tensor(9.4100e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1817, Task: 2, loss: 0.00009\n",
            "tensor(9.4277e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1817, Task: 3, loss: 0.00009\n",
            "tensor(9.4208e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1817, Task: 4, loss: 0.00009\n",
            "tensor(9.4510e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1817, Task: 5, loss: 0.00009\n",
            "tensor(2.1294e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1817, Task: 6, loss: 0.00002\n",
            "tensor(7.2983e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1817, Task: 7, loss: 0.00001\n",
            "tensor(7.0772e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1817, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1087e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1818, Task: 0, loss: 0.00009\n",
            "tensor(9.4460e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1818, Task: 1, loss: 0.00009\n",
            "tensor(9.4095e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1818, Task: 2, loss: 0.00009\n",
            "tensor(9.4271e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1818, Task: 3, loss: 0.00009\n",
            "tensor(9.4202e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1818, Task: 4, loss: 0.00009\n",
            "tensor(9.4504e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1818, Task: 5, loss: 0.00009\n",
            "tensor(2.1294e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1818, Task: 6, loss: 0.00002\n",
            "tensor(7.3000e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1818, Task: 7, loss: 0.00001\n",
            "tensor(7.0790e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1818, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1080e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1819, Task: 0, loss: 0.00009\n",
            "tensor(9.4455e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1819, Task: 1, loss: 0.00009\n",
            "tensor(9.4089e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1819, Task: 2, loss: 0.00009\n",
            "tensor(9.4265e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1819, Task: 3, loss: 0.00009\n",
            "tensor(9.4196e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1819, Task: 4, loss: 0.00009\n",
            "tensor(9.4498e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1819, Task: 5, loss: 0.00009\n",
            "tensor(2.1295e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1819, Task: 6, loss: 0.00002\n",
            "tensor(7.3017e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1819, Task: 7, loss: 0.00001\n",
            "tensor(7.0808e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1819, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1073e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1820, Task: 0, loss: 0.00009\n",
            "tensor(9.4449e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1820, Task: 1, loss: 0.00009\n",
            "tensor(9.4083e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1820, Task: 2, loss: 0.00009\n",
            "tensor(9.4260e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1820, Task: 3, loss: 0.00009\n",
            "tensor(9.4191e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1820, Task: 4, loss: 0.00009\n",
            "tensor(9.4493e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1820, Task: 5, loss: 0.00009\n",
            "tensor(2.1295e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1820, Task: 6, loss: 0.00002\n",
            "tensor(7.3033e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1820, Task: 7, loss: 0.00001\n",
            "tensor(7.0826e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1820, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1066e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1821, Task: 0, loss: 0.00009\n",
            "tensor(9.4443e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1821, Task: 1, loss: 0.00009\n",
            "tensor(9.4077e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1821, Task: 2, loss: 0.00009\n",
            "tensor(9.4254e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1821, Task: 3, loss: 0.00009\n",
            "tensor(9.4185e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1821, Task: 4, loss: 0.00009\n",
            "tensor(9.4487e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1821, Task: 5, loss: 0.00009\n",
            "tensor(2.1296e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1821, Task: 6, loss: 0.00002\n",
            "tensor(7.3049e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1821, Task: 7, loss: 0.00001\n",
            "tensor(7.0844e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1821, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1059e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1822, Task: 0, loss: 0.00009\n",
            "tensor(9.4437e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1822, Task: 1, loss: 0.00009\n",
            "tensor(9.4071e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1822, Task: 2, loss: 0.00009\n",
            "tensor(9.4248e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1822, Task: 3, loss: 0.00009\n",
            "tensor(9.4179e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1822, Task: 4, loss: 0.00009\n",
            "tensor(9.4481e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1822, Task: 5, loss: 0.00009\n",
            "tensor(2.1296e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1822, Task: 6, loss: 0.00002\n",
            "tensor(7.3065e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1822, Task: 7, loss: 0.00001\n",
            "tensor(7.0862e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1822, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1052e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1823, Task: 0, loss: 0.00009\n",
            "tensor(9.4431e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1823, Task: 1, loss: 0.00009\n",
            "tensor(9.4065e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1823, Task: 2, loss: 0.00009\n",
            "tensor(9.4242e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1823, Task: 3, loss: 0.00009\n",
            "tensor(9.4173e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1823, Task: 4, loss: 0.00009\n",
            "tensor(9.4475e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1823, Task: 5, loss: 0.00009\n",
            "tensor(2.1296e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1823, Task: 6, loss: 0.00002\n",
            "tensor(7.3081e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1823, Task: 7, loss: 0.00001\n",
            "tensor(7.0880e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1823, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1045e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1824, Task: 0, loss: 0.00009\n",
            "tensor(9.4425e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1824, Task: 1, loss: 0.00009\n",
            "tensor(9.4060e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1824, Task: 2, loss: 0.00009\n",
            "tensor(9.4236e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1824, Task: 3, loss: 0.00009\n",
            "tensor(9.4167e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1824, Task: 4, loss: 0.00009\n",
            "tensor(9.4469e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1824, Task: 5, loss: 0.00009\n",
            "tensor(2.1296e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1824, Task: 6, loss: 0.00002\n",
            "tensor(7.3096e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1824, Task: 7, loss: 0.00001\n",
            "tensor(7.0898e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1824, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1038e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1825, Task: 0, loss: 0.00009\n",
            "tensor(9.4420e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1825, Task: 1, loss: 0.00009\n",
            "tensor(9.4054e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1825, Task: 2, loss: 0.00009\n",
            "tensor(9.4230e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1825, Task: 3, loss: 0.00009\n",
            "tensor(9.4161e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1825, Task: 4, loss: 0.00009\n",
            "tensor(9.4463e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1825, Task: 5, loss: 0.00009\n",
            "tensor(2.1296e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1825, Task: 6, loss: 0.00002\n",
            "tensor(7.3111e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1825, Task: 7, loss: 0.00001\n",
            "tensor(7.0916e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1825, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1031e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1826, Task: 0, loss: 0.00009\n",
            "tensor(9.4414e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1826, Task: 1, loss: 0.00009\n",
            "tensor(9.4048e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1826, Task: 2, loss: 0.00009\n",
            "tensor(9.4224e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1826, Task: 3, loss: 0.00009\n",
            "tensor(9.4155e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1826, Task: 4, loss: 0.00009\n",
            "tensor(9.4457e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1826, Task: 5, loss: 0.00009\n",
            "tensor(2.1297e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1826, Task: 6, loss: 0.00002\n",
            "tensor(7.3125e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1826, Task: 7, loss: 0.00001\n",
            "tensor(7.0934e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1826, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1024e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1827, Task: 0, loss: 0.00009\n",
            "tensor(9.4408e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1827, Task: 1, loss: 0.00009\n",
            "tensor(9.4042e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1827, Task: 2, loss: 0.00009\n",
            "tensor(9.4218e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1827, Task: 3, loss: 0.00009\n",
            "tensor(9.4149e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1827, Task: 4, loss: 0.00009\n",
            "tensor(9.4451e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1827, Task: 5, loss: 0.00009\n",
            "tensor(2.1297e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1827, Task: 6, loss: 0.00002\n",
            "tensor(7.3141e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1827, Task: 7, loss: 0.00001\n",
            "tensor(7.0952e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1827, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1017e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1828, Task: 0, loss: 0.00009\n",
            "tensor(9.4402e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1828, Task: 1, loss: 0.00009\n",
            "tensor(9.4036e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1828, Task: 2, loss: 0.00009\n",
            "tensor(9.4212e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1828, Task: 3, loss: 0.00009\n",
            "tensor(9.4143e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1828, Task: 4, loss: 0.00009\n",
            "tensor(9.4445e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1828, Task: 5, loss: 0.00009\n",
            "tensor(2.1297e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1828, Task: 6, loss: 0.00002\n",
            "tensor(7.3157e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1828, Task: 7, loss: 0.00001\n",
            "tensor(7.0970e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1828, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1010e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1829, Task: 0, loss: 0.00009\n",
            "tensor(9.4396e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1829, Task: 1, loss: 0.00009\n",
            "tensor(9.4030e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1829, Task: 2, loss: 0.00009\n",
            "tensor(9.4207e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1829, Task: 3, loss: 0.00009\n",
            "tensor(9.4137e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1829, Task: 4, loss: 0.00009\n",
            "tensor(9.4439e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1829, Task: 5, loss: 0.00009\n",
            "tensor(2.1297e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1829, Task: 6, loss: 0.00002\n",
            "tensor(7.3172e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1829, Task: 7, loss: 0.00001\n",
            "tensor(7.0988e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1829, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.1003e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1830, Task: 0, loss: 0.00009\n",
            "tensor(9.4390e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1830, Task: 1, loss: 0.00009\n",
            "tensor(9.4024e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1830, Task: 2, loss: 0.00009\n",
            "tensor(9.4200e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1830, Task: 3, loss: 0.00009\n",
            "tensor(9.4131e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1830, Task: 4, loss: 0.00009\n",
            "tensor(9.4433e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1830, Task: 5, loss: 0.00009\n",
            "tensor(2.1298e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1830, Task: 6, loss: 0.00002\n",
            "tensor(7.3188e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1830, Task: 7, loss: 0.00001\n",
            "tensor(7.1007e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1830, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0996e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1831, Task: 0, loss: 0.00009\n",
            "tensor(9.4384e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1831, Task: 1, loss: 0.00009\n",
            "tensor(9.4018e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1831, Task: 2, loss: 0.00009\n",
            "tensor(9.4194e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1831, Task: 3, loss: 0.00009\n",
            "tensor(9.4125e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1831, Task: 4, loss: 0.00009\n",
            "tensor(9.4427e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1831, Task: 5, loss: 0.00009\n",
            "tensor(2.1298e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1831, Task: 6, loss: 0.00002\n",
            "tensor(7.3205e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1831, Task: 7, loss: 0.00001\n",
            "tensor(7.1025e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1831, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0989e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1832, Task: 0, loss: 0.00009\n",
            "tensor(9.4378e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1832, Task: 1, loss: 0.00009\n",
            "tensor(9.4012e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1832, Task: 2, loss: 0.00009\n",
            "tensor(9.4188e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1832, Task: 3, loss: 0.00009\n",
            "tensor(9.4119e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1832, Task: 4, loss: 0.00009\n",
            "tensor(9.4421e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1832, Task: 5, loss: 0.00009\n",
            "tensor(2.1298e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1832, Task: 6, loss: 0.00002\n",
            "tensor(7.3222e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1832, Task: 7, loss: 0.00001\n",
            "tensor(7.1044e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1832, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0982e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1833, Task: 0, loss: 0.00009\n",
            "tensor(9.4372e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1833, Task: 1, loss: 0.00009\n",
            "tensor(9.4006e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1833, Task: 2, loss: 0.00009\n",
            "tensor(9.4182e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1833, Task: 3, loss: 0.00009\n",
            "tensor(9.4113e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1833, Task: 4, loss: 0.00009\n",
            "tensor(9.4415e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1833, Task: 5, loss: 0.00009\n",
            "tensor(2.1299e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1833, Task: 6, loss: 0.00002\n",
            "tensor(7.3239e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1833, Task: 7, loss: 0.00001\n",
            "tensor(7.1063e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1833, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0975e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1834, Task: 0, loss: 0.00009\n",
            "tensor(9.4365e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1834, Task: 1, loss: 0.00009\n",
            "tensor(9.4000e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1834, Task: 2, loss: 0.00009\n",
            "tensor(9.4176e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1834, Task: 3, loss: 0.00009\n",
            "tensor(9.4107e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1834, Task: 4, loss: 0.00009\n",
            "tensor(9.4409e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1834, Task: 5, loss: 0.00009\n",
            "tensor(2.1299e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1834, Task: 6, loss: 0.00002\n",
            "tensor(7.3256e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1834, Task: 7, loss: 0.00001\n",
            "tensor(7.1082e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1834, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0968e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1835, Task: 0, loss: 0.00009\n",
            "tensor(9.4359e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1835, Task: 1, loss: 0.00009\n",
            "tensor(9.3994e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1835, Task: 2, loss: 0.00009\n",
            "tensor(9.4170e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1835, Task: 3, loss: 0.00009\n",
            "tensor(9.4101e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1835, Task: 4, loss: 0.00009\n",
            "tensor(9.4403e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1835, Task: 5, loss: 0.00009\n",
            "tensor(2.1299e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1835, Task: 6, loss: 0.00002\n",
            "tensor(7.3271e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1835, Task: 7, loss: 0.00001\n",
            "tensor(7.1100e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1835, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0961e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1836, Task: 0, loss: 0.00009\n",
            "tensor(9.4353e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1836, Task: 1, loss: 0.00009\n",
            "tensor(9.3987e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1836, Task: 2, loss: 0.00009\n",
            "tensor(9.4164e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1836, Task: 3, loss: 0.00009\n",
            "tensor(9.4095e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1836, Task: 4, loss: 0.00009\n",
            "tensor(9.4397e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1836, Task: 5, loss: 0.00009\n",
            "tensor(2.1299e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1836, Task: 6, loss: 0.00002\n",
            "tensor(7.3287e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1836, Task: 7, loss: 0.00001\n",
            "tensor(7.1119e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1836, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0954e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1837, Task: 0, loss: 0.00009\n",
            "tensor(9.4347e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1837, Task: 1, loss: 0.00009\n",
            "tensor(9.3981e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1837, Task: 2, loss: 0.00009\n",
            "tensor(9.4158e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1837, Task: 3, loss: 0.00009\n",
            "tensor(9.4089e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1837, Task: 4, loss: 0.00009\n",
            "tensor(9.4391e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1837, Task: 5, loss: 0.00009\n",
            "tensor(2.1300e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1837, Task: 6, loss: 0.00002\n",
            "tensor(7.3303e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1837, Task: 7, loss: 0.00001\n",
            "tensor(7.1138e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1837, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0947e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1838, Task: 0, loss: 0.00009\n",
            "tensor(9.4341e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1838, Task: 1, loss: 0.00009\n",
            "tensor(9.3975e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1838, Task: 2, loss: 0.00009\n",
            "tensor(9.4152e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1838, Task: 3, loss: 0.00009\n",
            "tensor(9.4083e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1838, Task: 4, loss: 0.00009\n",
            "tensor(9.4385e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1838, Task: 5, loss: 0.00009\n",
            "tensor(2.1300e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1838, Task: 6, loss: 0.00002\n",
            "tensor(7.3319e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1838, Task: 7, loss: 0.00001\n",
            "tensor(7.1156e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1838, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0940e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1839, Task: 0, loss: 0.00009\n",
            "tensor(9.4335e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1839, Task: 1, loss: 0.00009\n",
            "tensor(9.3969e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1839, Task: 2, loss: 0.00009\n",
            "tensor(9.4146e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1839, Task: 3, loss: 0.00009\n",
            "tensor(9.4077e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1839, Task: 4, loss: 0.00009\n",
            "tensor(9.4378e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1839, Task: 5, loss: 0.00009\n",
            "tensor(2.1300e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1839, Task: 6, loss: 0.00002\n",
            "tensor(7.3336e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1839, Task: 7, loss: 0.00001\n",
            "tensor(7.1175e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1839, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0933e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1840, Task: 0, loss: 0.00009\n",
            "tensor(9.4329e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1840, Task: 1, loss: 0.00009\n",
            "tensor(9.3963e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1840, Task: 2, loss: 0.00009\n",
            "tensor(9.4139e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1840, Task: 3, loss: 0.00009\n",
            "tensor(9.4070e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1840, Task: 4, loss: 0.00009\n",
            "tensor(9.4372e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1840, Task: 5, loss: 0.00009\n",
            "tensor(2.1300e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1840, Task: 6, loss: 0.00002\n",
            "tensor(7.3352e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1840, Task: 7, loss: 0.00001\n",
            "tensor(7.1194e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1840, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0926e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1841, Task: 0, loss: 0.00009\n",
            "tensor(9.4322e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1841, Task: 1, loss: 0.00009\n",
            "tensor(9.3957e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1841, Task: 2, loss: 0.00009\n",
            "tensor(9.4133e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1841, Task: 3, loss: 0.00009\n",
            "tensor(9.4064e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1841, Task: 4, loss: 0.00009\n",
            "tensor(9.4366e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1841, Task: 5, loss: 0.00009\n",
            "tensor(2.1301e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1841, Task: 6, loss: 0.00002\n",
            "tensor(7.3369e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1841, Task: 7, loss: 0.00001\n",
            "tensor(7.1213e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1841, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0919e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1842, Task: 0, loss: 0.00009\n",
            "tensor(9.4316e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1842, Task: 1, loss: 0.00009\n",
            "tensor(9.3950e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1842, Task: 2, loss: 0.00009\n",
            "tensor(9.4127e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1842, Task: 3, loss: 0.00009\n",
            "tensor(9.4058e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1842, Task: 4, loss: 0.00009\n",
            "tensor(9.4360e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1842, Task: 5, loss: 0.00009\n",
            "tensor(2.1301e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1842, Task: 6, loss: 0.00002\n",
            "tensor(7.3384e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1842, Task: 7, loss: 0.00001\n",
            "tensor(7.1232e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1842, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0912e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1843, Task: 0, loss: 0.00009\n",
            "tensor(9.4310e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1843, Task: 1, loss: 0.00009\n",
            "tensor(9.3944e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1843, Task: 2, loss: 0.00009\n",
            "tensor(9.4121e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1843, Task: 3, loss: 0.00009\n",
            "tensor(9.4052e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1843, Task: 4, loss: 0.00009\n",
            "tensor(9.4353e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1843, Task: 5, loss: 0.00009\n",
            "tensor(2.1301e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1843, Task: 6, loss: 0.00002\n",
            "tensor(7.3401e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1843, Task: 7, loss: 0.00001\n",
            "tensor(7.1251e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1843, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0905e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1844, Task: 0, loss: 0.00009\n",
            "tensor(9.4304e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1844, Task: 1, loss: 0.00009\n",
            "tensor(9.3938e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1844, Task: 2, loss: 0.00009\n",
            "tensor(9.4114e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1844, Task: 3, loss: 0.00009\n",
            "tensor(9.4045e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1844, Task: 4, loss: 0.00009\n",
            "tensor(9.4347e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1844, Task: 5, loss: 0.00009\n",
            "tensor(2.1301e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1844, Task: 6, loss: 0.00002\n",
            "tensor(7.3418e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1844, Task: 7, loss: 0.00001\n",
            "tensor(7.1270e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1844, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0898e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1845, Task: 0, loss: 0.00009\n",
            "tensor(9.4297e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1845, Task: 1, loss: 0.00009\n",
            "tensor(9.3932e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1845, Task: 2, loss: 0.00009\n",
            "tensor(9.4108e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1845, Task: 3, loss: 0.00009\n",
            "tensor(9.4039e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1845, Task: 4, loss: 0.00009\n",
            "tensor(9.4341e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1845, Task: 5, loss: 0.00009\n",
            "tensor(2.1302e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1845, Task: 6, loss: 0.00002\n",
            "tensor(7.3436e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1845, Task: 7, loss: 0.00001\n",
            "tensor(7.1290e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1845, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0891e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1846, Task: 0, loss: 0.00009\n",
            "tensor(9.4291e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1846, Task: 1, loss: 0.00009\n",
            "tensor(9.3925e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1846, Task: 2, loss: 0.00009\n",
            "tensor(9.4102e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1846, Task: 3, loss: 0.00009\n",
            "tensor(9.4033e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1846, Task: 4, loss: 0.00009\n",
            "tensor(9.4335e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1846, Task: 5, loss: 0.00009\n",
            "tensor(2.1302e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1846, Task: 6, loss: 0.00002\n",
            "tensor(7.3454e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1846, Task: 7, loss: 0.00001\n",
            "tensor(7.1309e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1846, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0884e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1847, Task: 0, loss: 0.00009\n",
            "tensor(9.4285e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1847, Task: 1, loss: 0.00009\n",
            "tensor(9.3919e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1847, Task: 2, loss: 0.00009\n",
            "tensor(9.4096e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1847, Task: 3, loss: 0.00009\n",
            "tensor(9.4027e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1847, Task: 4, loss: 0.00009\n",
            "tensor(9.4328e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1847, Task: 5, loss: 0.00009\n",
            "tensor(2.1303e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1847, Task: 6, loss: 0.00002\n",
            "tensor(7.3472e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1847, Task: 7, loss: 0.00001\n",
            "tensor(7.1329e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1847, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0877e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1848, Task: 0, loss: 0.00009\n",
            "tensor(9.4278e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1848, Task: 1, loss: 0.00009\n",
            "tensor(9.3913e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1848, Task: 2, loss: 0.00009\n",
            "tensor(9.4089e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1848, Task: 3, loss: 0.00009\n",
            "tensor(9.4020e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1848, Task: 4, loss: 0.00009\n",
            "tensor(9.4322e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1848, Task: 5, loss: 0.00009\n",
            "tensor(2.1303e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1848, Task: 6, loss: 0.00002\n",
            "tensor(7.3489e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1848, Task: 7, loss: 0.00001\n",
            "tensor(7.1348e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1848, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0870e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1849, Task: 0, loss: 0.00009\n",
            "tensor(9.4272e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1849, Task: 1, loss: 0.00009\n",
            "tensor(9.3906e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1849, Task: 2, loss: 0.00009\n",
            "tensor(9.4083e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1849, Task: 3, loss: 0.00009\n",
            "tensor(9.4014e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1849, Task: 4, loss: 0.00009\n",
            "tensor(9.4316e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1849, Task: 5, loss: 0.00009\n",
            "tensor(2.1303e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1849, Task: 6, loss: 0.00002\n",
            "tensor(7.3506e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1849, Task: 7, loss: 0.00001\n",
            "tensor(7.1368e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1849, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0863e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1850, Task: 0, loss: 0.00009\n",
            "tensor(9.4266e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1850, Task: 1, loss: 0.00009\n",
            "tensor(9.3900e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1850, Task: 2, loss: 0.00009\n",
            "tensor(9.4077e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1850, Task: 3, loss: 0.00009\n",
            "tensor(9.4008e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1850, Task: 4, loss: 0.00009\n",
            "tensor(9.4309e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1850, Task: 5, loss: 0.00009\n",
            "tensor(2.1303e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1850, Task: 6, loss: 0.00002\n",
            "tensor(7.3523e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1850, Task: 7, loss: 0.00001\n",
            "tensor(7.1387e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1850, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0856e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1851, Task: 0, loss: 0.00009\n",
            "tensor(9.4259e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1851, Task: 1, loss: 0.00009\n",
            "tensor(9.3894e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1851, Task: 2, loss: 0.00009\n",
            "tensor(9.4070e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1851, Task: 3, loss: 0.00009\n",
            "tensor(9.4001e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1851, Task: 4, loss: 0.00009\n",
            "tensor(9.4303e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1851, Task: 5, loss: 0.00009\n",
            "tensor(2.1304e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1851, Task: 6, loss: 0.00002\n",
            "tensor(7.3539e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1851, Task: 7, loss: 0.00001\n",
            "tensor(7.1407e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1851, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0849e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1852, Task: 0, loss: 0.00009\n",
            "tensor(9.4253e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1852, Task: 1, loss: 0.00009\n",
            "tensor(9.3887e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1852, Task: 2, loss: 0.00009\n",
            "tensor(9.4064e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1852, Task: 3, loss: 0.00009\n",
            "tensor(9.3995e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1852, Task: 4, loss: 0.00009\n",
            "tensor(9.4296e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1852, Task: 5, loss: 0.00009\n",
            "tensor(2.1304e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1852, Task: 6, loss: 0.00002\n",
            "tensor(7.3556e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1852, Task: 7, loss: 0.00001\n",
            "tensor(7.1426e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1852, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0842e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1853, Task: 0, loss: 0.00009\n",
            "tensor(9.4246e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1853, Task: 1, loss: 0.00009\n",
            "tensor(9.3881e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1853, Task: 2, loss: 0.00009\n",
            "tensor(9.4057e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1853, Task: 3, loss: 0.00009\n",
            "tensor(9.3988e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1853, Task: 4, loss: 0.00009\n",
            "tensor(9.4290e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1853, Task: 5, loss: 0.00009\n",
            "tensor(2.1304e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1853, Task: 6, loss: 0.00002\n",
            "tensor(7.3573e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1853, Task: 7, loss: 0.00001\n",
            "tensor(7.1446e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1853, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0835e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1854, Task: 0, loss: 0.00009\n",
            "tensor(9.4240e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1854, Task: 1, loss: 0.00009\n",
            "tensor(9.3874e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1854, Task: 2, loss: 0.00009\n",
            "tensor(9.4051e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1854, Task: 3, loss: 0.00009\n",
            "tensor(9.3982e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1854, Task: 4, loss: 0.00009\n",
            "tensor(9.4284e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1854, Task: 5, loss: 0.00009\n",
            "tensor(2.1304e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1854, Task: 6, loss: 0.00002\n",
            "tensor(7.3590e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1854, Task: 7, loss: 0.00001\n",
            "tensor(7.1465e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1854, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0828e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1855, Task: 0, loss: 0.00009\n",
            "tensor(9.4233e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1855, Task: 1, loss: 0.00009\n",
            "tensor(9.3868e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1855, Task: 2, loss: 0.00009\n",
            "tensor(9.4045e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1855, Task: 3, loss: 0.00009\n",
            "tensor(9.3976e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1855, Task: 4, loss: 0.00009\n",
            "tensor(9.4277e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1855, Task: 5, loss: 0.00009\n",
            "tensor(2.1305e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1855, Task: 6, loss: 0.00002\n",
            "tensor(7.3606e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1855, Task: 7, loss: 0.00001\n",
            "tensor(7.1485e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1855, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0821e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1856, Task: 0, loss: 0.00009\n",
            "tensor(9.4227e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1856, Task: 1, loss: 0.00009\n",
            "tensor(9.3862e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1856, Task: 2, loss: 0.00009\n",
            "tensor(9.4038e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1856, Task: 3, loss: 0.00009\n",
            "tensor(9.3969e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1856, Task: 4, loss: 0.00009\n",
            "tensor(9.4271e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1856, Task: 5, loss: 0.00009\n",
            "tensor(2.1305e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1856, Task: 6, loss: 0.00002\n",
            "tensor(7.3624e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1856, Task: 7, loss: 0.00001\n",
            "tensor(7.1505e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1856, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0814e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1857, Task: 0, loss: 0.00009\n",
            "tensor(9.4221e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1857, Task: 1, loss: 0.00009\n",
            "tensor(9.3855e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1857, Task: 2, loss: 0.00009\n",
            "tensor(9.4032e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1857, Task: 3, loss: 0.00009\n",
            "tensor(9.3963e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1857, Task: 4, loss: 0.00009\n",
            "tensor(9.4264e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1857, Task: 5, loss: 0.00009\n",
            "tensor(2.1305e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1857, Task: 6, loss: 0.00002\n",
            "tensor(7.3642e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1857, Task: 7, loss: 0.00001\n",
            "tensor(7.1525e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1857, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0807e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1858, Task: 0, loss: 0.00009\n",
            "tensor(9.4214e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1858, Task: 1, loss: 0.00009\n",
            "tensor(9.3849e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1858, Task: 2, loss: 0.00009\n",
            "tensor(9.4025e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1858, Task: 3, loss: 0.00009\n",
            "tensor(9.3956e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1858, Task: 4, loss: 0.00009\n",
            "tensor(9.4258e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1858, Task: 5, loss: 0.00009\n",
            "tensor(2.1306e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1858, Task: 6, loss: 0.00002\n",
            "tensor(7.3659e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1858, Task: 7, loss: 0.00001\n",
            "tensor(7.1545e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1858, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0800e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1859, Task: 0, loss: 0.00009\n",
            "tensor(9.4208e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1859, Task: 1, loss: 0.00009\n",
            "tensor(9.3842e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1859, Task: 2, loss: 0.00009\n",
            "tensor(9.4019e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1859, Task: 3, loss: 0.00009\n",
            "tensor(9.3950e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1859, Task: 4, loss: 0.00009\n",
            "tensor(9.4251e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1859, Task: 5, loss: 0.00009\n",
            "tensor(2.1306e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1859, Task: 6, loss: 0.00002\n",
            "tensor(7.3678e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1859, Task: 7, loss: 0.00001\n",
            "tensor(7.1565e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1859, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0793e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1860, Task: 0, loss: 0.00009\n",
            "tensor(9.4201e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1860, Task: 1, loss: 0.00009\n",
            "tensor(9.3836e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1860, Task: 2, loss: 0.00009\n",
            "tensor(9.4012e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1860, Task: 3, loss: 0.00009\n",
            "tensor(9.3943e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1860, Task: 4, loss: 0.00009\n",
            "tensor(9.4245e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1860, Task: 5, loss: 0.00009\n",
            "tensor(2.1306e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1860, Task: 6, loss: 0.00002\n",
            "tensor(7.3697e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1860, Task: 7, loss: 0.00001\n",
            "tensor(7.1585e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1860, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0786e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1861, Task: 0, loss: 0.00009\n",
            "tensor(9.4195e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1861, Task: 1, loss: 0.00009\n",
            "tensor(9.3829e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1861, Task: 2, loss: 0.00009\n",
            "tensor(9.4006e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1861, Task: 3, loss: 0.00009\n",
            "tensor(9.3937e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1861, Task: 4, loss: 0.00009\n",
            "tensor(9.4238e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1861, Task: 5, loss: 0.00009\n",
            "tensor(2.1307e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1861, Task: 6, loss: 0.00002\n",
            "tensor(7.3716e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1861, Task: 7, loss: 0.00001\n",
            "tensor(7.1605e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1861, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0779e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1862, Task: 0, loss: 0.00009\n",
            "tensor(9.4188e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1862, Task: 1, loss: 0.00009\n",
            "tensor(9.3823e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1862, Task: 2, loss: 0.00009\n",
            "tensor(9.3999e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1862, Task: 3, loss: 0.00009\n",
            "tensor(9.3930e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1862, Task: 4, loss: 0.00009\n",
            "tensor(9.4232e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1862, Task: 5, loss: 0.00009\n",
            "tensor(2.1307e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1862, Task: 6, loss: 0.00002\n",
            "tensor(7.3733e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1862, Task: 7, loss: 0.00001\n",
            "tensor(7.1626e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1862, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0772e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1863, Task: 0, loss: 0.00009\n",
            "tensor(9.4181e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1863, Task: 1, loss: 0.00009\n",
            "tensor(9.3816e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1863, Task: 2, loss: 0.00009\n",
            "tensor(9.3992e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1863, Task: 3, loss: 0.00009\n",
            "tensor(9.3923e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1863, Task: 4, loss: 0.00009\n",
            "tensor(9.4225e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1863, Task: 5, loss: 0.00009\n",
            "tensor(2.1308e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1863, Task: 6, loss: 0.00002\n",
            "tensor(7.3751e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1863, Task: 7, loss: 0.00001\n",
            "tensor(7.1646e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1863, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0765e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1864, Task: 0, loss: 0.00009\n",
            "tensor(9.4175e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1864, Task: 1, loss: 0.00009\n",
            "tensor(9.3809e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1864, Task: 2, loss: 0.00009\n",
            "tensor(9.3986e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1864, Task: 3, loss: 0.00009\n",
            "tensor(9.3917e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1864, Task: 4, loss: 0.00009\n",
            "tensor(9.4218e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1864, Task: 5, loss: 0.00009\n",
            "tensor(2.1308e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1864, Task: 6, loss: 0.00002\n",
            "tensor(7.3768e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1864, Task: 7, loss: 0.00001\n",
            "tensor(7.1666e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1864, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0758e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1865, Task: 0, loss: 0.00009\n",
            "tensor(9.4168e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1865, Task: 1, loss: 0.00009\n",
            "tensor(9.3803e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1865, Task: 2, loss: 0.00009\n",
            "tensor(9.3979e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1865, Task: 3, loss: 0.00009\n",
            "tensor(9.3910e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1865, Task: 4, loss: 0.00009\n",
            "tensor(9.4212e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1865, Task: 5, loss: 0.00009\n",
            "tensor(2.1308e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1865, Task: 6, loss: 0.00002\n",
            "tensor(7.3784e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1865, Task: 7, loss: 0.00001\n",
            "tensor(7.1686e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1865, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0751e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1866, Task: 0, loss: 0.00009\n",
            "tensor(9.4162e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1866, Task: 1, loss: 0.00009\n",
            "tensor(9.3796e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1866, Task: 2, loss: 0.00009\n",
            "tensor(9.3973e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1866, Task: 3, loss: 0.00009\n",
            "tensor(9.3904e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1866, Task: 4, loss: 0.00009\n",
            "tensor(9.4205e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1866, Task: 5, loss: 0.00009\n",
            "tensor(2.1308e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1866, Task: 6, loss: 0.00002\n",
            "tensor(7.3802e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1866, Task: 7, loss: 0.00001\n",
            "tensor(7.1706e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1866, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0744e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1867, Task: 0, loss: 0.00009\n",
            "tensor(9.4155e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1867, Task: 1, loss: 0.00009\n",
            "tensor(9.3789e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1867, Task: 2, loss: 0.00009\n",
            "tensor(9.3966e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1867, Task: 3, loss: 0.00009\n",
            "tensor(9.3897e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1867, Task: 4, loss: 0.00009\n",
            "tensor(9.4198e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1867, Task: 5, loss: 0.00009\n",
            "tensor(2.1308e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1867, Task: 6, loss: 0.00002\n",
            "tensor(7.3820e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1867, Task: 7, loss: 0.00001\n",
            "tensor(7.1727e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1867, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0737e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1868, Task: 0, loss: 0.00009\n",
            "tensor(9.4148e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1868, Task: 1, loss: 0.00009\n",
            "tensor(9.3783e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1868, Task: 2, loss: 0.00009\n",
            "tensor(9.3959e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1868, Task: 3, loss: 0.00009\n",
            "tensor(9.3890e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1868, Task: 4, loss: 0.00009\n",
            "tensor(9.4192e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1868, Task: 5, loss: 0.00009\n",
            "tensor(2.1309e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1868, Task: 6, loss: 0.00002\n",
            "tensor(7.3838e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1868, Task: 7, loss: 0.00001\n",
            "tensor(7.1747e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1868, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0730e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1869, Task: 0, loss: 0.00009\n",
            "tensor(9.4142e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1869, Task: 1, loss: 0.00009\n",
            "tensor(9.3776e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1869, Task: 2, loss: 0.00009\n",
            "tensor(9.3953e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1869, Task: 3, loss: 0.00009\n",
            "tensor(9.3884e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1869, Task: 4, loss: 0.00009\n",
            "tensor(9.4185e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1869, Task: 5, loss: 0.00009\n",
            "tensor(2.1309e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1869, Task: 6, loss: 0.00002\n",
            "tensor(7.3856e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1869, Task: 7, loss: 0.00001\n",
            "tensor(7.1768e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1869, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0723e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1870, Task: 0, loss: 0.00009\n",
            "tensor(9.4135e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1870, Task: 1, loss: 0.00009\n",
            "tensor(9.3770e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1870, Task: 2, loss: 0.00009\n",
            "tensor(9.3946e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1870, Task: 3, loss: 0.00009\n",
            "tensor(9.3877e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1870, Task: 4, loss: 0.00009\n",
            "tensor(9.4178e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1870, Task: 5, loss: 0.00009\n",
            "tensor(2.1309e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1870, Task: 6, loss: 0.00002\n",
            "tensor(7.3875e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1870, Task: 7, loss: 0.00001\n",
            "tensor(7.1788e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1870, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0716e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1871, Task: 0, loss: 0.00009\n",
            "tensor(9.4128e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1871, Task: 1, loss: 0.00009\n",
            "tensor(9.3763e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1871, Task: 2, loss: 0.00009\n",
            "tensor(9.3939e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1871, Task: 3, loss: 0.00009\n",
            "tensor(9.3870e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1871, Task: 4, loss: 0.00009\n",
            "tensor(9.4172e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1871, Task: 5, loss: 0.00009\n",
            "tensor(2.1310e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1871, Task: 6, loss: 0.00002\n",
            "tensor(7.3892e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1871, Task: 7, loss: 0.00001\n",
            "tensor(7.1809e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1871, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0709e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1872, Task: 0, loss: 0.00009\n",
            "tensor(9.4121e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1872, Task: 1, loss: 0.00009\n",
            "tensor(9.3756e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1872, Task: 2, loss: 0.00009\n",
            "tensor(9.3933e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1872, Task: 3, loss: 0.00009\n",
            "tensor(9.3864e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1872, Task: 4, loss: 0.00009\n",
            "tensor(9.4165e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1872, Task: 5, loss: 0.00009\n",
            "tensor(2.1310e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1872, Task: 6, loss: 0.00002\n",
            "tensor(7.3911e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1872, Task: 7, loss: 0.00001\n",
            "tensor(7.1830e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1872, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0702e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1873, Task: 0, loss: 0.00009\n",
            "tensor(9.4115e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1873, Task: 1, loss: 0.00009\n",
            "tensor(9.3749e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1873, Task: 2, loss: 0.00009\n",
            "tensor(9.3926e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1873, Task: 3, loss: 0.00009\n",
            "tensor(9.3857e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1873, Task: 4, loss: 0.00009\n",
            "tensor(9.4158e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1873, Task: 5, loss: 0.00009\n",
            "tensor(2.1310e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1873, Task: 6, loss: 0.00002\n",
            "tensor(7.3930e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1873, Task: 7, loss: 0.00001\n",
            "tensor(7.1851e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1873, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0695e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1874, Task: 0, loss: 0.00009\n",
            "tensor(9.4108e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1874, Task: 1, loss: 0.00009\n",
            "tensor(9.3743e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1874, Task: 2, loss: 0.00009\n",
            "tensor(9.3919e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1874, Task: 3, loss: 0.00009\n",
            "tensor(9.3850e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1874, Task: 4, loss: 0.00009\n",
            "tensor(9.4152e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1874, Task: 5, loss: 0.00009\n",
            "tensor(2.1311e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1874, Task: 6, loss: 0.00002\n",
            "tensor(7.3949e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1874, Task: 7, loss: 0.00001\n",
            "tensor(7.1871e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1874, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0688e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1875, Task: 0, loss: 0.00009\n",
            "tensor(9.4101e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1875, Task: 1, loss: 0.00009\n",
            "tensor(9.3736e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1875, Task: 2, loss: 0.00009\n",
            "tensor(9.3912e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1875, Task: 3, loss: 0.00009\n",
            "tensor(9.3843e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1875, Task: 4, loss: 0.00009\n",
            "tensor(9.4145e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1875, Task: 5, loss: 0.00009\n",
            "tensor(2.1311e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1875, Task: 6, loss: 0.00002\n",
            "tensor(7.3968e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1875, Task: 7, loss: 0.00001\n",
            "tensor(7.1892e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1875, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0681e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1876, Task: 0, loss: 0.00009\n",
            "tensor(9.4095e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1876, Task: 1, loss: 0.00009\n",
            "tensor(9.3729e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1876, Task: 2, loss: 0.00009\n",
            "tensor(9.3906e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1876, Task: 3, loss: 0.00009\n",
            "tensor(9.3837e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1876, Task: 4, loss: 0.00009\n",
            "tensor(9.4138e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1876, Task: 5, loss: 0.00009\n",
            "tensor(2.1311e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1876, Task: 6, loss: 0.00002\n",
            "tensor(7.3987e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1876, Task: 7, loss: 0.00001\n",
            "tensor(7.1913e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1876, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0674e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1877, Task: 0, loss: 0.00009\n",
            "tensor(9.4088e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1877, Task: 1, loss: 0.00009\n",
            "tensor(9.3722e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1877, Task: 2, loss: 0.00009\n",
            "tensor(9.3899e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1877, Task: 3, loss: 0.00009\n",
            "tensor(9.3830e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1877, Task: 4, loss: 0.00009\n",
            "tensor(9.4131e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1877, Task: 5, loss: 0.00009\n",
            "tensor(2.1312e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1877, Task: 6, loss: 0.00002\n",
            "tensor(7.4005e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1877, Task: 7, loss: 0.00001\n",
            "tensor(7.1934e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1877, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0666e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1878, Task: 0, loss: 0.00009\n",
            "tensor(9.4081e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1878, Task: 1, loss: 0.00009\n",
            "tensor(9.3716e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1878, Task: 2, loss: 0.00009\n",
            "tensor(9.3892e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1878, Task: 3, loss: 0.00009\n",
            "tensor(9.3823e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1878, Task: 4, loss: 0.00009\n",
            "tensor(9.4124e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1878, Task: 5, loss: 0.00009\n",
            "tensor(2.1312e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1878, Task: 6, loss: 0.00002\n",
            "tensor(7.4024e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1878, Task: 7, loss: 0.00001\n",
            "tensor(7.1955e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1878, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0659e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1879, Task: 0, loss: 0.00009\n",
            "tensor(9.4074e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1879, Task: 1, loss: 0.00009\n",
            "tensor(9.3709e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1879, Task: 2, loss: 0.00009\n",
            "tensor(9.3885e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1879, Task: 3, loss: 0.00009\n",
            "tensor(9.3816e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1879, Task: 4, loss: 0.00009\n",
            "tensor(9.4118e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1879, Task: 5, loss: 0.00009\n",
            "tensor(2.1312e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1879, Task: 6, loss: 0.00002\n",
            "tensor(7.4042e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1879, Task: 7, loss: 0.00001\n",
            "tensor(7.1976e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1879, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0652e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1880, Task: 0, loss: 0.00009\n",
            "tensor(9.4067e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1880, Task: 1, loss: 0.00009\n",
            "tensor(9.3702e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1880, Task: 2, loss: 0.00009\n",
            "tensor(9.3878e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1880, Task: 3, loss: 0.00009\n",
            "tensor(9.3809e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1880, Task: 4, loss: 0.00009\n",
            "tensor(9.4111e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1880, Task: 5, loss: 0.00009\n",
            "tensor(2.1313e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1880, Task: 6, loss: 0.00002\n",
            "tensor(7.4061e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1880, Task: 7, loss: 0.00001\n",
            "tensor(7.1997e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1880, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0645e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1881, Task: 0, loss: 0.00009\n",
            "tensor(9.4060e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1881, Task: 1, loss: 0.00009\n",
            "tensor(9.3695e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1881, Task: 2, loss: 0.00009\n",
            "tensor(9.3872e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1881, Task: 3, loss: 0.00009\n",
            "tensor(9.3803e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1881, Task: 4, loss: 0.00009\n",
            "tensor(9.4104e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1881, Task: 5, loss: 0.00009\n",
            "tensor(2.1313e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1881, Task: 6, loss: 0.00002\n",
            "tensor(7.4080e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1881, Task: 7, loss: 0.00001\n",
            "tensor(7.2018e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1881, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0638e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1882, Task: 0, loss: 0.00009\n",
            "tensor(9.4054e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1882, Task: 1, loss: 0.00009\n",
            "tensor(9.3688e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1882, Task: 2, loss: 0.00009\n",
            "tensor(9.3865e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1882, Task: 3, loss: 0.00009\n",
            "tensor(9.3796e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1882, Task: 4, loss: 0.00009\n",
            "tensor(9.4097e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1882, Task: 5, loss: 0.00009\n",
            "tensor(2.1313e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1882, Task: 6, loss: 0.00002\n",
            "tensor(7.4098e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1882, Task: 7, loss: 0.00001\n",
            "tensor(7.2039e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1882, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0631e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1883, Task: 0, loss: 0.00009\n",
            "tensor(9.4047e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1883, Task: 1, loss: 0.00009\n",
            "tensor(9.3681e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1883, Task: 2, loss: 0.00009\n",
            "tensor(9.3858e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1883, Task: 3, loss: 0.00009\n",
            "tensor(9.3789e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1883, Task: 4, loss: 0.00009\n",
            "tensor(9.4090e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1883, Task: 5, loss: 0.00009\n",
            "tensor(2.1313e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1883, Task: 6, loss: 0.00002\n",
            "tensor(7.4117e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1883, Task: 7, loss: 0.00001\n",
            "tensor(7.2060e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1883, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0624e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1884, Task: 0, loss: 0.00009\n",
            "tensor(9.4040e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1884, Task: 1, loss: 0.00009\n",
            "tensor(9.3675e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1884, Task: 2, loss: 0.00009\n",
            "tensor(9.3851e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1884, Task: 3, loss: 0.00009\n",
            "tensor(9.3782e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1884, Task: 4, loss: 0.00009\n",
            "tensor(9.4083e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1884, Task: 5, loss: 0.00009\n",
            "tensor(2.1314e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1884, Task: 6, loss: 0.00002\n",
            "tensor(7.4135e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1884, Task: 7, loss: 0.00001\n",
            "tensor(7.2082e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1884, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0617e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1885, Task: 0, loss: 0.00009\n",
            "tensor(9.4033e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1885, Task: 1, loss: 0.00009\n",
            "tensor(9.3668e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1885, Task: 2, loss: 0.00009\n",
            "tensor(9.3844e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1885, Task: 3, loss: 0.00009\n",
            "tensor(9.3775e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1885, Task: 4, loss: 0.00009\n",
            "tensor(9.4076e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1885, Task: 5, loss: 0.00009\n",
            "tensor(2.1314e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1885, Task: 6, loss: 0.00002\n",
            "tensor(7.4154e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1885, Task: 7, loss: 0.00001\n",
            "tensor(7.2103e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1885, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0610e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1886, Task: 0, loss: 0.00009\n",
            "tensor(9.4026e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1886, Task: 1, loss: 0.00009\n",
            "tensor(9.3661e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1886, Task: 2, loss: 0.00009\n",
            "tensor(9.3837e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1886, Task: 3, loss: 0.00009\n",
            "tensor(9.3768e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1886, Task: 4, loss: 0.00009\n",
            "tensor(9.4069e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1886, Task: 5, loss: 0.00009\n",
            "tensor(2.1314e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1886, Task: 6, loss: 0.00002\n",
            "tensor(7.4173e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1886, Task: 7, loss: 0.00001\n",
            "tensor(7.2124e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1886, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0603e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1887, Task: 0, loss: 0.00009\n",
            "tensor(9.4019e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1887, Task: 1, loss: 0.00009\n",
            "tensor(9.3654e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1887, Task: 2, loss: 0.00009\n",
            "tensor(9.3830e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1887, Task: 3, loss: 0.00009\n",
            "tensor(9.3761e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1887, Task: 4, loss: 0.00009\n",
            "tensor(9.4063e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1887, Task: 5, loss: 0.00009\n",
            "tensor(2.1315e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1887, Task: 6, loss: 0.00002\n",
            "tensor(7.4192e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1887, Task: 7, loss: 0.00001\n",
            "tensor(7.2146e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1887, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0596e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1888, Task: 0, loss: 0.00009\n",
            "tensor(9.4012e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1888, Task: 1, loss: 0.00009\n",
            "tensor(9.3647e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1888, Task: 2, loss: 0.00009\n",
            "tensor(9.3823e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1888, Task: 3, loss: 0.00009\n",
            "tensor(9.3754e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1888, Task: 4, loss: 0.00009\n",
            "tensor(9.4056e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1888, Task: 5, loss: 0.00009\n",
            "tensor(2.1315e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1888, Task: 6, loss: 0.00002\n",
            "tensor(7.4212e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1888, Task: 7, loss: 0.00001\n",
            "tensor(7.2167e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1888, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0589e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1889, Task: 0, loss: 0.00009\n",
            "tensor(9.4005e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1889, Task: 1, loss: 0.00009\n",
            "tensor(9.3640e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1889, Task: 2, loss: 0.00009\n",
            "tensor(9.3816e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1889, Task: 3, loss: 0.00009\n",
            "tensor(9.3747e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1889, Task: 4, loss: 0.00009\n",
            "tensor(9.4049e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1889, Task: 5, loss: 0.00009\n",
            "tensor(2.1315e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1889, Task: 6, loss: 0.00002\n",
            "tensor(7.4230e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1889, Task: 7, loss: 0.00001\n",
            "tensor(7.2189e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1889, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0582e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1890, Task: 0, loss: 0.00009\n",
            "tensor(9.3998e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1890, Task: 1, loss: 0.00009\n",
            "tensor(9.3633e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1890, Task: 2, loss: 0.00009\n",
            "tensor(9.3809e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1890, Task: 3, loss: 0.00009\n",
            "tensor(9.3740e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1890, Task: 4, loss: 0.00009\n",
            "tensor(9.4042e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1890, Task: 5, loss: 0.00009\n",
            "tensor(2.1316e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1890, Task: 6, loss: 0.00002\n",
            "tensor(7.4249e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1890, Task: 7, loss: 0.00001\n",
            "tensor(7.2210e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1890, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0575e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1891, Task: 0, loss: 0.00009\n",
            "tensor(9.3991e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1891, Task: 1, loss: 0.00009\n",
            "tensor(9.3626e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1891, Task: 2, loss: 0.00009\n",
            "tensor(9.3802e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1891, Task: 3, loss: 0.00009\n",
            "tensor(9.3733e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1891, Task: 4, loss: 0.00009\n",
            "tensor(9.4035e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1891, Task: 5, loss: 0.00009\n",
            "tensor(2.1316e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1891, Task: 6, loss: 0.00002\n",
            "tensor(7.4269e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1891, Task: 7, loss: 0.00001\n",
            "tensor(7.2232e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1891, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0568e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1892, Task: 0, loss: 0.00009\n",
            "tensor(9.3984e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1892, Task: 1, loss: 0.00009\n",
            "tensor(9.3619e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1892, Task: 2, loss: 0.00009\n",
            "tensor(9.3795e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1892, Task: 3, loss: 0.00009\n",
            "tensor(9.3726e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1892, Task: 4, loss: 0.00009\n",
            "tensor(9.4028e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1892, Task: 5, loss: 0.00009\n",
            "tensor(2.1317e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1892, Task: 6, loss: 0.00002\n",
            "tensor(7.4290e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1892, Task: 7, loss: 0.00001\n",
            "tensor(7.2254e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1892, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0561e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1893, Task: 0, loss: 0.00009\n",
            "tensor(9.3977e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1893, Task: 1, loss: 0.00009\n",
            "tensor(9.3612e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1893, Task: 2, loss: 0.00009\n",
            "tensor(9.3788e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1893, Task: 3, loss: 0.00009\n",
            "tensor(9.3720e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1893, Task: 4, loss: 0.00009\n",
            "tensor(9.4021e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1893, Task: 5, loss: 0.00009\n",
            "tensor(2.1317e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1893, Task: 6, loss: 0.00002\n",
            "tensor(7.4309e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1893, Task: 7, loss: 0.00001\n",
            "tensor(7.2276e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1893, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0554e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1894, Task: 0, loss: 0.00009\n",
            "tensor(9.3970e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1894, Task: 1, loss: 0.00009\n",
            "tensor(9.3605e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1894, Task: 2, loss: 0.00009\n",
            "tensor(9.3781e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1894, Task: 3, loss: 0.00009\n",
            "tensor(9.3712e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1894, Task: 4, loss: 0.00009\n",
            "tensor(9.4014e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1894, Task: 5, loss: 0.00009\n",
            "tensor(2.1317e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1894, Task: 6, loss: 0.00002\n",
            "tensor(7.4329e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1894, Task: 7, loss: 0.00001\n",
            "tensor(7.2297e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1894, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0547e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1895, Task: 0, loss: 0.00009\n",
            "tensor(9.3963e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1895, Task: 1, loss: 0.00009\n",
            "tensor(9.3598e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1895, Task: 2, loss: 0.00009\n",
            "tensor(9.3774e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1895, Task: 3, loss: 0.00009\n",
            "tensor(9.3705e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1895, Task: 4, loss: 0.00009\n",
            "tensor(9.4007e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1895, Task: 5, loss: 0.00009\n",
            "tensor(2.1318e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1895, Task: 6, loss: 0.00002\n",
            "tensor(7.4348e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1895, Task: 7, loss: 0.00001\n",
            "tensor(7.2319e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1895, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0540e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1896, Task: 0, loss: 0.00009\n",
            "tensor(9.3956e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1896, Task: 1, loss: 0.00009\n",
            "tensor(9.3591e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1896, Task: 2, loss: 0.00009\n",
            "tensor(9.3767e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1896, Task: 3, loss: 0.00009\n",
            "tensor(9.3698e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1896, Task: 4, loss: 0.00009\n",
            "tensor(9.4000e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1896, Task: 5, loss: 0.00009\n",
            "tensor(2.1318e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1896, Task: 6, loss: 0.00002\n",
            "tensor(7.4366e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1896, Task: 7, loss: 0.00001\n",
            "tensor(7.2341e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1896, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0533e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1897, Task: 0, loss: 0.00009\n",
            "tensor(9.3949e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1897, Task: 1, loss: 0.00009\n",
            "tensor(9.3584e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1897, Task: 2, loss: 0.00009\n",
            "tensor(9.3760e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1897, Task: 3, loss: 0.00009\n",
            "tensor(9.3691e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1897, Task: 4, loss: 0.00009\n",
            "tensor(9.3992e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1897, Task: 5, loss: 0.00009\n",
            "tensor(2.1318e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1897, Task: 6, loss: 0.00002\n",
            "tensor(7.4384e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1897, Task: 7, loss: 0.00001\n",
            "tensor(7.2363e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1897, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0526e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1898, Task: 0, loss: 0.00009\n",
            "tensor(9.3942e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1898, Task: 1, loss: 0.00009\n",
            "tensor(9.3577e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1898, Task: 2, loss: 0.00009\n",
            "tensor(9.3753e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1898, Task: 3, loss: 0.00009\n",
            "tensor(9.3684e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1898, Task: 4, loss: 0.00009\n",
            "tensor(9.3985e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1898, Task: 5, loss: 0.00009\n",
            "tensor(2.1318e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1898, Task: 6, loss: 0.00002\n",
            "tensor(7.4404e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1898, Task: 7, loss: 0.00001\n",
            "tensor(7.2384e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1898, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0519e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1899, Task: 0, loss: 0.00009\n",
            "tensor(9.3935e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1899, Task: 1, loss: 0.00009\n",
            "tensor(9.3570e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1899, Task: 2, loss: 0.00009\n",
            "tensor(9.3746e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1899, Task: 3, loss: 0.00009\n",
            "tensor(9.3677e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1899, Task: 4, loss: 0.00009\n",
            "tensor(9.3978e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1899, Task: 5, loss: 0.00009\n",
            "tensor(2.1319e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1899, Task: 6, loss: 0.00002\n",
            "tensor(7.4424e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1899, Task: 7, loss: 0.00001\n",
            "tensor(7.2406e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1899, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0512e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1900, Task: 0, loss: 0.00009\n",
            "tensor(9.3928e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1900, Task: 1, loss: 0.00009\n",
            "tensor(9.3563e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1900, Task: 2, loss: 0.00009\n",
            "tensor(9.3739e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1900, Task: 3, loss: 0.00009\n",
            "tensor(9.3670e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1900, Task: 4, loss: 0.00009\n",
            "tensor(9.3971e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1900, Task: 5, loss: 0.00009\n",
            "tensor(2.1319e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1900, Task: 6, loss: 0.00002\n",
            "tensor(7.4444e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1900, Task: 7, loss: 0.00001\n",
            "tensor(7.2429e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1900, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0505e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1901, Task: 0, loss: 0.00009\n",
            "tensor(9.3920e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1901, Task: 1, loss: 0.00009\n",
            "tensor(9.3556e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1901, Task: 2, loss: 0.00009\n",
            "tensor(9.3732e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1901, Task: 3, loss: 0.00009\n",
            "tensor(9.3663e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1901, Task: 4, loss: 0.00009\n",
            "tensor(9.3964e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1901, Task: 5, loss: 0.00009\n",
            "tensor(2.1320e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1901, Task: 6, loss: 0.00002\n",
            "tensor(7.4464e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1901, Task: 7, loss: 0.00001\n",
            "tensor(7.2451e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1901, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0498e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1902, Task: 0, loss: 0.00009\n",
            "tensor(9.3913e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1902, Task: 1, loss: 0.00009\n",
            "tensor(9.3548e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1902, Task: 2, loss: 0.00009\n",
            "tensor(9.3725e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1902, Task: 3, loss: 0.00009\n",
            "tensor(9.3656e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1902, Task: 4, loss: 0.00009\n",
            "tensor(9.3957e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1902, Task: 5, loss: 0.00009\n",
            "tensor(2.1320e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1902, Task: 6, loss: 0.00002\n",
            "tensor(7.4484e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1902, Task: 7, loss: 0.00001\n",
            "tensor(7.2473e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1902, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0491e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1903, Task: 0, loss: 0.00009\n",
            "tensor(9.3906e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1903, Task: 1, loss: 0.00009\n",
            "tensor(9.3541e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1903, Task: 2, loss: 0.00009\n",
            "tensor(9.3718e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1903, Task: 3, loss: 0.00009\n",
            "tensor(9.3649e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1903, Task: 4, loss: 0.00009\n",
            "tensor(9.3950e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1903, Task: 5, loss: 0.00009\n",
            "tensor(2.1320e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1903, Task: 6, loss: 0.00002\n",
            "tensor(7.4504e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1903, Task: 7, loss: 0.00001\n",
            "tensor(7.2495e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1903, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0484e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1904, Task: 0, loss: 0.00009\n",
            "tensor(9.3899e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1904, Task: 1, loss: 0.00009\n",
            "tensor(9.3534e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1904, Task: 2, loss: 0.00009\n",
            "tensor(9.3710e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1904, Task: 3, loss: 0.00009\n",
            "tensor(9.3642e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1904, Task: 4, loss: 0.00009\n",
            "tensor(9.3943e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1904, Task: 5, loss: 0.00009\n",
            "tensor(2.1321e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1904, Task: 6, loss: 0.00002\n",
            "tensor(7.4525e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1904, Task: 7, loss: 0.00001\n",
            "tensor(7.2517e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1904, Task: 8, loss: 0.00001\n",
            "tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0477e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1905, Task: 0, loss: 0.00009\n",
            "tensor(9.3892e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1905, Task: 1, loss: 0.00009\n",
            "tensor(9.3527e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1905, Task: 2, loss: 0.00009\n",
            "tensor(9.3703e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1905, Task: 3, loss: 0.00009\n",
            "tensor(9.3634e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1905, Task: 4, loss: 0.00009\n",
            "tensor(9.3935e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1905, Task: 5, loss: 0.00009\n",
            "tensor(2.1321e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1905, Task: 6, loss: 0.00002\n",
            "tensor(7.4545e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1905, Task: 7, loss: 0.00001\n",
            "tensor(7.2540e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1905, Task: 8, loss: 0.00001\n",
            "tensor(9.9977e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0470e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1906, Task: 0, loss: 0.00009\n",
            "tensor(9.3885e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1906, Task: 1, loss: 0.00009\n",
            "tensor(9.3520e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1906, Task: 2, loss: 0.00009\n",
            "tensor(9.3696e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1906, Task: 3, loss: 0.00009\n",
            "tensor(9.3627e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1906, Task: 4, loss: 0.00009\n",
            "tensor(9.3928e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1906, Task: 5, loss: 0.00009\n",
            "tensor(2.1321e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1906, Task: 6, loss: 0.00002\n",
            "tensor(7.4565e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1906, Task: 7, loss: 0.00001\n",
            "tensor(7.2562e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1906, Task: 8, loss: 0.00001\n",
            "tensor(9.9938e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0463e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1907, Task: 0, loss: 0.00009\n",
            "tensor(9.3878e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1907, Task: 1, loss: 0.00009\n",
            "tensor(9.3513e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1907, Task: 2, loss: 0.00009\n",
            "tensor(9.3689e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1907, Task: 3, loss: 0.00009\n",
            "tensor(9.3620e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1907, Task: 4, loss: 0.00009\n",
            "tensor(9.3921e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1907, Task: 5, loss: 0.00009\n",
            "tensor(2.1322e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1907, Task: 6, loss: 0.00002\n",
            "tensor(7.4585e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1907, Task: 7, loss: 0.00001\n",
            "tensor(7.2584e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1907, Task: 8, loss: 0.00001\n",
            "tensor(9.9899e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0456e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1908, Task: 0, loss: 0.00009\n",
            "tensor(9.3870e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1908, Task: 1, loss: 0.00009\n",
            "tensor(9.3505e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1908, Task: 2, loss: 0.00009\n",
            "tensor(9.3682e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1908, Task: 3, loss: 0.00009\n",
            "tensor(9.3613e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1908, Task: 4, loss: 0.00009\n",
            "tensor(9.3914e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1908, Task: 5, loss: 0.00009\n",
            "tensor(2.1322e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1908, Task: 6, loss: 0.00002\n",
            "tensor(7.4604e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1908, Task: 7, loss: 0.00001\n",
            "tensor(7.2607e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1908, Task: 8, loss: 0.00001\n",
            "tensor(9.9861e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0449e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1909, Task: 0, loss: 0.00009\n",
            "tensor(9.3863e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1909, Task: 1, loss: 0.00009\n",
            "tensor(9.3498e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1909, Task: 2, loss: 0.00009\n",
            "tensor(9.3674e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1909, Task: 3, loss: 0.00009\n",
            "tensor(9.3606e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1909, Task: 4, loss: 0.00009\n",
            "tensor(9.3907e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1909, Task: 5, loss: 0.00009\n",
            "tensor(2.1322e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1909, Task: 6, loss: 0.00002\n",
            "tensor(7.4623e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1909, Task: 7, loss: 0.00001\n",
            "tensor(7.2629e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1909, Task: 8, loss: 0.00001\n",
            "tensor(9.9822e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0442e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1910, Task: 0, loss: 0.00009\n",
            "tensor(9.3856e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1910, Task: 1, loss: 0.00009\n",
            "tensor(9.3491e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1910, Task: 2, loss: 0.00009\n",
            "tensor(9.3667e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1910, Task: 3, loss: 0.00009\n",
            "tensor(9.3598e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1910, Task: 4, loss: 0.00009\n",
            "tensor(9.3899e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1910, Task: 5, loss: 0.00009\n",
            "tensor(2.1323e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1910, Task: 6, loss: 0.00002\n",
            "tensor(7.4642e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1910, Task: 7, loss: 0.00001\n",
            "tensor(7.2651e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1910, Task: 8, loss: 0.00001\n",
            "tensor(9.9784e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0435e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1911, Task: 0, loss: 0.00009\n",
            "tensor(9.3848e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1911, Task: 1, loss: 0.00009\n",
            "tensor(9.3484e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1911, Task: 2, loss: 0.00009\n",
            "tensor(9.3660e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1911, Task: 3, loss: 0.00009\n",
            "tensor(9.3591e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1911, Task: 4, loss: 0.00009\n",
            "tensor(9.3892e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1911, Task: 5, loss: 0.00009\n",
            "tensor(2.1323e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1911, Task: 6, loss: 0.00002\n",
            "tensor(7.4661e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1911, Task: 7, loss: 0.00001\n",
            "tensor(7.2674e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1911, Task: 8, loss: 0.00001\n",
            "tensor(9.9745e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0428e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1912, Task: 0, loss: 0.00009\n",
            "tensor(9.3841e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1912, Task: 1, loss: 0.00009\n",
            "tensor(9.3477e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1912, Task: 2, loss: 0.00009\n",
            "tensor(9.3653e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1912, Task: 3, loss: 0.00009\n",
            "tensor(9.3584e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1912, Task: 4, loss: 0.00009\n",
            "tensor(9.3885e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1912, Task: 5, loss: 0.00009\n",
            "tensor(2.1323e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1912, Task: 6, loss: 0.00002\n",
            "tensor(7.4683e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1912, Task: 7, loss: 0.00001\n",
            "tensor(7.2696e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1912, Task: 8, loss: 0.00001\n",
            "tensor(9.9706e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0421e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1913, Task: 0, loss: 0.00009\n",
            "tensor(9.3834e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1913, Task: 1, loss: 0.00009\n",
            "tensor(9.3469e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1913, Task: 2, loss: 0.00009\n",
            "tensor(9.3645e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1913, Task: 3, loss: 0.00009\n",
            "tensor(9.3577e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1913, Task: 4, loss: 0.00009\n",
            "tensor(9.3878e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1913, Task: 5, loss: 0.00009\n",
            "tensor(2.1324e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1913, Task: 6, loss: 0.00002\n",
            "tensor(7.4703e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1913, Task: 7, loss: 0.00001\n",
            "tensor(7.2719e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1913, Task: 8, loss: 0.00001\n",
            "tensor(9.9668e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0414e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1914, Task: 0, loss: 0.00009\n",
            "tensor(9.3827e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1914, Task: 1, loss: 0.00009\n",
            "tensor(9.3462e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1914, Task: 2, loss: 0.00009\n",
            "tensor(9.3638e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1914, Task: 3, loss: 0.00009\n",
            "tensor(9.3569e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1914, Task: 4, loss: 0.00009\n",
            "tensor(9.3870e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1914, Task: 5, loss: 0.00009\n",
            "tensor(2.1324e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1914, Task: 6, loss: 0.00002\n",
            "tensor(7.4725e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1914, Task: 7, loss: 0.00001\n",
            "tensor(7.2742e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1914, Task: 8, loss: 0.00001\n",
            "tensor(9.9629e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0407e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1915, Task: 0, loss: 0.00009\n",
            "tensor(9.3819e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1915, Task: 1, loss: 0.00009\n",
            "tensor(9.3455e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1915, Task: 2, loss: 0.00009\n",
            "tensor(9.3631e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1915, Task: 3, loss: 0.00009\n",
            "tensor(9.3562e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1915, Task: 4, loss: 0.00009\n",
            "tensor(9.3863e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1915, Task: 5, loss: 0.00009\n",
            "tensor(2.1325e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1915, Task: 6, loss: 0.00002\n",
            "tensor(7.4746e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1915, Task: 7, loss: 0.00001\n",
            "tensor(7.2765e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1915, Task: 8, loss: 0.00001\n",
            "tensor(9.9590e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0400e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1916, Task: 0, loss: 0.00009\n",
            "tensor(9.3812e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1916, Task: 1, loss: 0.00009\n",
            "tensor(9.3447e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1916, Task: 2, loss: 0.00009\n",
            "tensor(9.3624e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1916, Task: 3, loss: 0.00009\n",
            "tensor(9.3555e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1916, Task: 4, loss: 0.00009\n",
            "tensor(9.3856e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1916, Task: 5, loss: 0.00009\n",
            "tensor(2.1325e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1916, Task: 6, loss: 0.00002\n",
            "tensor(7.4766e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1916, Task: 7, loss: 0.00001\n",
            "tensor(7.2788e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1916, Task: 8, loss: 0.00001\n",
            "tensor(9.9552e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0393e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1917, Task: 0, loss: 0.00009\n",
            "tensor(9.3805e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1917, Task: 1, loss: 0.00009\n",
            "tensor(9.3440e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1917, Task: 2, loss: 0.00009\n",
            "tensor(9.3616e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1917, Task: 3, loss: 0.00009\n",
            "tensor(9.3547e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1917, Task: 4, loss: 0.00009\n",
            "tensor(9.3848e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1917, Task: 5, loss: 0.00009\n",
            "tensor(2.1325e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1917, Task: 6, loss: 0.00002\n",
            "tensor(7.4787e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1917, Task: 7, loss: 0.00001\n",
            "tensor(7.2811e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1917, Task: 8, loss: 0.00001\n",
            "tensor(9.9513e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0386e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1918, Task: 0, loss: 0.00009\n",
            "tensor(9.3797e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1918, Task: 1, loss: 0.00009\n",
            "tensor(9.3433e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1918, Task: 2, loss: 0.00009\n",
            "tensor(9.3609e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1918, Task: 3, loss: 0.00009\n",
            "tensor(9.3540e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1918, Task: 4, loss: 0.00009\n",
            "tensor(9.3841e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1918, Task: 5, loss: 0.00009\n",
            "tensor(2.1326e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1918, Task: 6, loss: 0.00002\n",
            "tensor(7.4807e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1918, Task: 7, loss: 0.00001\n",
            "tensor(7.2834e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1918, Task: 8, loss: 0.00001\n",
            "tensor(9.9475e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0379e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1919, Task: 0, loss: 0.00009\n",
            "tensor(9.3790e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1919, Task: 1, loss: 0.00009\n",
            "tensor(9.3425e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1919, Task: 2, loss: 0.00009\n",
            "tensor(9.3602e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1919, Task: 3, loss: 0.00009\n",
            "tensor(9.3533e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1919, Task: 4, loss: 0.00009\n",
            "tensor(9.3834e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1919, Task: 5, loss: 0.00009\n",
            "tensor(2.1326e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1919, Task: 6, loss: 0.00002\n",
            "tensor(7.4827e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1919, Task: 7, loss: 0.00001\n",
            "tensor(7.2856e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1919, Task: 8, loss: 0.00001\n",
            "tensor(9.9437e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0371e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1920, Task: 0, loss: 0.00009\n",
            "tensor(9.3783e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1920, Task: 1, loss: 0.00009\n",
            "tensor(9.3418e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1920, Task: 2, loss: 0.00009\n",
            "tensor(9.3594e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1920, Task: 3, loss: 0.00009\n",
            "tensor(9.3525e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1920, Task: 4, loss: 0.00009\n",
            "tensor(9.3826e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1920, Task: 5, loss: 0.00009\n",
            "tensor(2.1326e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1920, Task: 6, loss: 0.00002\n",
            "tensor(7.4848e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1920, Task: 7, loss: 0.00001\n",
            "tensor(7.2879e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1920, Task: 8, loss: 0.00001\n",
            "tensor(9.9399e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0364e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1921, Task: 0, loss: 0.00009\n",
            "tensor(9.3775e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1921, Task: 1, loss: 0.00009\n",
            "tensor(9.3411e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1921, Task: 2, loss: 0.00009\n",
            "tensor(9.3587e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1921, Task: 3, loss: 0.00009\n",
            "tensor(9.3518e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1921, Task: 4, loss: 0.00009\n",
            "tensor(9.3819e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1921, Task: 5, loss: 0.00009\n",
            "tensor(2.1327e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1921, Task: 6, loss: 0.00002\n",
            "tensor(7.4867e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1921, Task: 7, loss: 0.00001\n",
            "tensor(7.2902e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1921, Task: 8, loss: 0.00001\n",
            "tensor(9.9361e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0357e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1922, Task: 0, loss: 0.00009\n",
            "tensor(9.3768e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1922, Task: 1, loss: 0.00009\n",
            "tensor(9.3403e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1922, Task: 2, loss: 0.00009\n",
            "tensor(9.3579e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1922, Task: 3, loss: 0.00009\n",
            "tensor(9.3511e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1922, Task: 4, loss: 0.00009\n",
            "tensor(9.3811e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1922, Task: 5, loss: 0.00009\n",
            "tensor(2.1327e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1922, Task: 6, loss: 0.00002\n",
            "tensor(7.4887e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1922, Task: 7, loss: 0.00001\n",
            "tensor(7.2925e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1922, Task: 8, loss: 0.00001\n",
            "tensor(9.9323e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0350e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1923, Task: 0, loss: 0.00009\n",
            "tensor(9.3760e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1923, Task: 1, loss: 0.00009\n",
            "tensor(9.3396e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1923, Task: 2, loss: 0.00009\n",
            "tensor(9.3572e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1923, Task: 3, loss: 0.00009\n",
            "tensor(9.3503e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1923, Task: 4, loss: 0.00009\n",
            "tensor(9.3804e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1923, Task: 5, loss: 0.00009\n",
            "tensor(2.1327e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1923, Task: 6, loss: 0.00002\n",
            "tensor(7.4908e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1923, Task: 7, loss: 0.00001\n",
            "tensor(7.2948e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1923, Task: 8, loss: 0.00001\n",
            "tensor(9.9285e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0343e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1924, Task: 0, loss: 0.00009\n",
            "tensor(9.3753e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1924, Task: 1, loss: 0.00009\n",
            "tensor(9.3389e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1924, Task: 2, loss: 0.00009\n",
            "tensor(9.3565e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1924, Task: 3, loss: 0.00009\n",
            "tensor(9.3496e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1924, Task: 4, loss: 0.00009\n",
            "tensor(9.3797e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1924, Task: 5, loss: 0.00009\n",
            "tensor(2.1328e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1924, Task: 6, loss: 0.00002\n",
            "tensor(7.4929e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1924, Task: 7, loss: 0.00001\n",
            "tensor(7.2971e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1924, Task: 8, loss: 0.00001\n",
            "tensor(9.9247e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0336e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1925, Task: 0, loss: 0.00009\n",
            "tensor(9.3746e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1925, Task: 1, loss: 0.00009\n",
            "tensor(9.3381e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1925, Task: 2, loss: 0.00009\n",
            "tensor(9.3557e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1925, Task: 3, loss: 0.00009\n",
            "tensor(9.3488e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1925, Task: 4, loss: 0.00009\n",
            "tensor(9.3789e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1925, Task: 5, loss: 0.00009\n",
            "tensor(2.1328e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1925, Task: 6, loss: 0.00002\n",
            "tensor(7.4950e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1925, Task: 7, loss: 0.00001\n",
            "tensor(7.2995e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1925, Task: 8, loss: 0.00001\n",
            "tensor(9.9209e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0329e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1926, Task: 0, loss: 0.00009\n",
            "tensor(9.3738e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1926, Task: 1, loss: 0.00009\n",
            "tensor(9.3374e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1926, Task: 2, loss: 0.00009\n",
            "tensor(9.3550e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1926, Task: 3, loss: 0.00009\n",
            "tensor(9.3481e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1926, Task: 4, loss: 0.00009\n",
            "tensor(9.3782e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1926, Task: 5, loss: 0.00009\n",
            "tensor(2.1328e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1926, Task: 6, loss: 0.00002\n",
            "tensor(7.4971e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1926, Task: 7, loss: 0.00001\n",
            "tensor(7.3018e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1926, Task: 8, loss: 0.00001\n",
            "tensor(9.9171e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0322e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1927, Task: 0, loss: 0.00009\n",
            "tensor(9.3731e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1927, Task: 1, loss: 0.00009\n",
            "tensor(9.3366e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1927, Task: 2, loss: 0.00009\n",
            "tensor(9.3542e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1927, Task: 3, loss: 0.00009\n",
            "tensor(9.3474e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1927, Task: 4, loss: 0.00009\n",
            "tensor(9.3774e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1927, Task: 5, loss: 0.00009\n",
            "tensor(2.1329e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1927, Task: 6, loss: 0.00002\n",
            "tensor(7.4992e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1927, Task: 7, loss: 0.00001\n",
            "tensor(7.3041e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1927, Task: 8, loss: 0.00001\n",
            "tensor(9.9133e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0315e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1928, Task: 0, loss: 0.00009\n",
            "tensor(9.3723e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1928, Task: 1, loss: 0.00009\n",
            "tensor(9.3359e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1928, Task: 2, loss: 0.00009\n",
            "tensor(9.3535e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1928, Task: 3, loss: 0.00009\n",
            "tensor(9.3466e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1928, Task: 4, loss: 0.00009\n",
            "tensor(9.3767e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1928, Task: 5, loss: 0.00009\n",
            "tensor(2.1329e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1928, Task: 6, loss: 0.00002\n",
            "tensor(7.5013e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1928, Task: 7, loss: 0.00001\n",
            "tensor(7.3065e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1928, Task: 8, loss: 0.00001\n",
            "tensor(9.9096e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0308e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1929, Task: 0, loss: 0.00009\n",
            "tensor(9.3716e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1929, Task: 1, loss: 0.00009\n",
            "tensor(9.3351e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1929, Task: 2, loss: 0.00009\n",
            "tensor(9.3527e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1929, Task: 3, loss: 0.00009\n",
            "tensor(9.3459e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1929, Task: 4, loss: 0.00009\n",
            "tensor(9.3759e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1929, Task: 5, loss: 0.00009\n",
            "tensor(2.1330e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1929, Task: 6, loss: 0.00002\n",
            "tensor(7.5035e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1929, Task: 7, loss: 0.00001\n",
            "tensor(7.3088e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1929, Task: 8, loss: 0.00001\n",
            "tensor(9.9057e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0301e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1930, Task: 0, loss: 0.00009\n",
            "tensor(9.3708e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1930, Task: 1, loss: 0.00009\n",
            "tensor(9.3344e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1930, Task: 2, loss: 0.00009\n",
            "tensor(9.3520e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1930, Task: 3, loss: 0.00009\n",
            "tensor(9.3451e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1930, Task: 4, loss: 0.00009\n",
            "tensor(9.3752e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1930, Task: 5, loss: 0.00009\n",
            "tensor(2.1330e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1930, Task: 6, loss: 0.00002\n",
            "tensor(7.5057e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1930, Task: 7, loss: 0.00001\n",
            "tensor(7.3112e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1930, Task: 8, loss: 0.00001\n",
            "tensor(9.9019e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0294e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1931, Task: 0, loss: 0.00009\n",
            "tensor(9.3701e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1931, Task: 1, loss: 0.00009\n",
            "tensor(9.3336e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1931, Task: 2, loss: 0.00009\n",
            "tensor(9.3513e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1931, Task: 3, loss: 0.00009\n",
            "tensor(9.3444e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1931, Task: 4, loss: 0.00009\n",
            "tensor(9.3744e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1931, Task: 5, loss: 0.00009\n",
            "tensor(2.1331e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1931, Task: 6, loss: 0.00002\n",
            "tensor(7.5079e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1931, Task: 7, loss: 0.00001\n",
            "tensor(7.3135e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1931, Task: 8, loss: 0.00001\n",
            "tensor(9.8981e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0287e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1932, Task: 0, loss: 0.00009\n",
            "tensor(9.3693e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1932, Task: 1, loss: 0.00009\n",
            "tensor(9.3329e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1932, Task: 2, loss: 0.00009\n",
            "tensor(9.3505e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1932, Task: 3, loss: 0.00009\n",
            "tensor(9.3436e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1932, Task: 4, loss: 0.00009\n",
            "tensor(9.3737e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1932, Task: 5, loss: 0.00009\n",
            "tensor(2.1331e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1932, Task: 6, loss: 0.00002\n",
            "tensor(7.5099e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1932, Task: 7, loss: 0.00001\n",
            "tensor(7.3159e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1932, Task: 8, loss: 0.00001\n",
            "tensor(9.8944e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0280e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1933, Task: 0, loss: 0.00009\n",
            "tensor(9.3686e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1933, Task: 1, loss: 0.00009\n",
            "tensor(9.3321e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1933, Task: 2, loss: 0.00009\n",
            "tensor(9.3497e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1933, Task: 3, loss: 0.00009\n",
            "tensor(9.3429e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1933, Task: 4, loss: 0.00009\n",
            "tensor(9.3729e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1933, Task: 5, loss: 0.00009\n",
            "tensor(2.1331e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1933, Task: 6, loss: 0.00002\n",
            "tensor(7.5119e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1933, Task: 7, loss: 0.00001\n",
            "tensor(7.3182e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1933, Task: 8, loss: 0.00001\n",
            "tensor(9.8907e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0273e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1934, Task: 0, loss: 0.00009\n",
            "tensor(9.3678e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1934, Task: 1, loss: 0.00009\n",
            "tensor(9.3314e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1934, Task: 2, loss: 0.00009\n",
            "tensor(9.3490e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1934, Task: 3, loss: 0.00009\n",
            "tensor(9.3421e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1934, Task: 4, loss: 0.00009\n",
            "tensor(9.3722e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1934, Task: 5, loss: 0.00009\n",
            "tensor(2.1332e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1934, Task: 6, loss: 0.00002\n",
            "tensor(7.5140e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1934, Task: 7, loss: 0.00001\n",
            "tensor(7.3205e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1934, Task: 8, loss: 0.00001\n",
            "tensor(9.8870e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0266e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1935, Task: 0, loss: 0.00009\n",
            "tensor(9.3671e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1935, Task: 1, loss: 0.00009\n",
            "tensor(9.3306e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1935, Task: 2, loss: 0.00009\n",
            "tensor(9.3482e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1935, Task: 3, loss: 0.00009\n",
            "tensor(9.3414e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1935, Task: 4, loss: 0.00009\n",
            "tensor(9.3714e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1935, Task: 5, loss: 0.00009\n",
            "tensor(2.1332e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1935, Task: 6, loss: 0.00002\n",
            "tensor(7.5160e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1935, Task: 7, loss: 0.00001\n",
            "tensor(7.3229e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1935, Task: 8, loss: 0.00001\n",
            "tensor(9.8833e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0259e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1936, Task: 0, loss: 0.00009\n",
            "tensor(9.3663e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1936, Task: 1, loss: 0.00009\n",
            "tensor(9.3299e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1936, Task: 2, loss: 0.00009\n",
            "tensor(9.3475e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1936, Task: 3, loss: 0.00009\n",
            "tensor(9.3406e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1936, Task: 4, loss: 0.00009\n",
            "tensor(9.3707e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1936, Task: 5, loss: 0.00009\n",
            "tensor(2.1332e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1936, Task: 6, loss: 0.00002\n",
            "tensor(7.5181e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1936, Task: 7, loss: 0.00001\n",
            "tensor(7.3253e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1936, Task: 8, loss: 0.00001\n",
            "tensor(9.8795e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0252e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1937, Task: 0, loss: 0.00009\n",
            "tensor(9.3656e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1937, Task: 1, loss: 0.00009\n",
            "tensor(9.3291e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1937, Task: 2, loss: 0.00009\n",
            "tensor(9.3467e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1937, Task: 3, loss: 0.00009\n",
            "tensor(9.3399e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1937, Task: 4, loss: 0.00009\n",
            "tensor(9.3699e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1937, Task: 5, loss: 0.00009\n",
            "tensor(2.1333e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1937, Task: 6, loss: 0.00002\n",
            "tensor(7.5203e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1937, Task: 7, loss: 0.00001\n",
            "tensor(7.3276e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1937, Task: 8, loss: 0.00001\n",
            "tensor(9.8758e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0245e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1938, Task: 0, loss: 0.00009\n",
            "tensor(9.3648e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1938, Task: 1, loss: 0.00009\n",
            "tensor(9.3284e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1938, Task: 2, loss: 0.00009\n",
            "tensor(9.3460e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1938, Task: 3, loss: 0.00009\n",
            "tensor(9.3391e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1938, Task: 4, loss: 0.00009\n",
            "tensor(9.3692e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1938, Task: 5, loss: 0.00009\n",
            "tensor(2.1333e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1938, Task: 6, loss: 0.00002\n",
            "tensor(7.5224e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1938, Task: 7, loss: 0.00001\n",
            "tensor(7.3300e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1938, Task: 8, loss: 0.00001\n",
            "tensor(9.8720e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0238e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1939, Task: 0, loss: 0.00009\n",
            "tensor(9.3640e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1939, Task: 1, loss: 0.00009\n",
            "tensor(9.3276e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1939, Task: 2, loss: 0.00009\n",
            "tensor(9.3452e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1939, Task: 3, loss: 0.00009\n",
            "tensor(9.3383e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1939, Task: 4, loss: 0.00009\n",
            "tensor(9.3684e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1939, Task: 5, loss: 0.00009\n",
            "tensor(2.1334e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1939, Task: 6, loss: 0.00002\n",
            "tensor(7.5246e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1939, Task: 7, loss: 0.00001\n",
            "tensor(7.3324e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1939, Task: 8, loss: 0.00001\n",
            "tensor(9.8683e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0231e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1940, Task: 0, loss: 0.00009\n",
            "tensor(9.3633e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1940, Task: 1, loss: 0.00009\n",
            "tensor(9.3269e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1940, Task: 2, loss: 0.00009\n",
            "tensor(9.3445e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1940, Task: 3, loss: 0.00009\n",
            "tensor(9.3376e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1940, Task: 4, loss: 0.00009\n",
            "tensor(9.3676e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1940, Task: 5, loss: 0.00009\n",
            "tensor(2.1334e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1940, Task: 6, loss: 0.00002\n",
            "tensor(7.5268e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1940, Task: 7, loss: 0.00001\n",
            "tensor(7.3348e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1940, Task: 8, loss: 0.00001\n",
            "tensor(9.8646e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0224e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1941, Task: 0, loss: 0.00009\n",
            "tensor(9.3625e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1941, Task: 1, loss: 0.00009\n",
            "tensor(9.3261e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1941, Task: 2, loss: 0.00009\n",
            "tensor(9.3437e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1941, Task: 3, loss: 0.00009\n",
            "tensor(9.3368e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1941, Task: 4, loss: 0.00009\n",
            "tensor(9.3669e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1941, Task: 5, loss: 0.00009\n",
            "tensor(2.1334e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1941, Task: 6, loss: 0.00002\n",
            "tensor(7.5289e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1941, Task: 7, loss: 0.00001\n",
            "tensor(7.3372e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1941, Task: 8, loss: 0.00001\n",
            "tensor(9.8608e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0217e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1942, Task: 0, loss: 0.00009\n",
            "tensor(9.3618e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1942, Task: 1, loss: 0.00009\n",
            "tensor(9.3253e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1942, Task: 2, loss: 0.00009\n",
            "tensor(9.3429e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1942, Task: 3, loss: 0.00009\n",
            "tensor(9.3361e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1942, Task: 4, loss: 0.00009\n",
            "tensor(9.3661e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1942, Task: 5, loss: 0.00009\n",
            "tensor(2.1335e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1942, Task: 6, loss: 0.00002\n",
            "tensor(7.5311e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1942, Task: 7, loss: 0.00001\n",
            "tensor(7.3396e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1942, Task: 8, loss: 0.00001\n",
            "tensor(9.8571e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0210e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1943, Task: 0, loss: 0.00009\n",
            "tensor(9.3610e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1943, Task: 1, loss: 0.00009\n",
            "tensor(9.3246e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1943, Task: 2, loss: 0.00009\n",
            "tensor(9.3422e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1943, Task: 3, loss: 0.00009\n",
            "tensor(9.3353e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1943, Task: 4, loss: 0.00009\n",
            "tensor(9.3653e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1943, Task: 5, loss: 0.00009\n",
            "tensor(2.1335e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1943, Task: 6, loss: 0.00002\n",
            "tensor(7.5332e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1943, Task: 7, loss: 0.00001\n",
            "tensor(7.3420e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1943, Task: 8, loss: 0.00001\n",
            "tensor(9.8534e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0203e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1944, Task: 0, loss: 0.00009\n",
            "tensor(9.3602e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1944, Task: 1, loss: 0.00009\n",
            "tensor(9.3238e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1944, Task: 2, loss: 0.00009\n",
            "tensor(9.3414e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1944, Task: 3, loss: 0.00009\n",
            "tensor(9.3345e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1944, Task: 4, loss: 0.00009\n",
            "tensor(9.3646e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1944, Task: 5, loss: 0.00009\n",
            "tensor(2.1336e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1944, Task: 6, loss: 0.00002\n",
            "tensor(7.5354e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1944, Task: 7, loss: 0.00001\n",
            "tensor(7.3444e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1944, Task: 8, loss: 0.00001\n",
            "tensor(9.8497e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0196e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1945, Task: 0, loss: 0.00009\n",
            "tensor(9.3595e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1945, Task: 1, loss: 0.00009\n",
            "tensor(9.3231e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1945, Task: 2, loss: 0.00009\n",
            "tensor(9.3406e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1945, Task: 3, loss: 0.00009\n",
            "tensor(9.3338e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1945, Task: 4, loss: 0.00009\n",
            "tensor(9.3638e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1945, Task: 5, loss: 0.00009\n",
            "tensor(2.1336e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1945, Task: 6, loss: 0.00002\n",
            "tensor(7.5376e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1945, Task: 7, loss: 0.00001\n",
            "tensor(7.3468e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1945, Task: 8, loss: 0.00001\n",
            "tensor(9.8460e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0189e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1946, Task: 0, loss: 0.00009\n",
            "tensor(9.3587e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1946, Task: 1, loss: 0.00009\n",
            "tensor(9.3223e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1946, Task: 2, loss: 0.00009\n",
            "tensor(9.3399e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1946, Task: 3, loss: 0.00009\n",
            "tensor(9.3330e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1946, Task: 4, loss: 0.00009\n",
            "tensor(9.3631e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1946, Task: 5, loss: 0.00009\n",
            "tensor(2.1336e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1946, Task: 6, loss: 0.00002\n",
            "tensor(7.5398e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1946, Task: 7, loss: 0.00001\n",
            "tensor(7.3492e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1946, Task: 8, loss: 0.00001\n",
            "tensor(9.8423e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0182e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1947, Task: 0, loss: 0.00009\n",
            "tensor(9.3579e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1947, Task: 1, loss: 0.00009\n",
            "tensor(9.3215e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1947, Task: 2, loss: 0.00009\n",
            "tensor(9.3391e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1947, Task: 3, loss: 0.00009\n",
            "tensor(9.3322e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1947, Task: 4, loss: 0.00009\n",
            "tensor(9.3623e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1947, Task: 5, loss: 0.00009\n",
            "tensor(2.1337e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1947, Task: 6, loss: 0.00002\n",
            "tensor(7.5419e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1947, Task: 7, loss: 0.00001\n",
            "tensor(7.3516e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1947, Task: 8, loss: 0.00001\n",
            "tensor(9.8386e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0175e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1948, Task: 0, loss: 0.00009\n",
            "tensor(9.3572e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1948, Task: 1, loss: 0.00009\n",
            "tensor(9.3207e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1948, Task: 2, loss: 0.00009\n",
            "tensor(9.3383e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1948, Task: 3, loss: 0.00009\n",
            "tensor(9.3315e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1948, Task: 4, loss: 0.00009\n",
            "tensor(9.3615e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1948, Task: 5, loss: 0.00009\n",
            "tensor(2.1337e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1948, Task: 6, loss: 0.00002\n",
            "tensor(7.5440e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1948, Task: 7, loss: 0.00001\n",
            "tensor(7.3540e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1948, Task: 8, loss: 0.00001\n",
            "tensor(9.8349e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0168e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1949, Task: 0, loss: 0.00009\n",
            "tensor(9.3564e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1949, Task: 1, loss: 0.00009\n",
            "tensor(9.3200e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1949, Task: 2, loss: 0.00009\n",
            "tensor(9.3376e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1949, Task: 3, loss: 0.00009\n",
            "tensor(9.3307e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1949, Task: 4, loss: 0.00009\n",
            "tensor(9.3607e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1949, Task: 5, loss: 0.00009\n",
            "tensor(2.1337e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1949, Task: 6, loss: 0.00002\n",
            "tensor(7.5461e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1949, Task: 7, loss: 0.00001\n",
            "tensor(7.3565e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1949, Task: 8, loss: 0.00001\n",
            "tensor(9.8313e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0161e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1950, Task: 0, loss: 0.00009\n",
            "tensor(9.3556e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1950, Task: 1, loss: 0.00009\n",
            "tensor(9.3192e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1950, Task: 2, loss: 0.00009\n",
            "tensor(9.3368e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1950, Task: 3, loss: 0.00009\n",
            "tensor(9.3299e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1950, Task: 4, loss: 0.00009\n",
            "tensor(9.3600e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1950, Task: 5, loss: 0.00009\n",
            "tensor(2.1338e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1950, Task: 6, loss: 0.00002\n",
            "tensor(7.5482e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1950, Task: 7, loss: 0.00001\n",
            "tensor(7.3589e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1950, Task: 8, loss: 0.00001\n",
            "tensor(9.8277e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0154e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1951, Task: 0, loss: 0.00009\n",
            "tensor(9.3548e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1951, Task: 1, loss: 0.00009\n",
            "tensor(9.3184e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1951, Task: 2, loss: 0.00009\n",
            "tensor(9.3360e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1951, Task: 3, loss: 0.00009\n",
            "tensor(9.3291e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1951, Task: 4, loss: 0.00009\n",
            "tensor(9.3592e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1951, Task: 5, loss: 0.00009\n",
            "tensor(2.1338e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1951, Task: 6, loss: 0.00002\n",
            "tensor(7.5505e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1951, Task: 7, loss: 0.00001\n",
            "tensor(7.3613e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1951, Task: 8, loss: 0.00001\n",
            "tensor(9.8240e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0147e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1952, Task: 0, loss: 0.00009\n",
            "tensor(9.3541e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1952, Task: 1, loss: 0.00009\n",
            "tensor(9.3177e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1952, Task: 2, loss: 0.00009\n",
            "tensor(9.3353e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1952, Task: 3, loss: 0.00009\n",
            "tensor(9.3284e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1952, Task: 4, loss: 0.00009\n",
            "tensor(9.3584e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1952, Task: 5, loss: 0.00009\n",
            "tensor(2.1339e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1952, Task: 6, loss: 0.00002\n",
            "tensor(7.5528e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1952, Task: 7, loss: 0.00001\n",
            "tensor(7.3638e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1952, Task: 8, loss: 0.00001\n",
            "tensor(9.8203e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0140e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1953, Task: 0, loss: 0.00009\n",
            "tensor(9.3533e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1953, Task: 1, loss: 0.00009\n",
            "tensor(9.3169e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1953, Task: 2, loss: 0.00009\n",
            "tensor(9.3345e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1953, Task: 3, loss: 0.00009\n",
            "tensor(9.3276e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1953, Task: 4, loss: 0.00009\n",
            "tensor(9.3576e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1953, Task: 5, loss: 0.00009\n",
            "tensor(2.1339e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1953, Task: 6, loss: 0.00002\n",
            "tensor(7.5551e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1953, Task: 7, loss: 0.00001\n",
            "tensor(7.3662e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1953, Task: 8, loss: 0.00001\n",
            "tensor(9.8166e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0133e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1954, Task: 0, loss: 0.00009\n",
            "tensor(9.3525e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1954, Task: 1, loss: 0.00009\n",
            "tensor(9.3161e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1954, Task: 2, loss: 0.00009\n",
            "tensor(9.3337e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1954, Task: 3, loss: 0.00009\n",
            "tensor(9.3268e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1954, Task: 4, loss: 0.00009\n",
            "tensor(9.3569e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1954, Task: 5, loss: 0.00009\n",
            "tensor(2.1340e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1954, Task: 6, loss: 0.00002\n",
            "tensor(7.5574e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1954, Task: 7, loss: 0.00001\n",
            "tensor(7.3687e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1954, Task: 8, loss: 0.00001\n",
            "tensor(9.8129e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0126e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1955, Task: 0, loss: 0.00009\n",
            "tensor(9.3518e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1955, Task: 1, loss: 0.00009\n",
            "tensor(9.3153e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1955, Task: 2, loss: 0.00009\n",
            "tensor(9.3329e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1955, Task: 3, loss: 0.00009\n",
            "tensor(9.3261e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1955, Task: 4, loss: 0.00009\n",
            "tensor(9.3561e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1955, Task: 5, loss: 0.00009\n",
            "tensor(2.1340e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1955, Task: 6, loss: 0.00002\n",
            "tensor(7.5596e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1955, Task: 7, loss: 0.00001\n",
            "tensor(7.3712e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1955, Task: 8, loss: 0.00001\n",
            "tensor(9.8092e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0118e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1956, Task: 0, loss: 0.00009\n",
            "tensor(9.3510e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1956, Task: 1, loss: 0.00009\n",
            "tensor(9.3146e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1956, Task: 2, loss: 0.00009\n",
            "tensor(9.3322e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1956, Task: 3, loss: 0.00009\n",
            "tensor(9.3253e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1956, Task: 4, loss: 0.00009\n",
            "tensor(9.3553e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1956, Task: 5, loss: 0.00009\n",
            "tensor(2.1341e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1956, Task: 6, loss: 0.00002\n",
            "tensor(7.5619e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1956, Task: 7, loss: 0.00001\n",
            "tensor(7.3736e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1956, Task: 8, loss: 0.00001\n",
            "tensor(9.8056e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0111e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1957, Task: 0, loss: 0.00009\n",
            "tensor(9.3502e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1957, Task: 1, loss: 0.00009\n",
            "tensor(9.3138e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1957, Task: 2, loss: 0.00009\n",
            "tensor(9.3314e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1957, Task: 3, loss: 0.00009\n",
            "tensor(9.3245e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1957, Task: 4, loss: 0.00009\n",
            "tensor(9.3545e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1957, Task: 5, loss: 0.00009\n",
            "tensor(2.1341e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1957, Task: 6, loss: 0.00002\n",
            "tensor(7.5639e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1957, Task: 7, loss: 0.00001\n",
            "tensor(7.3760e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1957, Task: 8, loss: 0.00001\n",
            "tensor(9.8020e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0104e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1958, Task: 0, loss: 0.00009\n",
            "tensor(9.3494e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1958, Task: 1, loss: 0.00009\n",
            "tensor(9.3130e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1958, Task: 2, loss: 0.00009\n",
            "tensor(9.3306e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1958, Task: 3, loss: 0.00009\n",
            "tensor(9.3237e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1958, Task: 4, loss: 0.00009\n",
            "tensor(9.3538e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1958, Task: 5, loss: 0.00009\n",
            "tensor(2.1341e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1958, Task: 6, loss: 0.00002\n",
            "tensor(7.5659e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1958, Task: 7, loss: 0.00001\n",
            "tensor(7.3785e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1958, Task: 8, loss: 0.00001\n",
            "tensor(9.7984e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0097e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1959, Task: 0, loss: 0.00009\n",
            "tensor(9.3486e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1959, Task: 1, loss: 0.00009\n",
            "tensor(9.3122e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1959, Task: 2, loss: 0.00009\n",
            "tensor(9.3298e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1959, Task: 3, loss: 0.00009\n",
            "tensor(9.3229e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1959, Task: 4, loss: 0.00009\n",
            "tensor(9.3530e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1959, Task: 5, loss: 0.00009\n",
            "tensor(2.1342e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1959, Task: 6, loss: 0.00002\n",
            "tensor(7.5682e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1959, Task: 7, loss: 0.00001\n",
            "tensor(7.3810e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1959, Task: 8, loss: 0.00001\n",
            "tensor(9.7947e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0090e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1960, Task: 0, loss: 0.00009\n",
            "tensor(9.3478e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1960, Task: 1, loss: 0.00009\n",
            "tensor(9.3114e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1960, Task: 2, loss: 0.00009\n",
            "tensor(9.3290e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1960, Task: 3, loss: 0.00009\n",
            "tensor(9.3222e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1960, Task: 4, loss: 0.00009\n",
            "tensor(9.3522e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1960, Task: 5, loss: 0.00009\n",
            "tensor(2.1342e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1960, Task: 6, loss: 0.00002\n",
            "tensor(7.5704e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1960, Task: 7, loss: 0.00001\n",
            "tensor(7.3834e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1960, Task: 8, loss: 0.00001\n",
            "tensor(9.7911e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0083e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1961, Task: 0, loss: 0.00009\n",
            "tensor(9.3471e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1961, Task: 1, loss: 0.00009\n",
            "tensor(9.3107e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1961, Task: 2, loss: 0.00009\n",
            "tensor(9.3282e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1961, Task: 3, loss: 0.00009\n",
            "tensor(9.3214e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1961, Task: 4, loss: 0.00009\n",
            "tensor(9.3514e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1961, Task: 5, loss: 0.00009\n",
            "tensor(2.1342e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1961, Task: 6, loss: 0.00002\n",
            "tensor(7.5726e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1961, Task: 7, loss: 0.00001\n",
            "tensor(7.3859e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1961, Task: 8, loss: 0.00001\n",
            "tensor(9.7875e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0076e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1962, Task: 0, loss: 0.00009\n",
            "tensor(9.3463e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1962, Task: 1, loss: 0.00009\n",
            "tensor(9.3099e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1962, Task: 2, loss: 0.00009\n",
            "tensor(9.3275e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1962, Task: 3, loss: 0.00009\n",
            "tensor(9.3206e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1962, Task: 4, loss: 0.00009\n",
            "tensor(9.3506e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1962, Task: 5, loss: 0.00009\n",
            "tensor(2.1343e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1962, Task: 6, loss: 0.00002\n",
            "tensor(7.5749e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1962, Task: 7, loss: 0.00001\n",
            "tensor(7.3884e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1962, Task: 8, loss: 0.00001\n",
            "tensor(9.7839e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0069e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1963, Task: 0, loss: 0.00009\n",
            "tensor(9.3455e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1963, Task: 1, loss: 0.00009\n",
            "tensor(9.3091e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1963, Task: 2, loss: 0.00009\n",
            "tensor(9.3267e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1963, Task: 3, loss: 0.00009\n",
            "tensor(9.3198e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1963, Task: 4, loss: 0.00009\n",
            "tensor(9.3498e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1963, Task: 5, loss: 0.00009\n",
            "tensor(2.1343e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1963, Task: 6, loss: 0.00002\n",
            "tensor(7.5773e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1963, Task: 7, loss: 0.00001\n",
            "tensor(7.3909e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1963, Task: 8, loss: 0.00001\n",
            "tensor(9.7802e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0062e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1964, Task: 0, loss: 0.00009\n",
            "tensor(9.3447e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1964, Task: 1, loss: 0.00009\n",
            "tensor(9.3083e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1964, Task: 2, loss: 0.00009\n",
            "tensor(9.3259e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1964, Task: 3, loss: 0.00009\n",
            "tensor(9.3190e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1964, Task: 4, loss: 0.00009\n",
            "tensor(9.3490e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1964, Task: 5, loss: 0.00009\n",
            "tensor(2.1344e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1964, Task: 6, loss: 0.00002\n",
            "tensor(7.5795e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1964, Task: 7, loss: 0.00001\n",
            "tensor(7.3934e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1964, Task: 8, loss: 0.00001\n",
            "tensor(9.7766e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0055e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1965, Task: 0, loss: 0.00009\n",
            "tensor(9.3439e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1965, Task: 1, loss: 0.00009\n",
            "tensor(9.3075e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1965, Task: 2, loss: 0.00009\n",
            "tensor(9.3251e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1965, Task: 3, loss: 0.00009\n",
            "tensor(9.3182e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1965, Task: 4, loss: 0.00009\n",
            "tensor(9.3483e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1965, Task: 5, loss: 0.00009\n",
            "tensor(2.1344e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1965, Task: 6, loss: 0.00002\n",
            "tensor(7.5818e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1965, Task: 7, loss: 0.00001\n",
            "tensor(7.3959e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1965, Task: 8, loss: 0.00001\n",
            "tensor(9.7730e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0048e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1966, Task: 0, loss: 0.00009\n",
            "tensor(9.3431e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1966, Task: 1, loss: 0.00009\n",
            "tensor(9.3067e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1966, Task: 2, loss: 0.00009\n",
            "tensor(9.3243e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1966, Task: 3, loss: 0.00009\n",
            "tensor(9.3175e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1966, Task: 4, loss: 0.00009\n",
            "tensor(9.3475e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1966, Task: 5, loss: 0.00009\n",
            "tensor(2.1345e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1966, Task: 6, loss: 0.00002\n",
            "tensor(7.5841e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1966, Task: 7, loss: 0.00001\n",
            "tensor(7.3984e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1966, Task: 8, loss: 0.00001\n",
            "tensor(9.7694e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0041e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1967, Task: 0, loss: 0.00009\n",
            "tensor(9.3423e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1967, Task: 1, loss: 0.00009\n",
            "tensor(9.3060e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1967, Task: 2, loss: 0.00009\n",
            "tensor(9.3235e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1967, Task: 3, loss: 0.00009\n",
            "tensor(9.3167e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1967, Task: 4, loss: 0.00009\n",
            "tensor(9.3467e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1967, Task: 5, loss: 0.00009\n",
            "tensor(2.1345e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1967, Task: 6, loss: 0.00002\n",
            "tensor(7.5864e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1967, Task: 7, loss: 0.00001\n",
            "tensor(7.4009e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1967, Task: 8, loss: 0.00001\n",
            "tensor(9.7657e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0034e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1968, Task: 0, loss: 0.00009\n",
            "tensor(9.3415e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1968, Task: 1, loss: 0.00009\n",
            "tensor(9.3052e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1968, Task: 2, loss: 0.00009\n",
            "tensor(9.3227e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1968, Task: 3, loss: 0.00009\n",
            "tensor(9.3159e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1968, Task: 4, loss: 0.00009\n",
            "tensor(9.3459e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1968, Task: 5, loss: 0.00009\n",
            "tensor(2.1345e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1968, Task: 6, loss: 0.00002\n",
            "tensor(7.5886e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1968, Task: 7, loss: 0.00001\n",
            "tensor(7.4034e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1968, Task: 8, loss: 0.00001\n",
            "tensor(9.7622e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0027e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1969, Task: 0, loss: 0.00009\n",
            "tensor(9.3408e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1969, Task: 1, loss: 0.00009\n",
            "tensor(9.3044e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1969, Task: 2, loss: 0.00009\n",
            "tensor(9.3219e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1969, Task: 3, loss: 0.00009\n",
            "tensor(9.3151e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1969, Task: 4, loss: 0.00009\n",
            "tensor(9.3451e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1969, Task: 5, loss: 0.00009\n",
            "tensor(2.1346e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1969, Task: 6, loss: 0.00002\n",
            "tensor(7.5908e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1969, Task: 7, loss: 0.00001\n",
            "tensor(7.4059e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1969, Task: 8, loss: 0.00001\n",
            "tensor(9.7586e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0020e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1970, Task: 0, loss: 0.00009\n",
            "tensor(9.3400e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1970, Task: 1, loss: 0.00009\n",
            "tensor(9.3036e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1970, Task: 2, loss: 0.00009\n",
            "tensor(9.3211e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1970, Task: 3, loss: 0.00009\n",
            "tensor(9.3143e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1970, Task: 4, loss: 0.00009\n",
            "tensor(9.3443e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1970, Task: 5, loss: 0.00009\n",
            "tensor(2.1346e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1970, Task: 6, loss: 0.00002\n",
            "tensor(7.5929e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1970, Task: 7, loss: 0.00001\n",
            "tensor(7.4084e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1970, Task: 8, loss: 0.00001\n",
            "tensor(9.7551e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0013e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1971, Task: 0, loss: 0.00009\n",
            "tensor(9.3392e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1971, Task: 1, loss: 0.00009\n",
            "tensor(9.3028e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1971, Task: 2, loss: 0.00009\n",
            "tensor(9.3204e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1971, Task: 3, loss: 0.00009\n",
            "tensor(9.3135e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1971, Task: 4, loss: 0.00009\n",
            "tensor(9.3435e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1971, Task: 5, loss: 0.00009\n",
            "tensor(2.1346e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1971, Task: 6, loss: 0.00002\n",
            "tensor(7.5951e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1971, Task: 7, loss: 0.00001\n",
            "tensor(7.4109e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1971, Task: 8, loss: 0.00001\n",
            "tensor(9.7515e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(6.0006e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1972, Task: 0, loss: 0.00009\n",
            "tensor(9.3384e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1972, Task: 1, loss: 0.00009\n",
            "tensor(9.3020e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1972, Task: 2, loss: 0.00009\n",
            "tensor(9.3196e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1972, Task: 3, loss: 0.00009\n",
            "tensor(9.3127e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1972, Task: 4, loss: 0.00009\n",
            "tensor(9.3427e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1972, Task: 5, loss: 0.00009\n",
            "tensor(2.1347e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1972, Task: 6, loss: 0.00002\n",
            "tensor(7.5974e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1972, Task: 7, loss: 0.00001\n",
            "tensor(7.4134e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1972, Task: 8, loss: 0.00001\n",
            "tensor(9.7480e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9999e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1973, Task: 0, loss: 0.00009\n",
            "tensor(9.3376e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1973, Task: 1, loss: 0.00009\n",
            "tensor(9.3012e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1973, Task: 2, loss: 0.00009\n",
            "tensor(9.3188e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1973, Task: 3, loss: 0.00009\n",
            "tensor(9.3119e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1973, Task: 4, loss: 0.00009\n",
            "tensor(9.3419e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1973, Task: 5, loss: 0.00009\n",
            "tensor(2.1347e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1973, Task: 6, loss: 0.00002\n",
            "tensor(7.5997e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1973, Task: 7, loss: 0.00001\n",
            "tensor(7.4160e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1973, Task: 8, loss: 0.00001\n",
            "tensor(9.7444e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9992e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1974, Task: 0, loss: 0.00009\n",
            "tensor(9.3368e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1974, Task: 1, loss: 0.00009\n",
            "tensor(9.3004e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1974, Task: 2, loss: 0.00009\n",
            "tensor(9.3180e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1974, Task: 3, loss: 0.00009\n",
            "tensor(9.3111e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1974, Task: 4, loss: 0.00009\n",
            "tensor(9.3411e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1974, Task: 5, loss: 0.00009\n",
            "tensor(2.1348e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1974, Task: 6, loss: 0.00002\n",
            "tensor(7.6021e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1974, Task: 7, loss: 0.00001\n",
            "tensor(7.4185e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1974, Task: 8, loss: 0.00001\n",
            "tensor(9.7408e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9985e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1975, Task: 0, loss: 0.00009\n",
            "tensor(9.3360e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1975, Task: 1, loss: 0.00009\n",
            "tensor(9.2996e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1975, Task: 2, loss: 0.00009\n",
            "tensor(9.3172e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1975, Task: 3, loss: 0.00009\n",
            "tensor(9.3103e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1975, Task: 4, loss: 0.00009\n",
            "tensor(9.3403e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1975, Task: 5, loss: 0.00009\n",
            "tensor(2.1348e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1975, Task: 6, loss: 0.00002\n",
            "tensor(7.6045e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1975, Task: 7, loss: 0.00001\n",
            "tensor(7.4211e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1975, Task: 8, loss: 0.00001\n",
            "tensor(9.7372e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9978e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1976, Task: 0, loss: 0.00009\n",
            "tensor(9.3352e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1976, Task: 1, loss: 0.00009\n",
            "tensor(9.2988e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1976, Task: 2, loss: 0.00009\n",
            "tensor(9.3164e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1976, Task: 3, loss: 0.00009\n",
            "tensor(9.3095e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1976, Task: 4, loss: 0.00009\n",
            "tensor(9.3395e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1976, Task: 5, loss: 0.00009\n",
            "tensor(2.1349e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1976, Task: 6, loss: 0.00002\n",
            "tensor(7.6070e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1976, Task: 7, loss: 0.00001\n",
            "tensor(7.4237e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1976, Task: 8, loss: 0.00001\n",
            "tensor(9.7336e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9971e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1977, Task: 0, loss: 0.00009\n",
            "tensor(9.3344e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1977, Task: 1, loss: 0.00009\n",
            "tensor(9.2980e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1977, Task: 2, loss: 0.00009\n",
            "tensor(9.3156e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1977, Task: 3, loss: 0.00009\n",
            "tensor(9.3087e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1977, Task: 4, loss: 0.00009\n",
            "tensor(9.3387e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1977, Task: 5, loss: 0.00009\n",
            "tensor(2.1349e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1977, Task: 6, loss: 0.00002\n",
            "tensor(7.6093e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1977, Task: 7, loss: 0.00001\n",
            "tensor(7.4262e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1977, Task: 8, loss: 0.00001\n",
            "tensor(9.7300e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9964e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1978, Task: 0, loss: 0.00009\n",
            "tensor(9.3336e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1978, Task: 1, loss: 0.00009\n",
            "tensor(9.2972e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1978, Task: 2, loss: 0.00009\n",
            "tensor(9.3148e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1978, Task: 3, loss: 0.00009\n",
            "tensor(9.3079e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1978, Task: 4, loss: 0.00009\n",
            "tensor(9.3379e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1978, Task: 5, loss: 0.00009\n",
            "tensor(2.1350e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1978, Task: 6, loss: 0.00002\n",
            "tensor(7.6114e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1978, Task: 7, loss: 0.00001\n",
            "tensor(7.4288e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1978, Task: 8, loss: 0.00001\n",
            "tensor(9.7265e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9957e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1979, Task: 0, loss: 0.00009\n",
            "tensor(9.3328e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1979, Task: 1, loss: 0.00009\n",
            "tensor(9.2964e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1979, Task: 2, loss: 0.00009\n",
            "tensor(9.3140e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1979, Task: 3, loss: 0.00009\n",
            "tensor(9.3071e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1979, Task: 4, loss: 0.00009\n",
            "tensor(9.3371e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1979, Task: 5, loss: 0.00009\n",
            "tensor(2.1350e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1979, Task: 6, loss: 0.00002\n",
            "tensor(7.6136e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1979, Task: 7, loss: 0.00001\n",
            "tensor(7.4313e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1979, Task: 8, loss: 0.00001\n",
            "tensor(9.7229e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9950e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1980, Task: 0, loss: 0.00009\n",
            "tensor(9.3320e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1980, Task: 1, loss: 0.00009\n",
            "tensor(9.2956e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1980, Task: 2, loss: 0.00009\n",
            "tensor(9.3132e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1980, Task: 3, loss: 0.00009\n",
            "tensor(9.3063e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1980, Task: 4, loss: 0.00009\n",
            "tensor(9.3363e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1980, Task: 5, loss: 0.00009\n",
            "tensor(2.1350e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1980, Task: 6, loss: 0.00002\n",
            "tensor(7.6159e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1980, Task: 7, loss: 0.00001\n",
            "tensor(7.4338e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1980, Task: 8, loss: 0.00001\n",
            "tensor(9.7194e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9943e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1981, Task: 0, loss: 0.00009\n",
            "tensor(9.3312e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1981, Task: 1, loss: 0.00009\n",
            "tensor(9.2948e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1981, Task: 2, loss: 0.00009\n",
            "tensor(9.3124e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1981, Task: 3, loss: 0.00009\n",
            "tensor(9.3055e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1981, Task: 4, loss: 0.00009\n",
            "tensor(9.3355e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1981, Task: 5, loss: 0.00009\n",
            "tensor(2.1351e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1981, Task: 6, loss: 0.00002\n",
            "tensor(7.6181e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1981, Task: 7, loss: 0.00001\n",
            "tensor(7.4364e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1981, Task: 8, loss: 0.00001\n",
            "tensor(9.7159e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9936e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1982, Task: 0, loss: 0.00009\n",
            "tensor(9.3304e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1982, Task: 1, loss: 0.00009\n",
            "tensor(9.2940e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1982, Task: 2, loss: 0.00009\n",
            "tensor(9.3116e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1982, Task: 3, loss: 0.00009\n",
            "tensor(9.3047e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1982, Task: 4, loss: 0.00009\n",
            "tensor(9.3347e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1982, Task: 5, loss: 0.00009\n",
            "tensor(2.1351e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1982, Task: 6, loss: 0.00002\n",
            "tensor(7.6204e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1982, Task: 7, loss: 0.00001\n",
            "tensor(7.4389e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1982, Task: 8, loss: 0.00001\n",
            "tensor(9.7124e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9929e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1983, Task: 0, loss: 0.00009\n",
            "tensor(9.3295e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1983, Task: 1, loss: 0.00009\n",
            "tensor(9.2932e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1983, Task: 2, loss: 0.00009\n",
            "tensor(9.3107e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1983, Task: 3, loss: 0.00009\n",
            "tensor(9.3039e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1983, Task: 4, loss: 0.00009\n",
            "tensor(9.3339e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1983, Task: 5, loss: 0.00009\n",
            "tensor(2.1352e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1983, Task: 6, loss: 0.00002\n",
            "tensor(7.6228e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1983, Task: 7, loss: 0.00001\n",
            "tensor(7.4415e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1983, Task: 8, loss: 0.00001\n",
            "tensor(9.7088e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9922e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1984, Task: 0, loss: 0.00009\n",
            "tensor(9.3287e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1984, Task: 1, loss: 0.00009\n",
            "tensor(9.2924e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1984, Task: 2, loss: 0.00009\n",
            "tensor(9.3099e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1984, Task: 3, loss: 0.00009\n",
            "tensor(9.3031e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1984, Task: 4, loss: 0.00009\n",
            "tensor(9.3331e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1984, Task: 5, loss: 0.00009\n",
            "tensor(2.1352e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1984, Task: 6, loss: 0.00002\n",
            "tensor(7.6253e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1984, Task: 7, loss: 0.00001\n",
            "tensor(7.4441e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1984, Task: 8, loss: 0.00001\n",
            "tensor(9.7053e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9915e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1985, Task: 0, loss: 0.00009\n",
            "tensor(9.3279e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1985, Task: 1, loss: 0.00009\n",
            "tensor(9.2916e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1985, Task: 2, loss: 0.00009\n",
            "tensor(9.3091e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1985, Task: 3, loss: 0.00009\n",
            "tensor(9.3023e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1985, Task: 4, loss: 0.00009\n",
            "tensor(9.3323e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1985, Task: 5, loss: 0.00009\n",
            "tensor(2.1353e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1985, Task: 6, loss: 0.00002\n",
            "tensor(7.6276e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1985, Task: 7, loss: 0.00001\n",
            "tensor(7.4467e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1985, Task: 8, loss: 0.00001\n",
            "tensor(9.7017e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9908e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1986, Task: 0, loss: 0.00009\n",
            "tensor(9.3271e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1986, Task: 1, loss: 0.00009\n",
            "tensor(9.2908e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1986, Task: 2, loss: 0.00009\n",
            "tensor(9.3083e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1986, Task: 3, loss: 0.00009\n",
            "tensor(9.3015e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1986, Task: 4, loss: 0.00009\n",
            "tensor(9.3315e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1986, Task: 5, loss: 0.00009\n",
            "tensor(2.1353e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1986, Task: 6, loss: 0.00002\n",
            "tensor(7.6300e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1986, Task: 7, loss: 0.00001\n",
            "tensor(7.4493e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1986, Task: 8, loss: 0.00001\n",
            "tensor(9.6982e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9901e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1987, Task: 0, loss: 0.00009\n",
            "tensor(9.3263e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1987, Task: 1, loss: 0.00009\n",
            "tensor(9.2900e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1987, Task: 2, loss: 0.00009\n",
            "tensor(9.3075e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1987, Task: 3, loss: 0.00009\n",
            "tensor(9.3007e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1987, Task: 4, loss: 0.00009\n",
            "tensor(9.3307e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1987, Task: 5, loss: 0.00009\n",
            "tensor(2.1354e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1987, Task: 6, loss: 0.00002\n",
            "tensor(7.6324e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1987, Task: 7, loss: 0.00001\n",
            "tensor(7.4519e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1987, Task: 8, loss: 0.00001\n",
            "tensor(9.6947e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9894e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1988, Task: 0, loss: 0.00009\n",
            "tensor(9.3255e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1988, Task: 1, loss: 0.00009\n",
            "tensor(9.2892e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1988, Task: 2, loss: 0.00009\n",
            "tensor(9.3067e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1988, Task: 3, loss: 0.00009\n",
            "tensor(9.2999e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1988, Task: 4, loss: 0.00009\n",
            "tensor(9.3298e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1988, Task: 5, loss: 0.00009\n",
            "tensor(2.1354e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1988, Task: 6, loss: 0.00002\n",
            "tensor(7.6348e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1988, Task: 7, loss: 0.00001\n",
            "tensor(7.4545e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1988, Task: 8, loss: 0.00001\n",
            "tensor(9.6912e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9887e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1989, Task: 0, loss: 0.00009\n",
            "tensor(9.3247e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1989, Task: 1, loss: 0.00009\n",
            "tensor(9.2883e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1989, Task: 2, loss: 0.00009\n",
            "tensor(9.3059e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1989, Task: 3, loss: 0.00009\n",
            "tensor(9.2990e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1989, Task: 4, loss: 0.00009\n",
            "tensor(9.3290e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1989, Task: 5, loss: 0.00009\n",
            "tensor(2.1355e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1989, Task: 6, loss: 0.00002\n",
            "tensor(7.6371e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1989, Task: 7, loss: 0.00001\n",
            "tensor(7.4571e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1989, Task: 8, loss: 0.00001\n",
            "tensor(9.6877e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9880e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1990, Task: 0, loss: 0.00009\n",
            "tensor(9.3239e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1990, Task: 1, loss: 0.00009\n",
            "tensor(9.2875e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1990, Task: 2, loss: 0.00009\n",
            "tensor(9.3051e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1990, Task: 3, loss: 0.00009\n",
            "tensor(9.2982e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1990, Task: 4, loss: 0.00009\n",
            "tensor(9.3282e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1990, Task: 5, loss: 0.00009\n",
            "tensor(2.1355e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1990, Task: 6, loss: 0.00002\n",
            "tensor(7.6394e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1990, Task: 7, loss: 0.00001\n",
            "tensor(7.4597e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1990, Task: 8, loss: 0.00001\n",
            "tensor(9.6842e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9873e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1991, Task: 0, loss: 0.00009\n",
            "tensor(9.3231e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1991, Task: 1, loss: 0.00009\n",
            "tensor(9.2867e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1991, Task: 2, loss: 0.00009\n",
            "tensor(9.3043e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1991, Task: 3, loss: 0.00009\n",
            "tensor(9.2974e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1991, Task: 4, loss: 0.00009\n",
            "tensor(9.3274e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1991, Task: 5, loss: 0.00009\n",
            "tensor(2.1355e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1991, Task: 6, loss: 0.00002\n",
            "tensor(7.6416e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1991, Task: 7, loss: 0.00001\n",
            "tensor(7.4623e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1991, Task: 8, loss: 0.00001\n",
            "tensor(9.6808e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9866e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1992, Task: 0, loss: 0.00009\n",
            "tensor(9.3222e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1992, Task: 1, loss: 0.00009\n",
            "tensor(9.2859e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1992, Task: 2, loss: 0.00009\n",
            "tensor(9.3034e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1992, Task: 3, loss: 0.00009\n",
            "tensor(9.2966e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1992, Task: 4, loss: 0.00009\n",
            "tensor(9.3266e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1992, Task: 5, loss: 0.00009\n",
            "tensor(2.1356e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1992, Task: 6, loss: 0.00002\n",
            "tensor(7.6439e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1992, Task: 7, loss: 0.00001\n",
            "tensor(7.4649e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1992, Task: 8, loss: 0.00001\n",
            "tensor(9.6773e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9858e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1993, Task: 0, loss: 0.00009\n",
            "tensor(9.3214e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1993, Task: 1, loss: 0.00009\n",
            "tensor(9.2851e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1993, Task: 2, loss: 0.00009\n",
            "tensor(9.3026e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1993, Task: 3, loss: 0.00009\n",
            "tensor(9.2958e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1993, Task: 4, loss: 0.00009\n",
            "tensor(9.3258e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1993, Task: 5, loss: 0.00009\n",
            "tensor(2.1356e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1993, Task: 6, loss: 0.00002\n",
            "tensor(7.6463e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1993, Task: 7, loss: 0.00001\n",
            "tensor(7.4675e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1993, Task: 8, loss: 0.00001\n",
            "tensor(9.6738e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9851e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1994, Task: 0, loss: 0.00009\n",
            "tensor(9.3206e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1994, Task: 1, loss: 0.00009\n",
            "tensor(9.2843e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1994, Task: 2, loss: 0.00009\n",
            "tensor(9.3018e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1994, Task: 3, loss: 0.00009\n",
            "tensor(9.2950e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1994, Task: 4, loss: 0.00009\n",
            "tensor(9.3249e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1994, Task: 5, loss: 0.00009\n",
            "tensor(2.1357e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1994, Task: 6, loss: 0.00002\n",
            "tensor(7.6486e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1994, Task: 7, loss: 0.00001\n",
            "tensor(7.4701e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1994, Task: 8, loss: 0.00001\n",
            "tensor(9.6704e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9844e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1995, Task: 0, loss: 0.00009\n",
            "tensor(9.3198e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1995, Task: 1, loss: 0.00009\n",
            "tensor(9.2834e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1995, Task: 2, loss: 0.00009\n",
            "tensor(9.3010e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1995, Task: 3, loss: 0.00009\n",
            "tensor(9.2941e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1995, Task: 4, loss: 0.00009\n",
            "tensor(9.3241e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1995, Task: 5, loss: 0.00009\n",
            "tensor(2.1357e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1995, Task: 6, loss: 0.00002\n",
            "tensor(7.6510e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1995, Task: 7, loss: 0.00001\n",
            "tensor(7.4728e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1995, Task: 8, loss: 0.00001\n",
            "tensor(9.6669e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9837e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1996, Task: 0, loss: 0.00009\n",
            "tensor(9.3190e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1996, Task: 1, loss: 0.00009\n",
            "tensor(9.2826e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1996, Task: 2, loss: 0.00009\n",
            "tensor(9.3002e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1996, Task: 3, loss: 0.00009\n",
            "tensor(9.2933e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1996, Task: 4, loss: 0.00009\n",
            "tensor(9.3233e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1996, Task: 5, loss: 0.00009\n",
            "tensor(2.1358e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1996, Task: 6, loss: 0.00002\n",
            "tensor(7.6534e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1996, Task: 7, loss: 0.00001\n",
            "tensor(7.4754e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1996, Task: 8, loss: 0.00001\n",
            "tensor(9.6634e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9830e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1997, Task: 0, loss: 0.00009\n",
            "tensor(9.3181e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1997, Task: 1, loss: 0.00009\n",
            "tensor(9.2818e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1997, Task: 2, loss: 0.00009\n",
            "tensor(9.2994e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1997, Task: 3, loss: 0.00009\n",
            "tensor(9.2925e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1997, Task: 4, loss: 0.00009\n",
            "tensor(9.3225e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1997, Task: 5, loss: 0.00009\n",
            "tensor(2.1358e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1997, Task: 6, loss: 0.00002\n",
            "tensor(7.6560e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1997, Task: 7, loss: 0.00001\n",
            "tensor(7.4781e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1997, Task: 8, loss: 0.00001\n",
            "tensor(9.6599e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9823e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1998, Task: 0, loss: 0.00009\n",
            "tensor(9.3173e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1998, Task: 1, loss: 0.00009\n",
            "tensor(9.2810e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1998, Task: 2, loss: 0.00009\n",
            "tensor(9.2985e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1998, Task: 3, loss: 0.00009\n",
            "tensor(9.2917e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1998, Task: 4, loss: 0.00009\n",
            "tensor(9.3217e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1998, Task: 5, loss: 0.00009\n",
            "tensor(2.1359e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1998, Task: 6, loss: 0.00002\n",
            "tensor(7.6584e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1998, Task: 7, loss: 0.00001\n",
            "tensor(7.4807e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1998, Task: 8, loss: 0.00001\n",
            "tensor(9.6564e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9816e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 1999, Task: 0, loss: 0.00009\n",
            "tensor(9.3165e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1999, Task: 1, loss: 0.00009\n",
            "tensor(9.2802e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1999, Task: 2, loss: 0.00009\n",
            "tensor(9.2977e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1999, Task: 3, loss: 0.00009\n",
            "tensor(9.2909e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1999, Task: 4, loss: 0.00009\n",
            "tensor(9.3208e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1999, Task: 5, loss: 0.00009\n",
            "tensor(2.1359e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1999, Task: 6, loss: 0.00002\n",
            "tensor(7.6607e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1999, Task: 7, loss: 0.00001\n",
            "tensor(7.4834e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 1999, Task: 8, loss: 0.00001\n",
            "tensor(9.6529e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.9809e-05, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import learn2learn as l2l\n",
        "epochs = 2000\n",
        "learning_rate = 0.01\n",
        "input_size = 1\n",
        "hidden_size = 2\n",
        "num_layers = 1\n",
        "num_classes = 1\n",
        "meta_learning_rate = 0.01\n",
        "adaptation_steps = 1\n",
        "encoder = LSTM(num_classes, input_size, hidden_size, num_layers)\n",
        "output_layer = nn.Linear(1, 1)\n",
        "maml = l2l.algorithms.MAML(output_layer, lr=learning_rate, first_order=False)\n",
        "opt = optim.Adam(list(maml.parameters()) + list(encoder.parameters()), lr=meta_learning_rate)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "for iteration in range(epochs):\n",
        "    opt.zero_grad()\n",
        "    iteration_error = 0.0\n",
        "    for task in range(9):\n",
        "        learner = maml.clone()\n",
        "        x_spt = trainX[task]\n",
        "        y_spt = trainY[task]\n",
        "        x_qry = trainX[task+1]\n",
        "        y_qry = trainY[task+1]\n",
        "        # Fast adapt\n",
        "        for _ in range(adaptation_steps):\n",
        "            pred = learner(encoder(x_spt))\n",
        "            error = loss_fn(pred, y_spt)\n",
        "            learner.adapt(error)\n",
        "            print(\"Epoch: %d, Task: %d, loss: %1.5f\" % (iteration, task, error.item()))\n",
        "\n",
        "        pred = learner(encoder(x_qry))\n",
        "        evaluation_error = loss_fn(pred, y_qry)\n",
        "        print(evaluation_error)\n",
        "        iteration_error += evaluation_error\n",
        "    # Meta-update the model parameters\n",
        "    iteration_error /= 10\n",
        "    print(iteration_error)\n",
        "    iteration_error.backward()   \n",
        "    opt.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#epoch2000\n",
        "from math import sqrt\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "print(\"mean_absolute_error:\",mean_absolute_error(dataY_plot, data_predict))\n",
        "\n",
        "print(\"mean_squared_error:\",mean_squared_error(dataY_plot, data_predict))\n",
        "\n",
        "print(\"rmse:\",sqrt(mean_squared_error(dataY_plot, data_predict)))\n",
        "\n",
        "print(\"r2 score:\",r2_score(dataY_plot, data_predict))\n",
        "print(\"mape_sk\", mean_absolute_percentage_error(dataY_plot, data_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RupIn8yuzAE0",
        "outputId": "a212c28b-d183-4560-8677-bf7d63e1775e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_absolute_error: 0.005366352\n",
            "mean_squared_error: 8.6890635e-05\n",
            "rmse: 0.009321514653203175\n",
            "r2 score: 0.7522808971328029\n",
            "mape_sk 261669780.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9ozVjgaWhJP",
        "outputId": "5eb0a07c-11b0-405b-ec7f-61f5b6eb1ced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_absolute_error: 0.007112361\n",
            "mean_squared_error: 0.00022172919\n",
            "rmse: 0.014890573906097836\n",
            "r2 score: 0.36786534393687054\n",
            "mape_sk 425316450.0\n"
          ]
        }
      ],
      "source": [
        "#V3\n",
        "from math import sqrt\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "print(\"mean_absolute_error:\",mean_absolute_error(dataY_plot, data_predict))\n",
        "\n",
        "print(\"mean_squared_error:\",mean_squared_error(dataY_plot, data_predict))\n",
        "\n",
        "print(\"rmse:\",sqrt(mean_squared_error(dataY_plot, data_predict)))\n",
        "\n",
        "print(\"r2 score:\",r2_score(dataY_plot, data_predict))\n",
        "print(\"mape_sk\", mean_absolute_percentage_error(dataY_plot, data_predict))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lLLmi3qQzx0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testXall=testX.reshape(-1,1,1)\n",
        "testYall=testY.reshape(-1,1)"
      ],
      "metadata": {
        "id": "ro8WbpwbD0AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#epoch2000\n",
        "learner.eval()\n",
        "test_predict = learner(encoder(testXall))\n",
        "test_predict = test_predict.data.numpy()\n",
        "testY_plot = testYall.data.numpy()\n",
        "#data_predict=data_predict.reshape(1, -1)\n",
        "test_predict = sc.inverse_transform(test_predict)\n",
        "testY_plot = sc.inverse_transform(testY_plot)\n",
        "\n",
        "#plt.axvline(x=train_size, c='r', linestyle='--')\n",
        "\n",
        "plt.plot(testY_plot)\n",
        "plt.plot(test_predict)\n",
        "plt.suptitle('Time-Series Prediction')\n",
        "plt.show()\n",
        "import math\n",
        "testScore = math.sqrt(mean_squared_error(testY_plot, test_predict))\n",
        "print('Train Score: %.2f RMSE' % (testScore))\n",
        "#testScore = math.sqrt(mean_squared_error(testY, test_predict))\n",
        "#print('Test Score: %.2f RMSE' % (testScore))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "BUnzb0pCztiw",
        "outputId": "612b6905-1395-477b-f819-687935975b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Score: 0.01 RMSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#epoch2000\n",
        "from math import sqrt\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "print(\"mean_absolute_error:\",mean_absolute_error(testY_plot, test_predict))\n",
        "\n",
        "print(\"mean_squared_error:\",mean_squared_error(testY_plot, test_predict))\n",
        "\n",
        "print(\"rmse:\",sqrt(mean_squared_error(testY_plot, test_predict)))\n",
        "\n",
        "print(\"r2 score:\",r2_score(testY_plot, test_predict))\n",
        "print(\"mape_sk\", mean_absolute_percentage_error(testY_plot, test_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a02Q2TCz2Ar",
        "outputId": "d77e15e9-ac36-4760-8f9a-d01d20cf9189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_absolute_error: 0.005199849\n",
            "mean_squared_error: 0.00012834572\n",
            "rmse: 0.011328977185908118\n",
            "r2 score: 0.8452537992759469\n",
            "mape_sk 872236800.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "MAML-LSTM",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
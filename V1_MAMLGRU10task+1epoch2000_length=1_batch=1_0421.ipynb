{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijZFtBJPgqkU",
        "outputId": "562bf1bf-e9cc-4092-9c80-37daacb186f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1679994, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from google.colab import drive\n",
        "from array import array\n",
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "drive.mount('/content/gdrive') # 此處需要登入google帳號\n",
        "data = pd.read_csv(\"/content/gdrive/My Drive/thesis/thesisdataset/millan_average7_396.csv\")\n",
        "#data = pd.read_csv(\"1101-1107sorted4.csv\")\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nwdaf_data = pd.read_csv(\"/content/gdrive/My Drive/thesis/thesisdataset/germany_average3_41.csv\")\n",
        "nwdaf_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc712H5z9pJl",
        "outputId": "2284460c-ca7a-4146-c993-eba89f3329f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1296000, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uk_data = pd.read_csv(\"/content/gdrive/My Drive/thesis/thesisdataset/uk_data_average5_69_v1.csv\")\n",
        "uk_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOkFzVj6tC6T",
        "outputId": "abafc867-0456-435b-f135-3ac4d0b70686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19888, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0pC7hRsvSBuM",
        "outputId": "2b5e065e-558a-4574-d197-27095b31894b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting learn2learn\n",
            "  Downloading learn2learn-0.1.7.tar.gz (841 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 34.3 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 40.4 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 40 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 51 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 61 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 71 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 81 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 92 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 102 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 112 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 122 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████                           | 133 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 143 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 153 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 163 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 174 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████                         | 184 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 194 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 204 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 215 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 225 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 235 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 245 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 256 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 266 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 276 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 286 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 296 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 307 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 317 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 327 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 337 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 348 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 358 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 368 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 378 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 389 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 399 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 409 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 419 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 430 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 440 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 450 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 460 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 471 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 481 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 491 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 501 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 512 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 522 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 532 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 542 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 552 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 563 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 573 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 583 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 593 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 604 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 614 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 624 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 634 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 645 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 655 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 665 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 675 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 686 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 696 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 706 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 716 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 727 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 737 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 747 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 757 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 768 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 778 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 788 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 798 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 808 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 819 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 829 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 839 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 841 kB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from learn2learn) (1.21.6)\n",
            "Requirement already satisfied: gym>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from learn2learn) (0.17.3)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from learn2learn) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from learn2learn) (0.11.1+cu111)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from learn2learn) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from learn2learn) (2.23.0)\n",
            "Collecting gsutil\n",
            "  Downloading gsutil-5.9.tar.gz (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 63.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from learn2learn) (4.64.0)\n",
            "Collecting qpth>=0.0.15\n",
            "  Downloading qpth-0.0.15.tar.gz (11 kB)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.14.0->learn2learn) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.14.0->learn2learn) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.14.0->learn2learn) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->learn2learn) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3.0->learn2learn) (7.1.2)\n",
            "Collecting argcomplete>=1.9.4\n",
            "  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.7/dist-packages (from gsutil->learn2learn) (1.7)\n",
            "Collecting fasteners>=0.14.1\n",
            "  Downloading fasteners-0.17.3-py3-none-any.whl (18 kB)\n",
            "Collecting gcs-oauth2-boto-plugin>=3.0\n",
            "  Downloading gcs-oauth2-boto-plugin-3.0.tar.gz (20 kB)\n",
            "Collecting google-apitools>=0.5.32\n",
            "  Downloading google_apitools-0.5.32-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 85.0 MB/s \n",
            "\u001b[?25hCollecting httplib2>=0.20.4\n",
            "  Downloading httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 8.3 MB/s \n",
            "\u001b[?25hCollecting google-reauth>=0.1.0\n",
            "  Downloading google_reauth-0.1.1-py2.py3-none-any.whl (17 kB)\n",
            "Collecting monotonic>=1.4\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting pyOpenSSL>=0.13\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting retry_decorator>=1.0.0\n",
            "  Downloading retry_decorator-1.1.1.tar.gz (3.9 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from gsutil->learn2learn) (1.15.0)\n",
            "Collecting google-auth[aiohttp]>=2.5.0\n",
            "  Downloading google_auth-2.6.5-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 73.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata<5,>=0.23 in /usr/local/lib/python3.7/dist-packages (from argcomplete>=1.9.4->gsutil->learn2learn) (4.11.3)\n",
            "Collecting rsa==4.7.2\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Collecting boto>=2.29.1\n",
            "  Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 64.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil->learn2learn) (4.1.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa==4.7.2->gcs-oauth2-boto-plugin>=3.0->gsutil->learn2learn) (0.4.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (0.2.8)\n",
            "Collecting aiohttp<4.0.0dev,>=3.6.2\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 79.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->learn2learn) (21.4.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 59.3 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 91.8 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting pyu2f\n",
            "  Downloading pyu2f-0.1.5.tar.gz (27 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.7/dist-packages (from httplib2>=0.20.4->gsutil->learn2learn) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5,>=0.23->argcomplete>=1.9.4->gsutil->learn2learn) (3.8.0)\n",
            "Collecting cryptography>=35.0\n",
            "  Downloading cryptography-36.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 62.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=35.0->pyOpenSSL>=0.13->gsutil->learn2learn) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=35.0->pyOpenSSL>=0.13->gsutil->learn2learn) (2.21)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->learn2learn) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->learn2learn) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->learn2learn) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->learn2learn) (1.24.3)\n",
            "Building wheels for collected packages: learn2learn, qpth, gsutil, gcs-oauth2-boto-plugin, retry-decorator, pyu2f\n",
            "  Building wheel for learn2learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for learn2learn: filename=learn2learn-0.1.7-cp37-cp37m-linux_x86_64.whl size=938560 sha256=6f9f85c1300ef62ad91e37a4559762fe1847de03aa3029f02f37ed3442ac9768\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/29/ac/1d46fdb88fb1fb02491123ef3fcec13d5363eb14fec6f8af05\n",
            "  Building wheel for qpth (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qpth: filename=qpth-0.0.15-py3-none-any.whl size=15379 sha256=c92e66dbf3f0c3ee7ca6f3293731ec934dbb0fabbca9943b4c3cf6a7a77f8379\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/bb/0f/3af358159c8cfc56654d85ba5069b53ab351dee72f5a57c2ff\n",
            "  Building wheel for gsutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gsutil: filename=gsutil-5.9-py3-none-any.whl size=3744804 sha256=d08a8256d306da32170bd868f3997c6471441c83d77b80a2d9bd5eb8526610b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/48/ef/e11e9eb34daf175bf09b270aeeff31cc37ca0e5086fa34ccf1\n",
            "  Building wheel for gcs-oauth2-boto-plugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gcs-oauth2-boto-plugin: filename=gcs_oauth2_boto_plugin-3.0-py3-none-any.whl size=23221 sha256=c14aca2905e2e035ef08aa03eaa517d5c9c058f545ffbe3cd9934759b9b85dc5\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/93/86/cb2140365b10150dbdba338da385c7c18c7cbd9e592e3421db\n",
            "  Building wheel for retry-decorator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for retry-decorator: filename=retry_decorator-1.1.1-py2.py3-none-any.whl size=3658 sha256=db335c63e15cefc6762df379b14272d6beadf578cd31fc921e1ac1c44989372a\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/39/dc/7359c639e34d9c388a1b3e1dc444363905194afc70f57eb9a5\n",
            "  Building wheel for pyu2f (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyu2f: filename=pyu2f-0.1.5-py3-none-any.whl size=39404 sha256=a82c38fb7e4924106c909f8445079d22115901d94ba477bd62d2d2f696abc374\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/84/c6/ee8093bf96e2224aca3a9bfa074aa3c86c39208f91055fd60f\n",
            "Successfully built learn2learn qpth gsutil gcs-oauth2-boto-plugin retry-decorator pyu2f\n",
            "Installing collected packages: multidict, frozenlist, yarl, rsa, pyu2f, httplib2, cryptography, asynctest, async-timeout, aiosignal, retry-decorator, pyOpenSSL, google-reauth, google-auth, fasteners, boto, aiohttp, monotonic, google-apitools, gcs-oauth2-boto-plugin, argcomplete, qpth, gsutil, learn2learn\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.8\n",
            "    Uninstalling rsa-4.8:\n",
            "      Successfully uninstalled rsa-4.8\n",
            "  Attempting uninstall: httplib2\n",
            "    Found existing installation: httplib2 0.17.4\n",
            "    Uninstalling httplib2-0.17.4:\n",
            "      Successfully uninstalled httplib2-0.17.4\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 1.35.0\n",
            "    Uninstalling google-auth-1.35.0:\n",
            "      Successfully uninstalled google-auth-1.35.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-api-core 1.31.5 requires google-auth<2.0dev,>=1.25.0, but you have google-auth 2.6.5 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 argcomplete-2.0.0 async-timeout-4.0.2 asynctest-0.13.0 boto-2.49.0 cryptography-36.0.2 fasteners-0.17.3 frozenlist-1.3.0 gcs-oauth2-boto-plugin-3.0 google-apitools-0.5.32 google-auth-2.6.5 google-reauth-0.1.1 gsutil-5.9 httplib2-0.20.4 learn2learn-0.1.7 monotonic-1.6 multidict-6.0.2 pyOpenSSL-22.0.0 pyu2f-0.1.5 qpth-0.0.15 retry-decorator-1.1.1 rsa-4.7.2 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "httplib2",
                  "rsa"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install learn2learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JK_XqJEmBbWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVenwNg89v4z",
        "outputId": "929a800a-30c6-4831-c740-a670a06c02e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 21 12:34:26 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -V"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWVGWZijAgxT",
        "outputId": "caaaedb5-dfd0-45b3-ffba-2d2066b94f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnKWk5wuA9Vv",
        "outputId": "ac8d9f49-649a-4351-dafe-d38471db2cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-G6HNxymideM"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data)\n",
        "dataset = df.internet.values.astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.DataFrame(nwdaf_data)\n",
        "dataset2 = df2.load.values.astype(float)"
      ],
      "metadata": {
        "id": "WPcIcdUE93iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = pd.DataFrame(uk_data)\n",
        "dataset4 = df4.internet.values.astype(float)"
      ],
      "metadata": {
        "id": "Xh1gYsAgurPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1000=np.append(dataset2, dataset4)"
      ],
      "metadata": {
        "id": "awZUErp59-4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1000=np.append(dataset1000, dataset)"
      ],
      "metadata": {
        "id": "7dTSCuIyvHNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "5L5fAmZD4JSI",
        "outputId": "98e0d743-d2d3-4c55-f809-85d7399b6b01"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#train_size = 2097000\n",
        "#plt.axvline(x=train_size, c='r', linestyle='--')\n",
        "plt.plot(dataset1000, label = 'Shampoo Sales Data')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0Y18hDI4npC",
        "outputId": "b7a93977-ef93-431a-9038-de60d5492db1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2995882,)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "\n",
        "dataset1000.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSVIgZjf48pD"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataset1000=dataset1000.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPsSWiFF5J4d",
        "outputId": "bbf5e146-9a19-4424-f7b6-f612c1f913b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2995882, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "dataset1000.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e44j-Ux74Mgp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "def sliding_windows(data, seq_length):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-seq_length):\n",
        "        _x = data[i:(i+seq_length)]\n",
        "        _y = data[i+seq_length]\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return np.array(x),np.array(y)\n",
        "\n",
        "sc = MinMaxScaler()\n",
        "dataset1000 = sc.fit_transform(dataset1000)\n",
        "\n",
        "seq_length = 1\n",
        "\n",
        "dataset1000 = sc.fit_transform(dataset1000)\n",
        "x, y = sliding_windows(dataset1000, seq_length)\n",
        "\n",
        "train_size = 2097200\n",
        "test_size = len(y) - train_size\n",
        "#train_size = 1200000\n",
        "#test_size = 480000\n",
        "#train_size = 2000000\n",
        "#test_size = 976000\n",
        "#test_size = 1018600\n",
        "dataX = Variable(torch.Tensor(np.array(x)))\n",
        "dataY= Variable(torch.Tensor(np.array(y)))\n",
        "\n",
        "trainX = Variable(torch.Tensor(np.array(x[0:train_size])))\n",
        "trainY = Variable(torch.Tensor(np.array(y[0:train_size])))\n",
        "\n",
        "testX = Variable(torch.Tensor(np.array(x[train_size:len(x)])))\n",
        "testY = Variable(torch.Tensor(np.array(y[train_size:len(y)])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReG82s-misSg"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc-fr6DNF_yq",
        "outputId": "6ae83371-d618-4d89-c7ff-d50d9244b5a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2097200, 1, 1])\n",
            "torch.Size([2097200, 1])\n",
            "torch.Size([898681, 1, 1])\n",
            "torch.Size([898681, 1])\n"
          ]
        }
      ],
      "source": [
        "print(trainX.shape)\n",
        "print(trainY.shape)\n",
        "print(testX.shape)\n",
        "print(testY.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w3uLq63YkRgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ht0iAK_He-X"
      },
      "outputs": [],
      "source": [
        "trainX=trainX.reshape(10,209720,1,1)\n",
        "trainY=trainY.reshape(10,209720,1)\n",
        "testX=testX.reshape(898681,1,1)\n",
        "testY=testY.reshape(898681,1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainX.shape)\n",
        "print(trainY.shape)\n",
        "print(testX.shape)\n",
        "print(testY.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lguz9WKQkbL2",
        "outputId": "0a78bd28-405c-4e89-caab-3b0a06771413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 209720, 1, 1])\n",
            "torch.Size([10, 209720, 1])\n",
            "torch.Size([898681, 1, 1])\n",
            "torch.Size([898681, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXz37vSL5m9E"
      },
      "outputs": [],
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
        "        super(GRUModel, self).__init__()\n",
        "\n",
        "        # Defining the number of layers and the nodes in each layer\n",
        "        self.layer_dim = layer_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # GRU layers\n",
        "        self.gru = nn.GRU(\n",
        "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
        "        )\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initializing hidden state for first input with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
        "\n",
        "        # Forward propagation by passing in the input and hidden state into the model\n",
        "        out, _ = self.gru(x, h0.detach())\n",
        "\n",
        "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
        "        # so that it can fit into the fully connected layer\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0gJxk1Ov-eP",
        "outputId": "fa497669-042f-47d8-dae7-8174274fdbb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m串流輸出內容已截斷至最後 5000 行。\u001b[0m\n",
            "Epoch: 2736, Task: 8, loss: 0.00001\n",
            "tensor(8.3131e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6103e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2737, Task: 0, loss: 0.00009\n",
            "tensor(8.7562e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2737, Task: 1, loss: 0.00009\n",
            "tensor(8.7216e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2737, Task: 2, loss: 0.00009\n",
            "tensor(8.7379e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2737, Task: 3, loss: 0.00009\n",
            "tensor(8.7318e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2737, Task: 4, loss: 0.00009\n",
            "tensor(8.7604e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2737, Task: 5, loss: 0.00009\n",
            "tensor(2.1768e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2737, Task: 6, loss: 0.00002\n",
            "tensor(9.5462e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2737, Task: 7, loss: 0.00001\n",
            "tensor(9.4719e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2737, Task: 8, loss: 0.00001\n",
            "tensor(8.3145e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6101e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2738, Task: 0, loss: 0.00009\n",
            "tensor(8.7553e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2738, Task: 1, loss: 0.00009\n",
            "tensor(8.7207e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2738, Task: 2, loss: 0.00009\n",
            "tensor(8.7370e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2738, Task: 3, loss: 0.00009\n",
            "tensor(8.7309e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2738, Task: 4, loss: 0.00009\n",
            "tensor(8.7595e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2738, Task: 5, loss: 0.00009\n",
            "tensor(2.1769e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2738, Task: 6, loss: 0.00002\n",
            "tensor(9.5496e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2738, Task: 7, loss: 0.00001\n",
            "tensor(9.4755e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2738, Task: 8, loss: 0.00001\n",
            "tensor(8.3160e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6099e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2739, Task: 0, loss: 0.00009\n",
            "tensor(8.7544e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2739, Task: 1, loss: 0.00009\n",
            "tensor(8.7198e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2739, Task: 2, loss: 0.00009\n",
            "tensor(8.7361e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2739, Task: 3, loss: 0.00009\n",
            "tensor(8.7300e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2739, Task: 4, loss: 0.00009\n",
            "tensor(8.7586e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2739, Task: 5, loss: 0.00009\n",
            "tensor(2.1770e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2739, Task: 6, loss: 0.00002\n",
            "tensor(9.5530e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2739, Task: 7, loss: 0.00001\n",
            "tensor(9.4792e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2739, Task: 8, loss: 0.00001\n",
            "tensor(8.3175e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6097e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2740, Task: 0, loss: 0.00009\n",
            "tensor(8.7535e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2740, Task: 1, loss: 0.00009\n",
            "tensor(8.7189e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2740, Task: 2, loss: 0.00009\n",
            "tensor(8.7352e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2740, Task: 3, loss: 0.00009\n",
            "tensor(8.7291e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2740, Task: 4, loss: 0.00009\n",
            "tensor(8.7577e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2740, Task: 5, loss: 0.00009\n",
            "tensor(2.1771e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2740, Task: 6, loss: 0.00002\n",
            "tensor(9.5565e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2740, Task: 7, loss: 0.00001\n",
            "tensor(9.4829e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2740, Task: 8, loss: 0.00001\n",
            "tensor(8.3190e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6094e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2741, Task: 0, loss: 0.00009\n",
            "tensor(8.7526e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2741, Task: 1, loss: 0.00009\n",
            "tensor(8.7180e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2741, Task: 2, loss: 0.00009\n",
            "tensor(8.7344e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2741, Task: 3, loss: 0.00009\n",
            "tensor(8.7282e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2741, Task: 4, loss: 0.00009\n",
            "tensor(8.7568e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2741, Task: 5, loss: 0.00009\n",
            "tensor(2.1772e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2741, Task: 6, loss: 0.00002\n",
            "tensor(9.5599e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2741, Task: 7, loss: 0.00001\n",
            "tensor(9.4865e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2741, Task: 8, loss: 0.00001\n",
            "tensor(8.3204e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6092e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2742, Task: 0, loss: 0.00009\n",
            "tensor(8.7517e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2742, Task: 1, loss: 0.00009\n",
            "tensor(8.7172e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2742, Task: 2, loss: 0.00009\n",
            "tensor(8.7335e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2742, Task: 3, loss: 0.00009\n",
            "tensor(8.7273e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2742, Task: 4, loss: 0.00009\n",
            "tensor(8.7560e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2742, Task: 5, loss: 0.00009\n",
            "tensor(2.1773e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2742, Task: 6, loss: 0.00002\n",
            "tensor(9.5634e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2742, Task: 7, loss: 0.00001\n",
            "tensor(9.4902e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2742, Task: 8, loss: 0.00001\n",
            "tensor(8.3219e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6090e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2743, Task: 0, loss: 0.00009\n",
            "tensor(8.7509e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2743, Task: 1, loss: 0.00009\n",
            "tensor(8.7163e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2743, Task: 2, loss: 0.00009\n",
            "tensor(8.7326e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2743, Task: 3, loss: 0.00009\n",
            "tensor(8.7265e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2743, Task: 4, loss: 0.00009\n",
            "tensor(8.7551e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2743, Task: 5, loss: 0.00009\n",
            "tensor(2.1774e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2743, Task: 6, loss: 0.00002\n",
            "tensor(9.5668e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2743, Task: 7, loss: 0.00001\n",
            "tensor(9.4939e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2743, Task: 8, loss: 0.00001\n",
            "tensor(8.3234e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6088e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2744, Task: 0, loss: 0.00009\n",
            "tensor(8.7500e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2744, Task: 1, loss: 0.00009\n",
            "tensor(8.7154e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2744, Task: 2, loss: 0.00009\n",
            "tensor(8.7317e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2744, Task: 3, loss: 0.00009\n",
            "tensor(8.7256e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2744, Task: 4, loss: 0.00009\n",
            "tensor(8.7542e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2744, Task: 5, loss: 0.00009\n",
            "tensor(2.1775e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2744, Task: 6, loss: 0.00002\n",
            "tensor(9.5703e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2744, Task: 7, loss: 0.00001\n",
            "tensor(9.4975e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2744, Task: 8, loss: 0.00001\n",
            "tensor(8.3248e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6086e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2745, Task: 0, loss: 0.00009\n",
            "tensor(8.7491e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2745, Task: 1, loss: 0.00009\n",
            "tensor(8.7145e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2745, Task: 2, loss: 0.00009\n",
            "tensor(8.7308e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2745, Task: 3, loss: 0.00009\n",
            "tensor(8.7247e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2745, Task: 4, loss: 0.00009\n",
            "tensor(8.7533e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2745, Task: 5, loss: 0.00009\n",
            "tensor(2.1776e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2745, Task: 6, loss: 0.00002\n",
            "tensor(9.5737e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2745, Task: 7, loss: 0.00001\n",
            "tensor(9.5012e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2745, Task: 8, loss: 0.00001\n",
            "tensor(8.3263e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6084e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2746, Task: 0, loss: 0.00009\n",
            "tensor(8.7482e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2746, Task: 1, loss: 0.00009\n",
            "tensor(8.7136e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2746, Task: 2, loss: 0.00009\n",
            "tensor(8.7300e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2746, Task: 3, loss: 0.00009\n",
            "tensor(8.7238e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2746, Task: 4, loss: 0.00009\n",
            "tensor(8.7524e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2746, Task: 5, loss: 0.00009\n",
            "tensor(2.1777e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2746, Task: 6, loss: 0.00002\n",
            "tensor(9.5772e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2746, Task: 7, loss: 0.00001\n",
            "tensor(9.5048e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2746, Task: 8, loss: 0.00001\n",
            "tensor(8.3278e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6082e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2747, Task: 0, loss: 0.00009\n",
            "tensor(8.7473e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2747, Task: 1, loss: 0.00009\n",
            "tensor(8.7128e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2747, Task: 2, loss: 0.00009\n",
            "tensor(8.7291e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2747, Task: 3, loss: 0.00009\n",
            "tensor(8.7229e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2747, Task: 4, loss: 0.00009\n",
            "tensor(8.7516e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2747, Task: 5, loss: 0.00009\n",
            "tensor(2.1778e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2747, Task: 6, loss: 0.00002\n",
            "tensor(9.5806e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2747, Task: 7, loss: 0.00001\n",
            "tensor(9.5085e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2747, Task: 8, loss: 0.00001\n",
            "tensor(8.3292e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6080e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2748, Task: 0, loss: 0.00009\n",
            "tensor(8.7465e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2748, Task: 1, loss: 0.00009\n",
            "tensor(8.7119e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2748, Task: 2, loss: 0.00009\n",
            "tensor(8.7282e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2748, Task: 3, loss: 0.00009\n",
            "tensor(8.7221e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2748, Task: 4, loss: 0.00009\n",
            "tensor(8.7507e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2748, Task: 5, loss: 0.00009\n",
            "tensor(2.1779e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2748, Task: 6, loss: 0.00002\n",
            "tensor(9.5840e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2748, Task: 7, loss: 0.00001\n",
            "tensor(9.5121e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2748, Task: 8, loss: 0.00001\n",
            "tensor(8.3307e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6078e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2749, Task: 0, loss: 0.00009\n",
            "tensor(8.7456e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2749, Task: 1, loss: 0.00009\n",
            "tensor(8.7110e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2749, Task: 2, loss: 0.00009\n",
            "tensor(8.7273e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2749, Task: 3, loss: 0.00009\n",
            "tensor(8.7212e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2749, Task: 4, loss: 0.00009\n",
            "tensor(8.7498e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2749, Task: 5, loss: 0.00009\n",
            "tensor(2.1781e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2749, Task: 6, loss: 0.00002\n",
            "tensor(9.5875e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2749, Task: 7, loss: 0.00001\n",
            "tensor(9.5158e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2749, Task: 8, loss: 0.00001\n",
            "tensor(8.3322e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6075e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2750, Task: 0, loss: 0.00009\n",
            "tensor(8.7447e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2750, Task: 1, loss: 0.00009\n",
            "tensor(8.7101e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2750, Task: 2, loss: 0.00009\n",
            "tensor(8.7265e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2750, Task: 3, loss: 0.00009\n",
            "tensor(8.7203e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2750, Task: 4, loss: 0.00009\n",
            "tensor(8.7489e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2750, Task: 5, loss: 0.00009\n",
            "tensor(2.1782e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2750, Task: 6, loss: 0.00002\n",
            "tensor(9.5909e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2750, Task: 7, loss: 0.00001\n",
            "tensor(9.5194e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2750, Task: 8, loss: 0.00001\n",
            "tensor(8.3336e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6073e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2751, Task: 0, loss: 0.00009\n",
            "tensor(8.7438e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2751, Task: 1, loss: 0.00009\n",
            "tensor(8.7093e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2751, Task: 2, loss: 0.00009\n",
            "tensor(8.7256e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2751, Task: 3, loss: 0.00009\n",
            "tensor(8.7194e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2751, Task: 4, loss: 0.00009\n",
            "tensor(8.7480e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2751, Task: 5, loss: 0.00009\n",
            "tensor(2.1783e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2751, Task: 6, loss: 0.00002\n",
            "tensor(9.5943e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2751, Task: 7, loss: 0.00001\n",
            "tensor(9.5231e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2751, Task: 8, loss: 0.00001\n",
            "tensor(8.3351e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6071e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2752, Task: 0, loss: 0.00009\n",
            "tensor(8.7430e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2752, Task: 1, loss: 0.00009\n",
            "tensor(8.7084e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2752, Task: 2, loss: 0.00009\n",
            "tensor(8.7247e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2752, Task: 3, loss: 0.00009\n",
            "tensor(8.7186e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2752, Task: 4, loss: 0.00009\n",
            "tensor(8.7472e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2752, Task: 5, loss: 0.00009\n",
            "tensor(2.1784e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2752, Task: 6, loss: 0.00002\n",
            "tensor(9.5977e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2752, Task: 7, loss: 0.00001\n",
            "tensor(9.5267e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2752, Task: 8, loss: 0.00001\n",
            "tensor(8.3366e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6069e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2753, Task: 0, loss: 0.00009\n",
            "tensor(8.7421e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2753, Task: 1, loss: 0.00009\n",
            "tensor(8.7075e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2753, Task: 2, loss: 0.00009\n",
            "tensor(8.7238e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2753, Task: 3, loss: 0.00009\n",
            "tensor(8.7177e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2753, Task: 4, loss: 0.00009\n",
            "tensor(8.7463e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2753, Task: 5, loss: 0.00009\n",
            "tensor(2.1785e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2753, Task: 6, loss: 0.00002\n",
            "tensor(9.6012e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2753, Task: 7, loss: 0.00001\n",
            "tensor(9.5304e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2753, Task: 8, loss: 0.00001\n",
            "tensor(8.3380e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6067e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2754, Task: 0, loss: 0.00009\n",
            "tensor(8.7412e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2754, Task: 1, loss: 0.00009\n",
            "tensor(8.7067e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2754, Task: 2, loss: 0.00009\n",
            "tensor(8.7230e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2754, Task: 3, loss: 0.00009\n",
            "tensor(8.7168e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2754, Task: 4, loss: 0.00009\n",
            "tensor(8.7454e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2754, Task: 5, loss: 0.00009\n",
            "tensor(2.1786e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2754, Task: 6, loss: 0.00002\n",
            "tensor(9.6046e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2754, Task: 7, loss: 0.00001\n",
            "tensor(9.5340e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2754, Task: 8, loss: 0.00001\n",
            "tensor(8.3395e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6065e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2755, Task: 0, loss: 0.00009\n",
            "tensor(8.7403e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2755, Task: 1, loss: 0.00009\n",
            "tensor(8.7058e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2755, Task: 2, loss: 0.00009\n",
            "tensor(8.7221e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2755, Task: 3, loss: 0.00009\n",
            "tensor(8.7160e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2755, Task: 4, loss: 0.00009\n",
            "tensor(8.7446e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2755, Task: 5, loss: 0.00009\n",
            "tensor(2.1787e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2755, Task: 6, loss: 0.00002\n",
            "tensor(9.6080e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2755, Task: 7, loss: 0.00001\n",
            "tensor(9.5376e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2755, Task: 8, loss: 0.00001\n",
            "tensor(8.3409e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6063e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2756, Task: 0, loss: 0.00009\n",
            "tensor(8.7395e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2756, Task: 1, loss: 0.00009\n",
            "tensor(8.7049e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2756, Task: 2, loss: 0.00009\n",
            "tensor(8.7212e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2756, Task: 3, loss: 0.00009\n",
            "tensor(8.7151e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2756, Task: 4, loss: 0.00009\n",
            "tensor(8.7437e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2756, Task: 5, loss: 0.00009\n",
            "tensor(2.1788e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2756, Task: 6, loss: 0.00002\n",
            "tensor(9.6114e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2756, Task: 7, loss: 0.00001\n",
            "tensor(9.5413e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2756, Task: 8, loss: 0.00001\n",
            "tensor(8.3424e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6061e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2757, Task: 0, loss: 0.00009\n",
            "tensor(8.7386e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2757, Task: 1, loss: 0.00009\n",
            "tensor(8.7041e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2757, Task: 2, loss: 0.00009\n",
            "tensor(8.7204e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2757, Task: 3, loss: 0.00009\n",
            "tensor(8.7142e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2757, Task: 4, loss: 0.00009\n",
            "tensor(8.7428e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2757, Task: 5, loss: 0.00009\n",
            "tensor(2.1789e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2757, Task: 6, loss: 0.00002\n",
            "tensor(9.6148e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2757, Task: 7, loss: 0.00001\n",
            "tensor(9.5449e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2757, Task: 8, loss: 0.00001\n",
            "tensor(8.3439e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6059e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2758, Task: 0, loss: 0.00009\n",
            "tensor(8.7377e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2758, Task: 1, loss: 0.00009\n",
            "tensor(8.7032e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2758, Task: 2, loss: 0.00009\n",
            "tensor(8.7195e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2758, Task: 3, loss: 0.00009\n",
            "tensor(8.7134e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2758, Task: 4, loss: 0.00009\n",
            "tensor(8.7420e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2758, Task: 5, loss: 0.00009\n",
            "tensor(2.1790e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2758, Task: 6, loss: 0.00002\n",
            "tensor(9.6183e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2758, Task: 7, loss: 0.00001\n",
            "tensor(9.5485e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2758, Task: 8, loss: 0.00001\n",
            "tensor(8.3453e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6057e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2759, Task: 0, loss: 0.00009\n",
            "tensor(8.7369e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2759, Task: 1, loss: 0.00009\n",
            "tensor(8.7023e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2759, Task: 2, loss: 0.00009\n",
            "tensor(8.7186e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2759, Task: 3, loss: 0.00009\n",
            "tensor(8.7125e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2759, Task: 4, loss: 0.00009\n",
            "tensor(8.7411e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2759, Task: 5, loss: 0.00009\n",
            "tensor(2.1791e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2759, Task: 6, loss: 0.00002\n",
            "tensor(9.6217e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2759, Task: 7, loss: 0.00001\n",
            "tensor(9.5522e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2759, Task: 8, loss: 0.00001\n",
            "tensor(8.3468e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6055e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2760, Task: 0, loss: 0.00009\n",
            "tensor(8.7360e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2760, Task: 1, loss: 0.00009\n",
            "tensor(8.7015e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2760, Task: 2, loss: 0.00009\n",
            "tensor(8.7178e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2760, Task: 3, loss: 0.00009\n",
            "tensor(8.7116e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2760, Task: 4, loss: 0.00009\n",
            "tensor(8.7402e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2760, Task: 5, loss: 0.00009\n",
            "tensor(2.1792e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2760, Task: 6, loss: 0.00002\n",
            "tensor(9.6251e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2760, Task: 7, loss: 0.00001\n",
            "tensor(9.5558e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2760, Task: 8, loss: 0.00001\n",
            "tensor(8.3482e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6053e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2761, Task: 0, loss: 0.00009\n",
            "tensor(8.7351e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2761, Task: 1, loss: 0.00009\n",
            "tensor(8.7006e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2761, Task: 2, loss: 0.00009\n",
            "tensor(8.7169e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2761, Task: 3, loss: 0.00009\n",
            "tensor(8.7108e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2761, Task: 4, loss: 0.00009\n",
            "tensor(8.7394e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2761, Task: 5, loss: 0.00009\n",
            "tensor(2.1794e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2761, Task: 6, loss: 0.00002\n",
            "tensor(9.6285e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2761, Task: 7, loss: 0.00001\n",
            "tensor(9.5594e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2761, Task: 8, loss: 0.00001\n",
            "tensor(8.3497e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6051e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2762, Task: 0, loss: 0.00009\n",
            "tensor(8.7343e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2762, Task: 1, loss: 0.00009\n",
            "tensor(8.6997e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2762, Task: 2, loss: 0.00009\n",
            "tensor(8.7160e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2762, Task: 3, loss: 0.00009\n",
            "tensor(8.7099e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2762, Task: 4, loss: 0.00009\n",
            "tensor(8.7385e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2762, Task: 5, loss: 0.00009\n",
            "tensor(2.1795e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2762, Task: 6, loss: 0.00002\n",
            "tensor(9.6319e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2762, Task: 7, loss: 0.00001\n",
            "tensor(9.5630e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2762, Task: 8, loss: 0.00001\n",
            "tensor(8.3512e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6049e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2763, Task: 0, loss: 0.00009\n",
            "tensor(8.7334e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2763, Task: 1, loss: 0.00009\n",
            "tensor(8.6989e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2763, Task: 2, loss: 0.00009\n",
            "tensor(8.7152e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2763, Task: 3, loss: 0.00009\n",
            "tensor(8.7090e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2763, Task: 4, loss: 0.00009\n",
            "tensor(8.7376e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2763, Task: 5, loss: 0.00009\n",
            "tensor(2.1796e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2763, Task: 6, loss: 0.00002\n",
            "tensor(9.6353e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2763, Task: 7, loss: 0.00001\n",
            "tensor(9.5667e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2763, Task: 8, loss: 0.00001\n",
            "tensor(8.3526e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6047e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2764, Task: 0, loss: 0.00009\n",
            "tensor(8.7326e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2764, Task: 1, loss: 0.00009\n",
            "tensor(8.6980e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2764, Task: 2, loss: 0.00009\n",
            "tensor(8.7143e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2764, Task: 3, loss: 0.00009\n",
            "tensor(8.7082e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2764, Task: 4, loss: 0.00009\n",
            "tensor(8.7368e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2764, Task: 5, loss: 0.00009\n",
            "tensor(2.1797e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2764, Task: 6, loss: 0.00002\n",
            "tensor(9.6387e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2764, Task: 7, loss: 0.00001\n",
            "tensor(9.5703e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2764, Task: 8, loss: 0.00001\n",
            "tensor(8.3541e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6045e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2765, Task: 0, loss: 0.00009\n",
            "tensor(8.7317e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2765, Task: 1, loss: 0.00009\n",
            "tensor(8.6972e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2765, Task: 2, loss: 0.00009\n",
            "tensor(8.7135e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2765, Task: 3, loss: 0.00009\n",
            "tensor(8.7073e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2765, Task: 4, loss: 0.00009\n",
            "tensor(8.7359e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2765, Task: 5, loss: 0.00009\n",
            "tensor(2.1798e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2765, Task: 6, loss: 0.00002\n",
            "tensor(9.6421e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2765, Task: 7, loss: 0.00001\n",
            "tensor(9.5739e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2765, Task: 8, loss: 0.00001\n",
            "tensor(8.3556e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6042e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2766, Task: 0, loss: 0.00009\n",
            "tensor(8.7308e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2766, Task: 1, loss: 0.00009\n",
            "tensor(8.6963e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2766, Task: 2, loss: 0.00009\n",
            "tensor(8.7126e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2766, Task: 3, loss: 0.00009\n",
            "tensor(8.7065e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2766, Task: 4, loss: 0.00009\n",
            "tensor(8.7350e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2766, Task: 5, loss: 0.00009\n",
            "tensor(2.1799e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2766, Task: 6, loss: 0.00002\n",
            "tensor(9.6455e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2766, Task: 7, loss: 0.00001\n",
            "tensor(9.5775e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2766, Task: 8, loss: 0.00001\n",
            "tensor(8.3570e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6040e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2767, Task: 0, loss: 0.00009\n",
            "tensor(8.7300e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2767, Task: 1, loss: 0.00009\n",
            "tensor(8.6954e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2767, Task: 2, loss: 0.00009\n",
            "tensor(8.7117e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2767, Task: 3, loss: 0.00009\n",
            "tensor(8.7056e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2767, Task: 4, loss: 0.00009\n",
            "tensor(8.7342e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2767, Task: 5, loss: 0.00009\n",
            "tensor(2.1800e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2767, Task: 6, loss: 0.00002\n",
            "tensor(9.6489e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2767, Task: 7, loss: 0.00001\n",
            "tensor(9.5811e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2767, Task: 8, loss: 0.00001\n",
            "tensor(8.3585e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6038e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2768, Task: 0, loss: 0.00009\n",
            "tensor(8.7291e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2768, Task: 1, loss: 0.00009\n",
            "tensor(8.6946e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2768, Task: 2, loss: 0.00009\n",
            "tensor(8.7109e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2768, Task: 3, loss: 0.00009\n",
            "tensor(8.7048e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2768, Task: 4, loss: 0.00009\n",
            "tensor(8.7333e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2768, Task: 5, loss: 0.00009\n",
            "tensor(2.1801e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2768, Task: 6, loss: 0.00002\n",
            "tensor(9.6523e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2768, Task: 7, loss: 0.00001\n",
            "tensor(9.5847e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2768, Task: 8, loss: 0.00001\n",
            "tensor(8.3599e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6036e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2769, Task: 0, loss: 0.00009\n",
            "tensor(8.7283e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2769, Task: 1, loss: 0.00009\n",
            "tensor(8.6937e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2769, Task: 2, loss: 0.00009\n",
            "tensor(8.7100e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2769, Task: 3, loss: 0.00009\n",
            "tensor(8.7039e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2769, Task: 4, loss: 0.00009\n",
            "tensor(8.7325e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2769, Task: 5, loss: 0.00009\n",
            "tensor(2.1802e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2769, Task: 6, loss: 0.00002\n",
            "tensor(9.6556e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2769, Task: 7, loss: 0.00001\n",
            "tensor(9.5883e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2769, Task: 8, loss: 0.00001\n",
            "tensor(8.3614e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6034e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2770, Task: 0, loss: 0.00009\n",
            "tensor(8.7274e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2770, Task: 1, loss: 0.00009\n",
            "tensor(8.6929e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2770, Task: 2, loss: 0.00009\n",
            "tensor(8.7092e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2770, Task: 3, loss: 0.00009\n",
            "tensor(8.7030e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2770, Task: 4, loss: 0.00009\n",
            "tensor(8.7316e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2770, Task: 5, loss: 0.00009\n",
            "tensor(2.1803e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2770, Task: 6, loss: 0.00002\n",
            "tensor(9.6590e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2770, Task: 7, loss: 0.00001\n",
            "tensor(9.5919e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2770, Task: 8, loss: 0.00001\n",
            "tensor(8.3628e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6032e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2771, Task: 0, loss: 0.00009\n",
            "tensor(8.7265e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2771, Task: 1, loss: 0.00009\n",
            "tensor(8.6920e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2771, Task: 2, loss: 0.00009\n",
            "tensor(8.7083e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2771, Task: 3, loss: 0.00009\n",
            "tensor(8.7022e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2771, Task: 4, loss: 0.00009\n",
            "tensor(8.7308e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2771, Task: 5, loss: 0.00009\n",
            "tensor(2.1804e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2771, Task: 6, loss: 0.00002\n",
            "tensor(9.6624e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2771, Task: 7, loss: 0.00001\n",
            "tensor(9.5955e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2771, Task: 8, loss: 0.00001\n",
            "tensor(8.3643e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6030e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2772, Task: 0, loss: 0.00009\n",
            "tensor(8.7257e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2772, Task: 1, loss: 0.00009\n",
            "tensor(8.6912e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2772, Task: 2, loss: 0.00009\n",
            "tensor(8.7075e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2772, Task: 3, loss: 0.00009\n",
            "tensor(8.7013e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2772, Task: 4, loss: 0.00009\n",
            "tensor(8.7299e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2772, Task: 5, loss: 0.00009\n",
            "tensor(2.1805e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2772, Task: 6, loss: 0.00002\n",
            "tensor(9.6658e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2772, Task: 7, loss: 0.00001\n",
            "tensor(9.5991e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2772, Task: 8, loss: 0.00001\n",
            "tensor(8.3657e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6028e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2773, Task: 0, loss: 0.00009\n",
            "tensor(8.7248e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2773, Task: 1, loss: 0.00009\n",
            "tensor(8.6903e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2773, Task: 2, loss: 0.00009\n",
            "tensor(8.7066e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2773, Task: 3, loss: 0.00009\n",
            "tensor(8.7005e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2773, Task: 4, loss: 0.00009\n",
            "tensor(8.7291e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2773, Task: 5, loss: 0.00009\n",
            "tensor(2.1807e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2773, Task: 6, loss: 0.00002\n",
            "tensor(9.6692e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2773, Task: 7, loss: 0.00001\n",
            "tensor(9.6027e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2773, Task: 8, loss: 0.00001\n",
            "tensor(8.3672e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6026e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2774, Task: 0, loss: 0.00009\n",
            "tensor(8.7240e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2774, Task: 1, loss: 0.00009\n",
            "tensor(8.6895e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2774, Task: 2, loss: 0.00009\n",
            "tensor(8.7058e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2774, Task: 3, loss: 0.00009\n",
            "tensor(8.6996e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2774, Task: 4, loss: 0.00009\n",
            "tensor(8.7282e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2774, Task: 5, loss: 0.00009\n",
            "tensor(2.1808e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2774, Task: 6, loss: 0.00002\n",
            "tensor(9.6726e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2774, Task: 7, loss: 0.00001\n",
            "tensor(9.6063e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2774, Task: 8, loss: 0.00001\n",
            "tensor(8.3686e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6024e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2775, Task: 0, loss: 0.00009\n",
            "tensor(8.7231e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2775, Task: 1, loss: 0.00009\n",
            "tensor(8.6886e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2775, Task: 2, loss: 0.00009\n",
            "tensor(8.7049e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2775, Task: 3, loss: 0.00009\n",
            "tensor(8.6988e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2775, Task: 4, loss: 0.00009\n",
            "tensor(8.7274e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2775, Task: 5, loss: 0.00009\n",
            "tensor(2.1809e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2775, Task: 6, loss: 0.00002\n",
            "tensor(9.6759e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2775, Task: 7, loss: 0.00001\n",
            "tensor(9.6099e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2775, Task: 8, loss: 0.00001\n",
            "tensor(8.3701e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6022e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2776, Task: 0, loss: 0.00009\n",
            "tensor(8.7223e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2776, Task: 1, loss: 0.00009\n",
            "tensor(8.6878e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2776, Task: 2, loss: 0.00009\n",
            "tensor(8.7041e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2776, Task: 3, loss: 0.00009\n",
            "tensor(8.6979e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2776, Task: 4, loss: 0.00009\n",
            "tensor(8.7265e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2776, Task: 5, loss: 0.00009\n",
            "tensor(2.1810e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2776, Task: 6, loss: 0.00002\n",
            "tensor(9.6793e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2776, Task: 7, loss: 0.00001\n",
            "tensor(9.6135e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2776, Task: 8, loss: 0.00001\n",
            "tensor(8.3715e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6020e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2777, Task: 0, loss: 0.00009\n",
            "tensor(8.7214e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2777, Task: 1, loss: 0.00009\n",
            "tensor(8.6869e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2777, Task: 2, loss: 0.00009\n",
            "tensor(8.7032e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2777, Task: 3, loss: 0.00009\n",
            "tensor(8.6971e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2777, Task: 4, loss: 0.00009\n",
            "tensor(8.7257e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2777, Task: 5, loss: 0.00009\n",
            "tensor(2.1811e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2777, Task: 6, loss: 0.00002\n",
            "tensor(9.6826e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2777, Task: 7, loss: 0.00001\n",
            "tensor(9.6171e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2777, Task: 8, loss: 0.00001\n",
            "tensor(8.3730e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6018e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2778, Task: 0, loss: 0.00009\n",
            "tensor(8.7206e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2778, Task: 1, loss: 0.00009\n",
            "tensor(8.6861e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2778, Task: 2, loss: 0.00009\n",
            "tensor(8.7024e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2778, Task: 3, loss: 0.00009\n",
            "tensor(8.6963e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2778, Task: 4, loss: 0.00009\n",
            "tensor(8.7248e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2778, Task: 5, loss: 0.00009\n",
            "tensor(2.1812e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2778, Task: 6, loss: 0.00002\n",
            "tensor(9.6860e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2778, Task: 7, loss: 0.00001\n",
            "tensor(9.6207e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2778, Task: 8, loss: 0.00001\n",
            "tensor(8.3744e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6016e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2779, Task: 0, loss: 0.00009\n",
            "tensor(8.7198e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2779, Task: 1, loss: 0.00009\n",
            "tensor(8.6853e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2779, Task: 2, loss: 0.00009\n",
            "tensor(8.7015e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2779, Task: 3, loss: 0.00009\n",
            "tensor(8.6954e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2779, Task: 4, loss: 0.00009\n",
            "tensor(8.7240e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2779, Task: 5, loss: 0.00009\n",
            "tensor(2.1813e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2779, Task: 6, loss: 0.00002\n",
            "tensor(9.6894e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2779, Task: 7, loss: 0.00001\n",
            "tensor(9.6243e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2779, Task: 8, loss: 0.00001\n",
            "tensor(8.3759e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6014e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2780, Task: 0, loss: 0.00009\n",
            "tensor(8.7189e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2780, Task: 1, loss: 0.00009\n",
            "tensor(8.6844e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2780, Task: 2, loss: 0.00009\n",
            "tensor(8.7007e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2780, Task: 3, loss: 0.00009\n",
            "tensor(8.6946e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2780, Task: 4, loss: 0.00009\n",
            "tensor(8.7231e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2780, Task: 5, loss: 0.00009\n",
            "tensor(2.1814e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2780, Task: 6, loss: 0.00002\n",
            "tensor(9.6928e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2780, Task: 7, loss: 0.00001\n",
            "tensor(9.6278e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2780, Task: 8, loss: 0.00001\n",
            "tensor(8.3773e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6012e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2781, Task: 0, loss: 0.00009\n",
            "tensor(8.7181e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2781, Task: 1, loss: 0.00009\n",
            "tensor(8.6836e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2781, Task: 2, loss: 0.00009\n",
            "tensor(8.6999e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2781, Task: 3, loss: 0.00009\n",
            "tensor(8.6937e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2781, Task: 4, loss: 0.00009\n",
            "tensor(8.7223e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2781, Task: 5, loss: 0.00009\n",
            "tensor(2.1815e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2781, Task: 6, loss: 0.00002\n",
            "tensor(9.6961e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2781, Task: 7, loss: 0.00001\n",
            "tensor(9.6314e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2781, Task: 8, loss: 0.00001\n",
            "tensor(8.3788e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6011e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2782, Task: 0, loss: 0.00009\n",
            "tensor(8.7172e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2782, Task: 1, loss: 0.00009\n",
            "tensor(8.6827e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2782, Task: 2, loss: 0.00009\n",
            "tensor(8.6990e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2782, Task: 3, loss: 0.00009\n",
            "tensor(8.6929e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2782, Task: 4, loss: 0.00009\n",
            "tensor(8.7214e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2782, Task: 5, loss: 0.00009\n",
            "tensor(2.1816e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2782, Task: 6, loss: 0.00002\n",
            "tensor(9.6995e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2782, Task: 7, loss: 0.00001\n",
            "tensor(9.6350e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2782, Task: 8, loss: 0.00001\n",
            "tensor(8.3802e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6009e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2783, Task: 0, loss: 0.00009\n",
            "tensor(8.7164e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2783, Task: 1, loss: 0.00009\n",
            "tensor(8.6819e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2783, Task: 2, loss: 0.00009\n",
            "tensor(8.6982e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2783, Task: 3, loss: 0.00009\n",
            "tensor(8.6920e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2783, Task: 4, loss: 0.00009\n",
            "tensor(8.7206e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2783, Task: 5, loss: 0.00009\n",
            "tensor(2.1817e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2783, Task: 6, loss: 0.00002\n",
            "tensor(9.7028e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2783, Task: 7, loss: 0.00001\n",
            "tensor(9.6386e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2783, Task: 8, loss: 0.00001\n",
            "tensor(8.3817e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6007e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2784, Task: 0, loss: 0.00009\n",
            "tensor(8.7155e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2784, Task: 1, loss: 0.00009\n",
            "tensor(8.6811e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2784, Task: 2, loss: 0.00009\n",
            "tensor(8.6973e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2784, Task: 3, loss: 0.00009\n",
            "tensor(8.6912e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2784, Task: 4, loss: 0.00009\n",
            "tensor(8.7197e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2784, Task: 5, loss: 0.00009\n",
            "tensor(2.1818e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2784, Task: 6, loss: 0.00002\n",
            "tensor(9.7062e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2784, Task: 7, loss: 0.00001\n",
            "tensor(9.6421e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2784, Task: 8, loss: 0.00001\n",
            "tensor(8.3831e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6005e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2785, Task: 0, loss: 0.00009\n",
            "tensor(8.7147e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2785, Task: 1, loss: 0.00009\n",
            "tensor(8.6802e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2785, Task: 2, loss: 0.00009\n",
            "tensor(8.6965e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2785, Task: 3, loss: 0.00009\n",
            "tensor(8.6904e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2785, Task: 4, loss: 0.00009\n",
            "tensor(8.7189e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2785, Task: 5, loss: 0.00009\n",
            "tensor(2.1820e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2785, Task: 6, loss: 0.00002\n",
            "tensor(9.7095e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2785, Task: 7, loss: 0.00001\n",
            "tensor(9.6457e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2785, Task: 8, loss: 0.00001\n",
            "tensor(8.3845e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6003e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2786, Task: 0, loss: 0.00009\n",
            "tensor(8.7139e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2786, Task: 1, loss: 0.00009\n",
            "tensor(8.6794e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2786, Task: 2, loss: 0.00009\n",
            "tensor(8.6957e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2786, Task: 3, loss: 0.00009\n",
            "tensor(8.6895e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2786, Task: 4, loss: 0.00009\n",
            "tensor(8.7181e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2786, Task: 5, loss: 0.00009\n",
            "tensor(2.1821e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2786, Task: 6, loss: 0.00002\n",
            "tensor(9.7129e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2786, Task: 7, loss: 0.00001\n",
            "tensor(9.6493e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2786, Task: 8, loss: 0.00001\n",
            "tensor(8.3860e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.6001e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2787, Task: 0, loss: 0.00009\n",
            "tensor(8.7130e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2787, Task: 1, loss: 0.00009\n",
            "tensor(8.6785e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2787, Task: 2, loss: 0.00009\n",
            "tensor(8.6948e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2787, Task: 3, loss: 0.00009\n",
            "tensor(8.6887e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2787, Task: 4, loss: 0.00009\n",
            "tensor(8.7172e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2787, Task: 5, loss: 0.00009\n",
            "tensor(2.1822e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2787, Task: 6, loss: 0.00002\n",
            "tensor(9.7162e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2787, Task: 7, loss: 0.00001\n",
            "tensor(9.6528e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2787, Task: 8, loss: 0.00001\n",
            "tensor(8.3874e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5999e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2788, Task: 0, loss: 0.00009\n",
            "tensor(8.7122e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2788, Task: 1, loss: 0.00009\n",
            "tensor(8.6777e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2788, Task: 2, loss: 0.00009\n",
            "tensor(8.6940e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2788, Task: 3, loss: 0.00009\n",
            "tensor(8.6879e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2788, Task: 4, loss: 0.00009\n",
            "tensor(8.7164e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2788, Task: 5, loss: 0.00009\n",
            "tensor(2.1823e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2788, Task: 6, loss: 0.00002\n",
            "tensor(9.7195e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2788, Task: 7, loss: 0.00001\n",
            "tensor(9.6564e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2788, Task: 8, loss: 0.00001\n",
            "tensor(8.3888e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5997e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2789, Task: 0, loss: 0.00009\n",
            "tensor(8.7114e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2789, Task: 1, loss: 0.00009\n",
            "tensor(8.6769e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2789, Task: 2, loss: 0.00009\n",
            "tensor(8.6932e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2789, Task: 3, loss: 0.00009\n",
            "tensor(8.6870e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2789, Task: 4, loss: 0.00009\n",
            "tensor(8.7156e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2789, Task: 5, loss: 0.00009\n",
            "tensor(2.1824e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2789, Task: 6, loss: 0.00002\n",
            "tensor(9.7229e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2789, Task: 7, loss: 0.00001\n",
            "tensor(9.6599e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2789, Task: 8, loss: 0.00001\n",
            "tensor(8.3903e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5995e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2790, Task: 0, loss: 0.00009\n",
            "tensor(8.7105e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2790, Task: 1, loss: 0.00009\n",
            "tensor(8.6761e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2790, Task: 2, loss: 0.00009\n",
            "tensor(8.6923e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2790, Task: 3, loss: 0.00009\n",
            "tensor(8.6862e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2790, Task: 4, loss: 0.00009\n",
            "tensor(8.7147e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2790, Task: 5, loss: 0.00009\n",
            "tensor(2.1825e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2790, Task: 6, loss: 0.00002\n",
            "tensor(9.7262e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2790, Task: 7, loss: 0.00001\n",
            "tensor(9.6635e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2790, Task: 8, loss: 0.00001\n",
            "tensor(8.3917e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5993e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2791, Task: 0, loss: 0.00009\n",
            "tensor(8.7097e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2791, Task: 1, loss: 0.00009\n",
            "tensor(8.6752e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2791, Task: 2, loss: 0.00009\n",
            "tensor(8.6915e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2791, Task: 3, loss: 0.00009\n",
            "tensor(8.6854e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2791, Task: 4, loss: 0.00009\n",
            "tensor(8.7139e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2791, Task: 5, loss: 0.00009\n",
            "tensor(2.1826e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2791, Task: 6, loss: 0.00002\n",
            "tensor(9.7296e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2791, Task: 7, loss: 0.00001\n",
            "tensor(9.6670e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2791, Task: 8, loss: 0.00001\n",
            "tensor(8.3931e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5991e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2792, Task: 0, loss: 0.00009\n",
            "tensor(8.7089e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2792, Task: 1, loss: 0.00009\n",
            "tensor(8.6744e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2792, Task: 2, loss: 0.00009\n",
            "tensor(8.6907e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2792, Task: 3, loss: 0.00009\n",
            "tensor(8.6845e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2792, Task: 4, loss: 0.00009\n",
            "tensor(8.7131e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2792, Task: 5, loss: 0.00009\n",
            "tensor(2.1827e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2792, Task: 6, loss: 0.00002\n",
            "tensor(9.7329e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2792, Task: 7, loss: 0.00001\n",
            "tensor(9.6706e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2792, Task: 8, loss: 0.00001\n",
            "tensor(8.3946e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5989e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2793, Task: 0, loss: 0.00009\n",
            "tensor(8.7080e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2793, Task: 1, loss: 0.00009\n",
            "tensor(8.6736e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2793, Task: 2, loss: 0.00009\n",
            "tensor(8.6898e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2793, Task: 3, loss: 0.00009\n",
            "tensor(8.6837e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2793, Task: 4, loss: 0.00009\n",
            "tensor(8.7122e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2793, Task: 5, loss: 0.00009\n",
            "tensor(2.1828e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2793, Task: 6, loss: 0.00002\n",
            "tensor(9.7362e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2793, Task: 7, loss: 0.00001\n",
            "tensor(9.6741e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2793, Task: 8, loss: 0.00001\n",
            "tensor(8.3960e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5987e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2794, Task: 0, loss: 0.00009\n",
            "tensor(8.7072e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2794, Task: 1, loss: 0.00009\n",
            "tensor(8.6727e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2794, Task: 2, loss: 0.00009\n",
            "tensor(8.6890e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2794, Task: 3, loss: 0.00009\n",
            "tensor(8.6829e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2794, Task: 4, loss: 0.00009\n",
            "tensor(8.7114e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2794, Task: 5, loss: 0.00009\n",
            "tensor(2.1829e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2794, Task: 6, loss: 0.00002\n",
            "tensor(9.7395e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2794, Task: 7, loss: 0.00001\n",
            "tensor(9.6777e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2794, Task: 8, loss: 0.00001\n",
            "tensor(8.3974e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5985e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2795, Task: 0, loss: 0.00009\n",
            "tensor(8.7064e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2795, Task: 1, loss: 0.00009\n",
            "tensor(8.6719e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2795, Task: 2, loss: 0.00009\n",
            "tensor(8.6882e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2795, Task: 3, loss: 0.00009\n",
            "tensor(8.6821e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2795, Task: 4, loss: 0.00009\n",
            "tensor(8.7106e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2795, Task: 5, loss: 0.00009\n",
            "tensor(2.1830e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2795, Task: 6, loss: 0.00002\n",
            "tensor(9.7428e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2795, Task: 7, loss: 0.00001\n",
            "tensor(9.6812e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2795, Task: 8, loss: 0.00001\n",
            "tensor(8.3989e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5983e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2796, Task: 0, loss: 0.00009\n",
            "tensor(8.7055e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2796, Task: 1, loss: 0.00009\n",
            "tensor(8.6711e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2796, Task: 2, loss: 0.00009\n",
            "tensor(8.6873e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2796, Task: 3, loss: 0.00009\n",
            "tensor(8.6812e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2796, Task: 4, loss: 0.00009\n",
            "tensor(8.7097e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2796, Task: 5, loss: 0.00009\n",
            "tensor(2.1832e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2796, Task: 6, loss: 0.00002\n",
            "tensor(9.7462e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2796, Task: 7, loss: 0.00001\n",
            "tensor(9.6848e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2796, Task: 8, loss: 0.00001\n",
            "tensor(8.4003e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5981e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2797, Task: 0, loss: 0.00009\n",
            "tensor(8.7047e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2797, Task: 1, loss: 0.00009\n",
            "tensor(8.6703e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2797, Task: 2, loss: 0.00009\n",
            "tensor(8.6865e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2797, Task: 3, loss: 0.00009\n",
            "tensor(8.6804e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2797, Task: 4, loss: 0.00009\n",
            "tensor(8.7089e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2797, Task: 5, loss: 0.00009\n",
            "tensor(2.1833e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2797, Task: 6, loss: 0.00002\n",
            "tensor(9.7495e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2797, Task: 7, loss: 0.00001\n",
            "tensor(9.6883e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2797, Task: 8, loss: 0.00001\n",
            "tensor(8.4017e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5980e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2798, Task: 0, loss: 0.00009\n",
            "tensor(8.7039e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2798, Task: 1, loss: 0.00009\n",
            "tensor(8.6694e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2798, Task: 2, loss: 0.00009\n",
            "tensor(8.6857e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2798, Task: 3, loss: 0.00009\n",
            "tensor(8.6796e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2798, Task: 4, loss: 0.00009\n",
            "tensor(8.7081e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2798, Task: 5, loss: 0.00009\n",
            "tensor(2.1834e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2798, Task: 6, loss: 0.00002\n",
            "tensor(9.7528e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2798, Task: 7, loss: 0.00001\n",
            "tensor(9.6918e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2798, Task: 8, loss: 0.00001\n",
            "tensor(8.4031e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5978e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2799, Task: 0, loss: 0.00009\n",
            "tensor(8.7031e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2799, Task: 1, loss: 0.00009\n",
            "tensor(8.6686e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2799, Task: 2, loss: 0.00009\n",
            "tensor(8.6849e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2799, Task: 3, loss: 0.00009\n",
            "tensor(8.6788e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2799, Task: 4, loss: 0.00009\n",
            "tensor(8.7073e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2799, Task: 5, loss: 0.00009\n",
            "tensor(2.1835e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2799, Task: 6, loss: 0.00002\n",
            "tensor(9.7561e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2799, Task: 7, loss: 0.00001\n",
            "tensor(9.6954e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2799, Task: 8, loss: 0.00001\n",
            "tensor(8.4045e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5976e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2800, Task: 0, loss: 0.00009\n",
            "tensor(8.7022e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2800, Task: 1, loss: 0.00009\n",
            "tensor(8.6678e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2800, Task: 2, loss: 0.00009\n",
            "tensor(8.6841e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2800, Task: 3, loss: 0.00009\n",
            "tensor(8.6779e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2800, Task: 4, loss: 0.00009\n",
            "tensor(8.7064e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2800, Task: 5, loss: 0.00009\n",
            "tensor(2.1836e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2800, Task: 6, loss: 0.00002\n",
            "tensor(9.7594e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2800, Task: 7, loss: 0.00001\n",
            "tensor(9.6989e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2800, Task: 8, loss: 0.00001\n",
            "tensor(8.4060e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5974e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2801, Task: 0, loss: 0.00009\n",
            "tensor(8.7014e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2801, Task: 1, loss: 0.00009\n",
            "tensor(8.6670e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2801, Task: 2, loss: 0.00009\n",
            "tensor(8.6832e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2801, Task: 3, loss: 0.00009\n",
            "tensor(8.6771e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2801, Task: 4, loss: 0.00009\n",
            "tensor(8.7056e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2801, Task: 5, loss: 0.00009\n",
            "tensor(2.1837e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2801, Task: 6, loss: 0.00002\n",
            "tensor(9.7627e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2801, Task: 7, loss: 0.00001\n",
            "tensor(9.7024e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2801, Task: 8, loss: 0.00001\n",
            "tensor(8.4074e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5972e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2802, Task: 0, loss: 0.00009\n",
            "tensor(8.7006e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2802, Task: 1, loss: 0.00009\n",
            "tensor(8.6662e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2802, Task: 2, loss: 0.00009\n",
            "tensor(8.6824e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2802, Task: 3, loss: 0.00009\n",
            "tensor(8.6763e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2802, Task: 4, loss: 0.00009\n",
            "tensor(8.7048e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2802, Task: 5, loss: 0.00009\n",
            "tensor(2.1838e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2802, Task: 6, loss: 0.00002\n",
            "tensor(9.7660e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2802, Task: 7, loss: 0.00001\n",
            "tensor(9.7059e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2802, Task: 8, loss: 0.00001\n",
            "tensor(8.4088e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5970e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2803, Task: 0, loss: 0.00009\n",
            "tensor(8.6998e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2803, Task: 1, loss: 0.00009\n",
            "tensor(8.6653e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2803, Task: 2, loss: 0.00009\n",
            "tensor(8.6816e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2803, Task: 3, loss: 0.00009\n",
            "tensor(8.6755e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2803, Task: 4, loss: 0.00009\n",
            "tensor(8.7040e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2803, Task: 5, loss: 0.00009\n",
            "tensor(2.1839e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2803, Task: 6, loss: 0.00002\n",
            "tensor(9.7693e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2803, Task: 7, loss: 0.00001\n",
            "tensor(9.7095e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2803, Task: 8, loss: 0.00001\n",
            "tensor(8.4102e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5968e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2804, Task: 0, loss: 0.00009\n",
            "tensor(8.6990e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2804, Task: 1, loss: 0.00009\n",
            "tensor(8.6645e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2804, Task: 2, loss: 0.00009\n",
            "tensor(8.6808e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2804, Task: 3, loss: 0.00009\n",
            "tensor(8.6747e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2804, Task: 4, loss: 0.00009\n",
            "tensor(8.7032e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2804, Task: 5, loss: 0.00009\n",
            "tensor(2.1840e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2804, Task: 6, loss: 0.00002\n",
            "tensor(9.7726e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2804, Task: 7, loss: 0.00001\n",
            "tensor(9.7130e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2804, Task: 8, loss: 0.00001\n",
            "tensor(8.4116e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5966e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2805, Task: 0, loss: 0.00009\n",
            "tensor(8.6981e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2805, Task: 1, loss: 0.00009\n",
            "tensor(8.6637e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2805, Task: 2, loss: 0.00009\n",
            "tensor(8.6800e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2805, Task: 3, loss: 0.00009\n",
            "tensor(8.6738e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2805, Task: 4, loss: 0.00009\n",
            "tensor(8.7023e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2805, Task: 5, loss: 0.00009\n",
            "tensor(2.1841e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2805, Task: 6, loss: 0.00002\n",
            "tensor(9.7759e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2805, Task: 7, loss: 0.00001\n",
            "tensor(9.7165e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2805, Task: 8, loss: 0.00001\n",
            "tensor(8.4130e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5964e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2806, Task: 0, loss: 0.00009\n",
            "tensor(8.6973e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2806, Task: 1, loss: 0.00009\n",
            "tensor(8.6629e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2806, Task: 2, loss: 0.00009\n",
            "tensor(8.6791e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2806, Task: 3, loss: 0.00009\n",
            "tensor(8.6730e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2806, Task: 4, loss: 0.00009\n",
            "tensor(8.7015e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2806, Task: 5, loss: 0.00009\n",
            "tensor(2.1842e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2806, Task: 6, loss: 0.00002\n",
            "tensor(9.7792e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2806, Task: 7, loss: 0.00001\n",
            "tensor(9.7200e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2806, Task: 8, loss: 0.00001\n",
            "tensor(8.4145e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5963e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2807, Task: 0, loss: 0.00009\n",
            "tensor(8.6965e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2807, Task: 1, loss: 0.00009\n",
            "tensor(8.6621e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2807, Task: 2, loss: 0.00009\n",
            "tensor(8.6783e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2807, Task: 3, loss: 0.00009\n",
            "tensor(8.6722e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2807, Task: 4, loss: 0.00009\n",
            "tensor(8.7007e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2807, Task: 5, loss: 0.00009\n",
            "tensor(2.1843e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2807, Task: 6, loss: 0.00002\n",
            "tensor(9.7825e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2807, Task: 7, loss: 0.00001\n",
            "tensor(9.7235e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2807, Task: 8, loss: 0.00001\n",
            "tensor(8.4159e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5961e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2808, Task: 0, loss: 0.00009\n",
            "tensor(8.6957e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2808, Task: 1, loss: 0.00009\n",
            "tensor(8.6613e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2808, Task: 2, loss: 0.00009\n",
            "tensor(8.6775e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2808, Task: 3, loss: 0.00009\n",
            "tensor(8.6714e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2808, Task: 4, loss: 0.00009\n",
            "tensor(8.6999e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2808, Task: 5, loss: 0.00009\n",
            "tensor(2.1845e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2808, Task: 6, loss: 0.00002\n",
            "tensor(9.7858e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2808, Task: 7, loss: 0.00001\n",
            "tensor(9.7270e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2808, Task: 8, loss: 0.00001\n",
            "tensor(8.4173e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5959e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2809, Task: 0, loss: 0.00009\n",
            "tensor(8.6949e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2809, Task: 1, loss: 0.00009\n",
            "tensor(8.6605e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2809, Task: 2, loss: 0.00009\n",
            "tensor(8.6767e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2809, Task: 3, loss: 0.00009\n",
            "tensor(8.6706e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2809, Task: 4, loss: 0.00009\n",
            "tensor(8.6991e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2809, Task: 5, loss: 0.00009\n",
            "tensor(2.1846e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2809, Task: 6, loss: 0.00002\n",
            "tensor(9.7891e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2809, Task: 7, loss: 0.00001\n",
            "tensor(9.7305e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2809, Task: 8, loss: 0.00001\n",
            "tensor(8.4187e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5957e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2810, Task: 0, loss: 0.00009\n",
            "tensor(8.6941e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2810, Task: 1, loss: 0.00009\n",
            "tensor(8.6596e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2810, Task: 2, loss: 0.00009\n",
            "tensor(8.6759e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2810, Task: 3, loss: 0.00009\n",
            "tensor(8.6698e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2810, Task: 4, loss: 0.00009\n",
            "tensor(8.6983e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2810, Task: 5, loss: 0.00009\n",
            "tensor(2.1847e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2810, Task: 6, loss: 0.00002\n",
            "tensor(9.7923e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2810, Task: 7, loss: 0.00001\n",
            "tensor(9.7340e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2810, Task: 8, loss: 0.00001\n",
            "tensor(8.4201e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5955e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2811, Task: 0, loss: 0.00009\n",
            "tensor(8.6933e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2811, Task: 1, loss: 0.00009\n",
            "tensor(8.6588e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2811, Task: 2, loss: 0.00009\n",
            "tensor(8.6751e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2811, Task: 3, loss: 0.00009\n",
            "tensor(8.6690e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2811, Task: 4, loss: 0.00009\n",
            "tensor(8.6975e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2811, Task: 5, loss: 0.00009\n",
            "tensor(2.1848e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2811, Task: 6, loss: 0.00002\n",
            "tensor(9.7956e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2811, Task: 7, loss: 0.00001\n",
            "tensor(9.7375e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2811, Task: 8, loss: 0.00001\n",
            "tensor(8.4215e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5953e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2812, Task: 0, loss: 0.00009\n",
            "tensor(8.6924e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2812, Task: 1, loss: 0.00009\n",
            "tensor(8.6580e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2812, Task: 2, loss: 0.00009\n",
            "tensor(8.6743e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2812, Task: 3, loss: 0.00009\n",
            "tensor(8.6682e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2812, Task: 4, loss: 0.00009\n",
            "tensor(8.6966e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2812, Task: 5, loss: 0.00009\n",
            "tensor(2.1849e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2812, Task: 6, loss: 0.00002\n",
            "tensor(9.7989e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2812, Task: 7, loss: 0.00001\n",
            "tensor(9.7410e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2812, Task: 8, loss: 0.00001\n",
            "tensor(8.4229e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5951e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2813, Task: 0, loss: 0.00009\n",
            "tensor(8.6916e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2813, Task: 1, loss: 0.00009\n",
            "tensor(8.6572e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2813, Task: 2, loss: 0.00009\n",
            "tensor(8.6735e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2813, Task: 3, loss: 0.00009\n",
            "tensor(8.6674e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2813, Task: 4, loss: 0.00009\n",
            "tensor(8.6958e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2813, Task: 5, loss: 0.00009\n",
            "tensor(2.1850e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2813, Task: 6, loss: 0.00002\n",
            "tensor(9.8022e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2813, Task: 7, loss: 0.00001\n",
            "tensor(9.7445e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2813, Task: 8, loss: 0.00001\n",
            "tensor(8.4243e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5950e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2814, Task: 0, loss: 0.00009\n",
            "tensor(8.6908e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2814, Task: 1, loss: 0.00009\n",
            "tensor(8.6564e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2814, Task: 2, loss: 0.00009\n",
            "tensor(8.6727e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2814, Task: 3, loss: 0.00009\n",
            "tensor(8.6666e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2814, Task: 4, loss: 0.00009\n",
            "tensor(8.6950e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2814, Task: 5, loss: 0.00009\n",
            "tensor(2.1851e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2814, Task: 6, loss: 0.00002\n",
            "tensor(9.8054e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2814, Task: 7, loss: 0.00001\n",
            "tensor(9.7480e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2814, Task: 8, loss: 0.00001\n",
            "tensor(8.4257e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5948e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2815, Task: 0, loss: 0.00009\n",
            "tensor(8.6900e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2815, Task: 1, loss: 0.00009\n",
            "tensor(8.6556e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2815, Task: 2, loss: 0.00009\n",
            "tensor(8.6719e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2815, Task: 3, loss: 0.00009\n",
            "tensor(8.6657e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2815, Task: 4, loss: 0.00009\n",
            "tensor(8.6942e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2815, Task: 5, loss: 0.00009\n",
            "tensor(2.1852e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2815, Task: 6, loss: 0.00002\n",
            "tensor(9.8087e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2815, Task: 7, loss: 0.00001\n",
            "tensor(9.7515e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2815, Task: 8, loss: 0.00001\n",
            "tensor(8.4271e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5946e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2816, Task: 0, loss: 0.00009\n",
            "tensor(8.6892e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2816, Task: 1, loss: 0.00009\n",
            "tensor(8.6548e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2816, Task: 2, loss: 0.00009\n",
            "tensor(8.6711e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2816, Task: 3, loss: 0.00009\n",
            "tensor(8.6649e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2816, Task: 4, loss: 0.00009\n",
            "tensor(8.6934e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2816, Task: 5, loss: 0.00009\n",
            "tensor(2.1853e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2816, Task: 6, loss: 0.00002\n",
            "tensor(9.8120e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2816, Task: 7, loss: 0.00001\n",
            "tensor(9.7550e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2816, Task: 8, loss: 0.00001\n",
            "tensor(8.4285e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5944e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2817, Task: 0, loss: 0.00009\n",
            "tensor(8.6884e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2817, Task: 1, loss: 0.00009\n",
            "tensor(8.6540e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2817, Task: 2, loss: 0.00009\n",
            "tensor(8.6702e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2817, Task: 3, loss: 0.00009\n",
            "tensor(8.6641e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2817, Task: 4, loss: 0.00009\n",
            "tensor(8.6926e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2817, Task: 5, loss: 0.00009\n",
            "tensor(2.1854e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2817, Task: 6, loss: 0.00002\n",
            "tensor(9.8152e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2817, Task: 7, loss: 0.00001\n",
            "tensor(9.7585e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2817, Task: 8, loss: 0.00001\n",
            "tensor(8.4299e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5942e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2818, Task: 0, loss: 0.00009\n",
            "tensor(8.6876e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2818, Task: 1, loss: 0.00009\n",
            "tensor(8.6532e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2818, Task: 2, loss: 0.00009\n",
            "tensor(8.6694e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2818, Task: 3, loss: 0.00009\n",
            "tensor(8.6633e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2818, Task: 4, loss: 0.00009\n",
            "tensor(8.6918e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2818, Task: 5, loss: 0.00009\n",
            "tensor(2.1855e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2818, Task: 6, loss: 0.00002\n",
            "tensor(9.8185e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2818, Task: 7, loss: 0.00001\n",
            "tensor(9.7619e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2818, Task: 8, loss: 0.00001\n",
            "tensor(8.4313e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5940e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2819, Task: 0, loss: 0.00009\n",
            "tensor(8.6868e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2819, Task: 1, loss: 0.00009\n",
            "tensor(8.6524e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2819, Task: 2, loss: 0.00009\n",
            "tensor(8.6686e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2819, Task: 3, loss: 0.00009\n",
            "tensor(8.6625e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2819, Task: 4, loss: 0.00009\n",
            "tensor(8.6910e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2819, Task: 5, loss: 0.00009\n",
            "tensor(2.1857e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2819, Task: 6, loss: 0.00002\n",
            "tensor(9.8218e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2819, Task: 7, loss: 0.00001\n",
            "tensor(9.7654e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2819, Task: 8, loss: 0.00001\n",
            "tensor(8.4327e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5938e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2820, Task: 0, loss: 0.00009\n",
            "tensor(8.6860e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2820, Task: 1, loss: 0.00009\n",
            "tensor(8.6516e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2820, Task: 2, loss: 0.00009\n",
            "tensor(8.6678e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2820, Task: 3, loss: 0.00009\n",
            "tensor(8.6617e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2820, Task: 4, loss: 0.00009\n",
            "tensor(8.6902e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2820, Task: 5, loss: 0.00009\n",
            "tensor(2.1858e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2820, Task: 6, loss: 0.00002\n",
            "tensor(9.8250e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2820, Task: 7, loss: 0.00001\n",
            "tensor(9.7689e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2820, Task: 8, loss: 0.00001\n",
            "tensor(8.4341e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5937e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2821, Task: 0, loss: 0.00009\n",
            "tensor(8.6852e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2821, Task: 1, loss: 0.00009\n",
            "tensor(8.6508e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2821, Task: 2, loss: 0.00009\n",
            "tensor(8.6670e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2821, Task: 3, loss: 0.00009\n",
            "tensor(8.6609e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2821, Task: 4, loss: 0.00009\n",
            "tensor(8.6894e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2821, Task: 5, loss: 0.00009\n",
            "tensor(2.1859e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2821, Task: 6, loss: 0.00002\n",
            "tensor(9.8282e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2821, Task: 7, loss: 0.00001\n",
            "tensor(9.7724e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2821, Task: 8, loss: 0.00001\n",
            "tensor(8.4355e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5935e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2822, Task: 0, loss: 0.00009\n",
            "tensor(8.6844e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2822, Task: 1, loss: 0.00009\n",
            "tensor(8.6500e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2822, Task: 2, loss: 0.00009\n",
            "tensor(8.6662e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2822, Task: 3, loss: 0.00009\n",
            "tensor(8.6601e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2822, Task: 4, loss: 0.00009\n",
            "tensor(8.6886e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2822, Task: 5, loss: 0.00009\n",
            "tensor(2.1860e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2822, Task: 6, loss: 0.00002\n",
            "tensor(9.8315e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2822, Task: 7, loss: 0.00001\n",
            "tensor(9.7758e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2822, Task: 8, loss: 0.00001\n",
            "tensor(8.4369e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5933e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2823, Task: 0, loss: 0.00009\n",
            "tensor(8.6836e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2823, Task: 1, loss: 0.00009\n",
            "tensor(8.6492e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2823, Task: 2, loss: 0.00009\n",
            "tensor(8.6655e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2823, Task: 3, loss: 0.00009\n",
            "tensor(8.6593e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2823, Task: 4, loss: 0.00009\n",
            "tensor(8.6878e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2823, Task: 5, loss: 0.00009\n",
            "tensor(2.1861e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2823, Task: 6, loss: 0.00002\n",
            "tensor(9.8347e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2823, Task: 7, loss: 0.00001\n",
            "tensor(9.7793e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2823, Task: 8, loss: 0.00001\n",
            "tensor(8.4382e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5931e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2824, Task: 0, loss: 0.00009\n",
            "tensor(8.6828e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2824, Task: 1, loss: 0.00009\n",
            "tensor(8.6484e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2824, Task: 2, loss: 0.00009\n",
            "tensor(8.6647e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2824, Task: 3, loss: 0.00009\n",
            "tensor(8.6586e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2824, Task: 4, loss: 0.00009\n",
            "tensor(8.6870e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2824, Task: 5, loss: 0.00009\n",
            "tensor(2.1862e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2824, Task: 6, loss: 0.00002\n",
            "tensor(9.8380e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2824, Task: 7, loss: 0.00001\n",
            "tensor(9.7828e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2824, Task: 8, loss: 0.00001\n",
            "tensor(8.4396e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5929e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2825, Task: 0, loss: 0.00009\n",
            "tensor(8.6820e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2825, Task: 1, loss: 0.00009\n",
            "tensor(8.6476e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2825, Task: 2, loss: 0.00009\n",
            "tensor(8.6639e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2825, Task: 3, loss: 0.00009\n",
            "tensor(8.6578e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2825, Task: 4, loss: 0.00009\n",
            "tensor(8.6862e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2825, Task: 5, loss: 0.00009\n",
            "tensor(2.1863e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2825, Task: 6, loss: 0.00002\n",
            "tensor(9.8412e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2825, Task: 7, loss: 0.00001\n",
            "tensor(9.7862e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2825, Task: 8, loss: 0.00001\n",
            "tensor(8.4410e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5928e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2826, Task: 0, loss: 0.00009\n",
            "tensor(8.6812e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2826, Task: 1, loss: 0.00009\n",
            "tensor(8.6468e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2826, Task: 2, loss: 0.00009\n",
            "tensor(8.6631e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2826, Task: 3, loss: 0.00009\n",
            "tensor(8.6570e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2826, Task: 4, loss: 0.00009\n",
            "tensor(8.6854e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2826, Task: 5, loss: 0.00009\n",
            "tensor(2.1864e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2826, Task: 6, loss: 0.00002\n",
            "tensor(9.8445e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2826, Task: 7, loss: 0.00001\n",
            "tensor(9.7897e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2826, Task: 8, loss: 0.00001\n",
            "tensor(8.4424e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5926e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2827, Task: 0, loss: 0.00009\n",
            "tensor(8.6804e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2827, Task: 1, loss: 0.00009\n",
            "tensor(8.6461e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2827, Task: 2, loss: 0.00009\n",
            "tensor(8.6623e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2827, Task: 3, loss: 0.00009\n",
            "tensor(8.6562e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2827, Task: 4, loss: 0.00009\n",
            "tensor(8.6846e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2827, Task: 5, loss: 0.00009\n",
            "tensor(2.1865e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2827, Task: 6, loss: 0.00002\n",
            "tensor(9.8477e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2827, Task: 7, loss: 0.00001\n",
            "tensor(9.7931e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2827, Task: 8, loss: 0.00001\n",
            "tensor(8.4438e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5924e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2828, Task: 0, loss: 0.00009\n",
            "tensor(8.6796e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2828, Task: 1, loss: 0.00009\n",
            "tensor(8.6453e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2828, Task: 2, loss: 0.00009\n",
            "tensor(8.6615e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2828, Task: 3, loss: 0.00009\n",
            "tensor(8.6554e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2828, Task: 4, loss: 0.00009\n",
            "tensor(8.6838e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2828, Task: 5, loss: 0.00009\n",
            "tensor(2.1866e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2828, Task: 6, loss: 0.00002\n",
            "tensor(9.8509e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2828, Task: 7, loss: 0.00001\n",
            "tensor(9.7966e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2828, Task: 8, loss: 0.00001\n",
            "tensor(8.4452e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5922e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2829, Task: 0, loss: 0.00009\n",
            "tensor(8.6788e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2829, Task: 1, loss: 0.00009\n",
            "tensor(8.6445e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2829, Task: 2, loss: 0.00009\n",
            "tensor(8.6607e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2829, Task: 3, loss: 0.00009\n",
            "tensor(8.6546e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2829, Task: 4, loss: 0.00009\n",
            "tensor(8.6830e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2829, Task: 5, loss: 0.00009\n",
            "tensor(2.1867e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2829, Task: 6, loss: 0.00002\n",
            "tensor(9.8541e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2829, Task: 7, loss: 0.00001\n",
            "tensor(9.8000e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2829, Task: 8, loss: 0.00001\n",
            "tensor(8.4465e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5920e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2830, Task: 0, loss: 0.00009\n",
            "tensor(8.6781e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2830, Task: 1, loss: 0.00009\n",
            "tensor(8.6437e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2830, Task: 2, loss: 0.00009\n",
            "tensor(8.6599e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2830, Task: 3, loss: 0.00009\n",
            "tensor(8.6538e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2830, Task: 4, loss: 0.00009\n",
            "tensor(8.6822e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2830, Task: 5, loss: 0.00009\n",
            "tensor(2.1868e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2830, Task: 6, loss: 0.00002\n",
            "tensor(9.8574e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2830, Task: 7, loss: 0.00001\n",
            "tensor(9.8035e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2830, Task: 8, loss: 0.00001\n",
            "tensor(8.4479e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5919e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2831, Task: 0, loss: 0.00009\n",
            "tensor(8.6773e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2831, Task: 1, loss: 0.00009\n",
            "tensor(8.6429e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2831, Task: 2, loss: 0.00009\n",
            "tensor(8.6591e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2831, Task: 3, loss: 0.00009\n",
            "tensor(8.6530e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2831, Task: 4, loss: 0.00009\n",
            "tensor(8.6815e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2831, Task: 5, loss: 0.00009\n",
            "tensor(2.1870e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2831, Task: 6, loss: 0.00002\n",
            "tensor(9.8606e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2831, Task: 7, loss: 0.00001\n",
            "tensor(9.8069e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2831, Task: 8, loss: 0.00001\n",
            "tensor(8.4493e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5917e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2832, Task: 0, loss: 0.00009\n",
            "tensor(8.6765e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2832, Task: 1, loss: 0.00009\n",
            "tensor(8.6421e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2832, Task: 2, loss: 0.00009\n",
            "tensor(8.6583e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2832, Task: 3, loss: 0.00009\n",
            "tensor(8.6522e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2832, Task: 4, loss: 0.00009\n",
            "tensor(8.6807e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2832, Task: 5, loss: 0.00009\n",
            "tensor(2.1871e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2832, Task: 6, loss: 0.00002\n",
            "tensor(9.8638e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2832, Task: 7, loss: 0.00001\n",
            "tensor(9.8104e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2832, Task: 8, loss: 0.00001\n",
            "tensor(8.4506e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5915e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2833, Task: 0, loss: 0.00009\n",
            "tensor(8.6757e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2833, Task: 1, loss: 0.00009\n",
            "tensor(8.6413e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2833, Task: 2, loss: 0.00009\n",
            "tensor(8.6575e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2833, Task: 3, loss: 0.00009\n",
            "tensor(8.6514e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2833, Task: 4, loss: 0.00009\n",
            "tensor(8.6799e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2833, Task: 5, loss: 0.00009\n",
            "tensor(2.1872e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2833, Task: 6, loss: 0.00002\n",
            "tensor(9.8671e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2833, Task: 7, loss: 0.00001\n",
            "tensor(9.8138e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2833, Task: 8, loss: 0.00001\n",
            "tensor(8.4520e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5913e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2834, Task: 0, loss: 0.00009\n",
            "tensor(8.6749e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2834, Task: 1, loss: 0.00009\n",
            "tensor(8.6405e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2834, Task: 2, loss: 0.00009\n",
            "tensor(8.6568e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2834, Task: 3, loss: 0.00009\n",
            "tensor(8.6507e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2834, Task: 4, loss: 0.00009\n",
            "tensor(8.6791e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2834, Task: 5, loss: 0.00009\n",
            "tensor(2.1873e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2834, Task: 6, loss: 0.00002\n",
            "tensor(9.8702e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2834, Task: 7, loss: 0.00001\n",
            "tensor(9.8172e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2834, Task: 8, loss: 0.00001\n",
            "tensor(8.4534e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5911e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2835, Task: 0, loss: 0.00009\n",
            "tensor(8.6741e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2835, Task: 1, loss: 0.00009\n",
            "tensor(8.6398e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2835, Task: 2, loss: 0.00009\n",
            "tensor(8.6560e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2835, Task: 3, loss: 0.00009\n",
            "tensor(8.6499e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2835, Task: 4, loss: 0.00009\n",
            "tensor(8.6783e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2835, Task: 5, loss: 0.00009\n",
            "tensor(2.1874e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2835, Task: 6, loss: 0.00002\n",
            "tensor(9.8734e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2835, Task: 7, loss: 0.00001\n",
            "tensor(9.8207e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2835, Task: 8, loss: 0.00001\n",
            "tensor(8.4548e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5910e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2836, Task: 0, loss: 0.00009\n",
            "tensor(8.6733e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2836, Task: 1, loss: 0.00009\n",
            "tensor(8.6390e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2836, Task: 2, loss: 0.00009\n",
            "tensor(8.6552e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2836, Task: 3, loss: 0.00009\n",
            "tensor(8.6491e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2836, Task: 4, loss: 0.00009\n",
            "tensor(8.6775e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2836, Task: 5, loss: 0.00009\n",
            "tensor(2.1875e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2836, Task: 6, loss: 0.00002\n",
            "tensor(9.8767e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2836, Task: 7, loss: 0.00001\n",
            "tensor(9.8241e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2836, Task: 8, loss: 0.00001\n",
            "tensor(8.4561e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5908e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2837, Task: 0, loss: 0.00009\n",
            "tensor(8.6726e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2837, Task: 1, loss: 0.00009\n",
            "tensor(8.6382e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2837, Task: 2, loss: 0.00009\n",
            "tensor(8.6544e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2837, Task: 3, loss: 0.00009\n",
            "tensor(8.6483e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2837, Task: 4, loss: 0.00009\n",
            "tensor(8.6767e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2837, Task: 5, loss: 0.00009\n",
            "tensor(2.1876e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2837, Task: 6, loss: 0.00002\n",
            "tensor(9.8799e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2837, Task: 7, loss: 0.00001\n",
            "tensor(9.8275e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2837, Task: 8, loss: 0.00001\n",
            "tensor(8.4575e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5906e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2838, Task: 0, loss: 0.00009\n",
            "tensor(8.6718e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2838, Task: 1, loss: 0.00009\n",
            "tensor(8.6374e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2838, Task: 2, loss: 0.00009\n",
            "tensor(8.6536e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2838, Task: 3, loss: 0.00009\n",
            "tensor(8.6475e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2838, Task: 4, loss: 0.00009\n",
            "tensor(8.6760e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2838, Task: 5, loss: 0.00009\n",
            "tensor(2.1877e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2838, Task: 6, loss: 0.00002\n",
            "tensor(9.8831e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2838, Task: 7, loss: 0.00001\n",
            "tensor(9.8310e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2838, Task: 8, loss: 0.00001\n",
            "tensor(8.4588e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5904e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2839, Task: 0, loss: 0.00009\n",
            "tensor(8.6710e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2839, Task: 1, loss: 0.00009\n",
            "tensor(8.6366e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2839, Task: 2, loss: 0.00009\n",
            "tensor(8.6529e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2839, Task: 3, loss: 0.00009\n",
            "tensor(8.6468e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2839, Task: 4, loss: 0.00009\n",
            "tensor(8.6752e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2839, Task: 5, loss: 0.00009\n",
            "tensor(2.1878e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2839, Task: 6, loss: 0.00002\n",
            "tensor(9.8863e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2839, Task: 7, loss: 0.00001\n",
            "tensor(9.8344e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2839, Task: 8, loss: 0.00001\n",
            "tensor(8.4602e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5903e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2840, Task: 0, loss: 0.00009\n",
            "tensor(8.6702e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2840, Task: 1, loss: 0.00009\n",
            "tensor(8.6359e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2840, Task: 2, loss: 0.00009\n",
            "tensor(8.6521e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2840, Task: 3, loss: 0.00009\n",
            "tensor(8.6460e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2840, Task: 4, loss: 0.00009\n",
            "tensor(8.6744e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2840, Task: 5, loss: 0.00009\n",
            "tensor(2.1879e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2840, Task: 6, loss: 0.00002\n",
            "tensor(9.8895e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2840, Task: 7, loss: 0.00001\n",
            "tensor(9.8378e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2840, Task: 8, loss: 0.00001\n",
            "tensor(8.4616e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5901e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2841, Task: 0, loss: 0.00009\n",
            "tensor(8.6694e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2841, Task: 1, loss: 0.00009\n",
            "tensor(8.6351e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2841, Task: 2, loss: 0.00009\n",
            "tensor(8.6513e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2841, Task: 3, loss: 0.00009\n",
            "tensor(8.6452e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2841, Task: 4, loss: 0.00009\n",
            "tensor(8.6736e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2841, Task: 5, loss: 0.00009\n",
            "tensor(2.1880e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2841, Task: 6, loss: 0.00002\n",
            "tensor(9.8927e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2841, Task: 7, loss: 0.00001\n",
            "tensor(9.8412e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2841, Task: 8, loss: 0.00001\n",
            "tensor(8.4629e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5899e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2842, Task: 0, loss: 0.00009\n",
            "tensor(8.6687e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2842, Task: 1, loss: 0.00009\n",
            "tensor(8.6343e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2842, Task: 2, loss: 0.00009\n",
            "tensor(8.6505e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2842, Task: 3, loss: 0.00009\n",
            "tensor(8.6444e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2842, Task: 4, loss: 0.00009\n",
            "tensor(8.6728e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2842, Task: 5, loss: 0.00009\n",
            "tensor(2.1881e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2842, Task: 6, loss: 0.00002\n",
            "tensor(9.8958e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2842, Task: 7, loss: 0.00001\n",
            "tensor(9.8446e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2842, Task: 8, loss: 0.00001\n",
            "tensor(8.4643e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5897e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2843, Task: 0, loss: 0.00009\n",
            "tensor(8.6679e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2843, Task: 1, loss: 0.00009\n",
            "tensor(8.6335e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2843, Task: 2, loss: 0.00009\n",
            "tensor(8.6497e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2843, Task: 3, loss: 0.00009\n",
            "tensor(8.6437e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2843, Task: 4, loss: 0.00009\n",
            "tensor(8.6721e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2843, Task: 5, loss: 0.00009\n",
            "tensor(2.1883e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2843, Task: 6, loss: 0.00002\n",
            "tensor(9.8990e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2843, Task: 7, loss: 0.00001\n",
            "tensor(9.8480e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2843, Task: 8, loss: 0.00001\n",
            "tensor(8.4656e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5895e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2844, Task: 0, loss: 0.00009\n",
            "tensor(8.6671e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2844, Task: 1, loss: 0.00009\n",
            "tensor(8.6328e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2844, Task: 2, loss: 0.00009\n",
            "tensor(8.6490e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2844, Task: 3, loss: 0.00009\n",
            "tensor(8.6429e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2844, Task: 4, loss: 0.00009\n",
            "tensor(8.6713e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2844, Task: 5, loss: 0.00009\n",
            "tensor(2.1884e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2844, Task: 6, loss: 0.00002\n",
            "tensor(9.9022e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2844, Task: 7, loss: 0.00001\n",
            "tensor(9.8514e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2844, Task: 8, loss: 0.00001\n",
            "tensor(8.4670e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5894e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2845, Task: 0, loss: 0.00009\n",
            "tensor(8.6663e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2845, Task: 1, loss: 0.00009\n",
            "tensor(8.6320e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2845, Task: 2, loss: 0.00009\n",
            "tensor(8.6482e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2845, Task: 3, loss: 0.00009\n",
            "tensor(8.6421e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2845, Task: 4, loss: 0.00009\n",
            "tensor(8.6705e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2845, Task: 5, loss: 0.00009\n",
            "tensor(2.1885e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2845, Task: 6, loss: 0.00002\n",
            "tensor(9.9054e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2845, Task: 7, loss: 0.00001\n",
            "tensor(9.8548e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2845, Task: 8, loss: 0.00001\n",
            "tensor(8.4683e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5892e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2846, Task: 0, loss: 0.00009\n",
            "tensor(8.6656e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2846, Task: 1, loss: 0.00009\n",
            "tensor(8.6312e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2846, Task: 2, loss: 0.00009\n",
            "tensor(8.6474e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2846, Task: 3, loss: 0.00009\n",
            "tensor(8.6413e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2846, Task: 4, loss: 0.00009\n",
            "tensor(8.6698e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2846, Task: 5, loss: 0.00009\n",
            "tensor(2.1886e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2846, Task: 6, loss: 0.00002\n",
            "tensor(9.9086e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2846, Task: 7, loss: 0.00001\n",
            "tensor(9.8582e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2846, Task: 8, loss: 0.00001\n",
            "tensor(8.4697e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5890e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2847, Task: 0, loss: 0.00009\n",
            "tensor(8.6648e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2847, Task: 1, loss: 0.00009\n",
            "tensor(8.6305e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2847, Task: 2, loss: 0.00009\n",
            "tensor(8.6467e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2847, Task: 3, loss: 0.00009\n",
            "tensor(8.6406e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2847, Task: 4, loss: 0.00009\n",
            "tensor(8.6690e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2847, Task: 5, loss: 0.00009\n",
            "tensor(2.1887e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2847, Task: 6, loss: 0.00002\n",
            "tensor(9.9117e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2847, Task: 7, loss: 0.00001\n",
            "tensor(9.8616e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2847, Task: 8, loss: 0.00001\n",
            "tensor(8.4710e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5888e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2848, Task: 0, loss: 0.00009\n",
            "tensor(8.6640e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2848, Task: 1, loss: 0.00009\n",
            "tensor(8.6297e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2848, Task: 2, loss: 0.00009\n",
            "tensor(8.6459e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2848, Task: 3, loss: 0.00009\n",
            "tensor(8.6398e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2848, Task: 4, loss: 0.00009\n",
            "tensor(8.6682e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2848, Task: 5, loss: 0.00009\n",
            "tensor(2.1888e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2848, Task: 6, loss: 0.00002\n",
            "tensor(9.9149e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2848, Task: 7, loss: 0.00001\n",
            "tensor(9.8650e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2848, Task: 8, loss: 0.00001\n",
            "tensor(8.4723e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5887e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2849, Task: 0, loss: 0.00009\n",
            "tensor(8.6633e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2849, Task: 1, loss: 0.00009\n",
            "tensor(8.6289e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2849, Task: 2, loss: 0.00009\n",
            "tensor(8.6451e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2849, Task: 3, loss: 0.00009\n",
            "tensor(8.6390e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2849, Task: 4, loss: 0.00009\n",
            "tensor(8.6674e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2849, Task: 5, loss: 0.00009\n",
            "tensor(2.1889e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2849, Task: 6, loss: 0.00002\n",
            "tensor(9.9181e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2849, Task: 7, loss: 0.00001\n",
            "tensor(9.8684e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2849, Task: 8, loss: 0.00001\n",
            "tensor(8.4737e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5885e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2850, Task: 0, loss: 0.00009\n",
            "tensor(8.6625e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2850, Task: 1, loss: 0.00009\n",
            "tensor(8.6282e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2850, Task: 2, loss: 0.00009\n",
            "tensor(8.6444e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2850, Task: 3, loss: 0.00009\n",
            "tensor(8.6383e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2850, Task: 4, loss: 0.00009\n",
            "tensor(8.6667e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2850, Task: 5, loss: 0.00009\n",
            "tensor(2.1890e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2850, Task: 6, loss: 0.00002\n",
            "tensor(9.9213e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2850, Task: 7, loss: 0.00001\n",
            "tensor(9.8718e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2850, Task: 8, loss: 0.00001\n",
            "tensor(8.4750e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5883e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2851, Task: 0, loss: 0.00009\n",
            "tensor(8.6617e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2851, Task: 1, loss: 0.00009\n",
            "tensor(8.6274e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2851, Task: 2, loss: 0.00009\n",
            "tensor(8.6436e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2851, Task: 3, loss: 0.00009\n",
            "tensor(8.6375e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2851, Task: 4, loss: 0.00009\n",
            "tensor(8.6659e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2851, Task: 5, loss: 0.00009\n",
            "tensor(2.1891e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2851, Task: 6, loss: 0.00002\n",
            "tensor(9.9244e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2851, Task: 7, loss: 0.00001\n",
            "tensor(9.8752e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2851, Task: 8, loss: 0.00001\n",
            "tensor(8.4764e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5882e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2852, Task: 0, loss: 0.00009\n",
            "tensor(8.6610e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2852, Task: 1, loss: 0.00009\n",
            "tensor(8.6266e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2852, Task: 2, loss: 0.00009\n",
            "tensor(8.6428e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2852, Task: 3, loss: 0.00009\n",
            "tensor(8.6367e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2852, Task: 4, loss: 0.00009\n",
            "tensor(8.6651e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2852, Task: 5, loss: 0.00009\n",
            "tensor(2.1892e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2852, Task: 6, loss: 0.00002\n",
            "tensor(9.9276e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2852, Task: 7, loss: 0.00001\n",
            "tensor(9.8786e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2852, Task: 8, loss: 0.00001\n",
            "tensor(8.4777e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5880e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2853, Task: 0, loss: 0.00009\n",
            "tensor(8.6602e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2853, Task: 1, loss: 0.00009\n",
            "tensor(8.6259e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2853, Task: 2, loss: 0.00009\n",
            "tensor(8.6421e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2853, Task: 3, loss: 0.00009\n",
            "tensor(8.6360e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2853, Task: 4, loss: 0.00009\n",
            "tensor(8.6644e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2853, Task: 5, loss: 0.00009\n",
            "tensor(2.1893e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2853, Task: 6, loss: 0.00002\n",
            "tensor(9.9307e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2853, Task: 7, loss: 0.00001\n",
            "tensor(9.8819e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2853, Task: 8, loss: 0.00001\n",
            "tensor(8.4790e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5878e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2854, Task: 0, loss: 0.00009\n",
            "tensor(8.6594e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2854, Task: 1, loss: 0.00009\n",
            "tensor(8.6251e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2854, Task: 2, loss: 0.00009\n",
            "tensor(8.6413e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2854, Task: 3, loss: 0.00009\n",
            "tensor(8.6352e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2854, Task: 4, loss: 0.00009\n",
            "tensor(8.6636e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2854, Task: 5, loss: 0.00009\n",
            "tensor(2.1895e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2854, Task: 6, loss: 0.00002\n",
            "tensor(9.9339e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2854, Task: 7, loss: 0.00001\n",
            "tensor(9.8853e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2854, Task: 8, loss: 0.00001\n",
            "tensor(8.4804e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5876e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2855, Task: 0, loss: 0.00009\n",
            "tensor(8.6587e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2855, Task: 1, loss: 0.00009\n",
            "tensor(8.6243e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2855, Task: 2, loss: 0.00009\n",
            "tensor(8.6405e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2855, Task: 3, loss: 0.00009\n",
            "tensor(8.6345e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2855, Task: 4, loss: 0.00009\n",
            "tensor(8.6628e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2855, Task: 5, loss: 0.00009\n",
            "tensor(2.1896e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2855, Task: 6, loss: 0.00002\n",
            "tensor(9.9370e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2855, Task: 7, loss: 0.00001\n",
            "tensor(9.8887e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2855, Task: 8, loss: 0.00001\n",
            "tensor(8.4817e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5875e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2856, Task: 0, loss: 0.00009\n",
            "tensor(8.6579e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2856, Task: 1, loss: 0.00009\n",
            "tensor(8.6236e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2856, Task: 2, loss: 0.00009\n",
            "tensor(8.6398e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2856, Task: 3, loss: 0.00009\n",
            "tensor(8.6337e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2856, Task: 4, loss: 0.00009\n",
            "tensor(8.6621e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2856, Task: 5, loss: 0.00009\n",
            "tensor(2.1897e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2856, Task: 6, loss: 0.00002\n",
            "tensor(9.9402e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2856, Task: 7, loss: 0.00001\n",
            "tensor(9.8921e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2856, Task: 8, loss: 0.00001\n",
            "tensor(8.4830e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5873e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2857, Task: 0, loss: 0.00009\n",
            "tensor(8.6571e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2857, Task: 1, loss: 0.00009\n",
            "tensor(8.6228e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2857, Task: 2, loss: 0.00009\n",
            "tensor(8.6390e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2857, Task: 3, loss: 0.00009\n",
            "tensor(8.6329e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2857, Task: 4, loss: 0.00009\n",
            "tensor(8.6613e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2857, Task: 5, loss: 0.00009\n",
            "tensor(2.1898e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2857, Task: 6, loss: 0.00002\n",
            "tensor(9.9433e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2857, Task: 7, loss: 0.00001\n",
            "tensor(9.8954e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2857, Task: 8, loss: 0.00001\n",
            "tensor(8.4843e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5871e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2858, Task: 0, loss: 0.00009\n",
            "tensor(8.6564e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2858, Task: 1, loss: 0.00009\n",
            "tensor(8.6221e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2858, Task: 2, loss: 0.00009\n",
            "tensor(8.6383e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2858, Task: 3, loss: 0.00009\n",
            "tensor(8.6322e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2858, Task: 4, loss: 0.00009\n",
            "tensor(8.6606e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2858, Task: 5, loss: 0.00009\n",
            "tensor(2.1899e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2858, Task: 6, loss: 0.00002\n",
            "tensor(9.9465e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2858, Task: 7, loss: 0.00001\n",
            "tensor(9.8988e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2858, Task: 8, loss: 0.00001\n",
            "tensor(8.4856e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5870e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2859, Task: 0, loss: 0.00009\n",
            "tensor(8.6556e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2859, Task: 1, loss: 0.00009\n",
            "tensor(8.6213e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2859, Task: 2, loss: 0.00009\n",
            "tensor(8.6375e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2859, Task: 3, loss: 0.00009\n",
            "tensor(8.6314e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2859, Task: 4, loss: 0.00009\n",
            "tensor(8.6598e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2859, Task: 5, loss: 0.00009\n",
            "tensor(2.1900e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2859, Task: 6, loss: 0.00002\n",
            "tensor(9.9496e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2859, Task: 7, loss: 0.00001\n",
            "tensor(9.9022e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2859, Task: 8, loss: 0.00001\n",
            "tensor(8.4870e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5868e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2860, Task: 0, loss: 0.00009\n",
            "tensor(8.6549e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2860, Task: 1, loss: 0.00009\n",
            "tensor(8.6206e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2860, Task: 2, loss: 0.00009\n",
            "tensor(8.6368e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2860, Task: 3, loss: 0.00009\n",
            "tensor(8.6307e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2860, Task: 4, loss: 0.00009\n",
            "tensor(8.6591e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2860, Task: 5, loss: 0.00009\n",
            "tensor(2.1901e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2860, Task: 6, loss: 0.00002\n",
            "tensor(9.9527e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2860, Task: 7, loss: 0.00001\n",
            "tensor(9.9055e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2860, Task: 8, loss: 0.00001\n",
            "tensor(8.4883e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5866e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2861, Task: 0, loss: 0.00009\n",
            "tensor(8.6541e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2861, Task: 1, loss: 0.00009\n",
            "tensor(8.6198e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2861, Task: 2, loss: 0.00009\n",
            "tensor(8.6360e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2861, Task: 3, loss: 0.00009\n",
            "tensor(8.6299e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2861, Task: 4, loss: 0.00009\n",
            "tensor(8.6583e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2861, Task: 5, loss: 0.00009\n",
            "tensor(2.1902e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2861, Task: 6, loss: 0.00002\n",
            "tensor(9.9558e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2861, Task: 7, loss: 0.00001\n",
            "tensor(9.9089e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2861, Task: 8, loss: 0.00001\n",
            "tensor(8.4896e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5864e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2862, Task: 0, loss: 0.00009\n",
            "tensor(8.6534e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2862, Task: 1, loss: 0.00009\n",
            "tensor(8.6191e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2862, Task: 2, loss: 0.00009\n",
            "tensor(8.6352e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2862, Task: 3, loss: 0.00009\n",
            "tensor(8.6292e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2862, Task: 4, loss: 0.00009\n",
            "tensor(8.6575e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2862, Task: 5, loss: 0.00009\n",
            "tensor(2.1903e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2862, Task: 6, loss: 0.00002\n",
            "tensor(9.9590e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2862, Task: 7, loss: 0.00001\n",
            "tensor(9.9122e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2862, Task: 8, loss: 0.00001\n",
            "tensor(8.4909e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5863e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2863, Task: 0, loss: 0.00009\n",
            "tensor(8.6526e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2863, Task: 1, loss: 0.00009\n",
            "tensor(8.6183e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2863, Task: 2, loss: 0.00009\n",
            "tensor(8.6345e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2863, Task: 3, loss: 0.00009\n",
            "tensor(8.6284e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2863, Task: 4, loss: 0.00009\n",
            "tensor(8.6568e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2863, Task: 5, loss: 0.00009\n",
            "tensor(2.1904e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2863, Task: 6, loss: 0.00002\n",
            "tensor(9.9621e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2863, Task: 7, loss: 0.00001\n",
            "tensor(9.9156e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2863, Task: 8, loss: 0.00001\n",
            "tensor(8.4922e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5861e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2864, Task: 0, loss: 0.00009\n",
            "tensor(8.6519e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2864, Task: 1, loss: 0.00009\n",
            "tensor(8.6176e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2864, Task: 2, loss: 0.00009\n",
            "tensor(8.6337e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2864, Task: 3, loss: 0.00009\n",
            "tensor(8.6277e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2864, Task: 4, loss: 0.00009\n",
            "tensor(8.6560e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2864, Task: 5, loss: 0.00009\n",
            "tensor(2.1905e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2864, Task: 6, loss: 0.00002\n",
            "tensor(9.9653e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2864, Task: 7, loss: 0.00001\n",
            "tensor(9.9189e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2864, Task: 8, loss: 0.00001\n",
            "tensor(8.4935e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5859e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2865, Task: 0, loss: 0.00009\n",
            "tensor(8.6511e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2865, Task: 1, loss: 0.00009\n",
            "tensor(8.6168e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2865, Task: 2, loss: 0.00009\n",
            "tensor(8.6330e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2865, Task: 3, loss: 0.00009\n",
            "tensor(8.6269e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2865, Task: 4, loss: 0.00009\n",
            "tensor(8.6553e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2865, Task: 5, loss: 0.00009\n",
            "tensor(2.1906e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2865, Task: 6, loss: 0.00002\n",
            "tensor(9.9684e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2865, Task: 7, loss: 0.00001\n",
            "tensor(9.9222e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2865, Task: 8, loss: 0.00001\n",
            "tensor(8.4948e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5858e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2866, Task: 0, loss: 0.00009\n",
            "tensor(8.6504e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2866, Task: 1, loss: 0.00009\n",
            "tensor(8.6161e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2866, Task: 2, loss: 0.00009\n",
            "tensor(8.6322e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2866, Task: 3, loss: 0.00009\n",
            "tensor(8.6262e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2866, Task: 4, loss: 0.00009\n",
            "tensor(8.6545e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2866, Task: 5, loss: 0.00009\n",
            "tensor(2.1908e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2866, Task: 6, loss: 0.00002\n",
            "tensor(9.9715e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2866, Task: 7, loss: 0.00001\n",
            "tensor(9.9256e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2866, Task: 8, loss: 0.00001\n",
            "tensor(8.4961e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5856e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2867, Task: 0, loss: 0.00009\n",
            "tensor(8.6496e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2867, Task: 1, loss: 0.00009\n",
            "tensor(8.6153e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2867, Task: 2, loss: 0.00009\n",
            "tensor(8.6315e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2867, Task: 3, loss: 0.00009\n",
            "tensor(8.6254e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2867, Task: 4, loss: 0.00009\n",
            "tensor(8.6538e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2867, Task: 5, loss: 0.00009\n",
            "tensor(2.1909e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2867, Task: 6, loss: 0.00002\n",
            "tensor(9.9746e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2867, Task: 7, loss: 0.00001\n",
            "tensor(9.9289e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2867, Task: 8, loss: 0.00001\n",
            "tensor(8.4974e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5854e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2868, Task: 0, loss: 0.00009\n",
            "tensor(8.6489e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2868, Task: 1, loss: 0.00009\n",
            "tensor(8.6146e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2868, Task: 2, loss: 0.00009\n",
            "tensor(8.6308e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2868, Task: 3, loss: 0.00009\n",
            "tensor(8.6247e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2868, Task: 4, loss: 0.00009\n",
            "tensor(8.6530e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2868, Task: 5, loss: 0.00009\n",
            "tensor(2.1910e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2868, Task: 6, loss: 0.00002\n",
            "tensor(9.9777e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2868, Task: 7, loss: 0.00001\n",
            "tensor(9.9322e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2868, Task: 8, loss: 0.00001\n",
            "tensor(8.4987e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5853e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2869, Task: 0, loss: 0.00009\n",
            "tensor(8.6481e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2869, Task: 1, loss: 0.00009\n",
            "tensor(8.6138e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2869, Task: 2, loss: 0.00009\n",
            "tensor(8.6300e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2869, Task: 3, loss: 0.00009\n",
            "tensor(8.6239e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2869, Task: 4, loss: 0.00009\n",
            "tensor(8.6523e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2869, Task: 5, loss: 0.00009\n",
            "tensor(2.1911e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2869, Task: 6, loss: 0.00002\n",
            "tensor(9.9808e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2869, Task: 7, loss: 0.00001\n",
            "tensor(9.9356e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2869, Task: 8, loss: 0.00001\n",
            "tensor(8.5000e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5851e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2870, Task: 0, loss: 0.00009\n",
            "tensor(8.6474e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2870, Task: 1, loss: 0.00009\n",
            "tensor(8.6131e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2870, Task: 2, loss: 0.00009\n",
            "tensor(8.6293e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2870, Task: 3, loss: 0.00009\n",
            "tensor(8.6232e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2870, Task: 4, loss: 0.00009\n",
            "tensor(8.6516e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2870, Task: 5, loss: 0.00009\n",
            "tensor(2.1912e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2870, Task: 6, loss: 0.00002\n",
            "tensor(9.9839e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2870, Task: 7, loss: 0.00001\n",
            "tensor(9.9389e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2870, Task: 8, loss: 0.00001\n",
            "tensor(8.5013e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5849e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2871, Task: 0, loss: 0.00009\n",
            "tensor(8.6466e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2871, Task: 1, loss: 0.00009\n",
            "tensor(8.6123e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2871, Task: 2, loss: 0.00009\n",
            "tensor(8.6285e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2871, Task: 3, loss: 0.00009\n",
            "tensor(8.6224e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2871, Task: 4, loss: 0.00009\n",
            "tensor(8.6508e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2871, Task: 5, loss: 0.00009\n",
            "tensor(2.1913e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2871, Task: 6, loss: 0.00002\n",
            "tensor(9.9870e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2871, Task: 7, loss: 0.00001\n",
            "tensor(9.9422e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2871, Task: 8, loss: 0.00001\n",
            "tensor(8.5026e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5848e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2872, Task: 0, loss: 0.00009\n",
            "tensor(8.6459e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2872, Task: 1, loss: 0.00009\n",
            "tensor(8.6116e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2872, Task: 2, loss: 0.00009\n",
            "tensor(8.6278e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2872, Task: 3, loss: 0.00009\n",
            "tensor(8.6217e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2872, Task: 4, loss: 0.00009\n",
            "tensor(8.6501e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2872, Task: 5, loss: 0.00009\n",
            "tensor(2.1914e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2872, Task: 6, loss: 0.00002\n",
            "tensor(9.9901e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2872, Task: 7, loss: 0.00001\n",
            "tensor(9.9455e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2872, Task: 8, loss: 0.00001\n",
            "tensor(8.5039e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5846e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2873, Task: 0, loss: 0.00009\n",
            "tensor(8.6451e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2873, Task: 1, loss: 0.00009\n",
            "tensor(8.6109e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2873, Task: 2, loss: 0.00009\n",
            "tensor(8.6270e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2873, Task: 3, loss: 0.00009\n",
            "tensor(8.6210e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2873, Task: 4, loss: 0.00009\n",
            "tensor(8.6493e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2873, Task: 5, loss: 0.00009\n",
            "tensor(2.1915e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2873, Task: 6, loss: 0.00002\n",
            "tensor(9.9932e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2873, Task: 7, loss: 0.00001\n",
            "tensor(9.9489e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2873, Task: 8, loss: 0.00001\n",
            "tensor(8.5052e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5844e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2874, Task: 0, loss: 0.00009\n",
            "tensor(8.6444e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2874, Task: 1, loss: 0.00009\n",
            "tensor(8.6101e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2874, Task: 2, loss: 0.00009\n",
            "tensor(8.6263e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2874, Task: 3, loss: 0.00009\n",
            "tensor(8.6202e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2874, Task: 4, loss: 0.00009\n",
            "tensor(8.6486e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2874, Task: 5, loss: 0.00009\n",
            "tensor(2.1916e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2874, Task: 6, loss: 0.00002\n",
            "tensor(9.9963e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2874, Task: 7, loss: 0.00001\n",
            "tensor(9.9522e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2874, Task: 8, loss: 0.00001\n",
            "tensor(8.5065e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5843e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2875, Task: 0, loss: 0.00009\n",
            "tensor(8.6437e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2875, Task: 1, loss: 0.00009\n",
            "tensor(8.6094e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2875, Task: 2, loss: 0.00009\n",
            "tensor(8.6256e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2875, Task: 3, loss: 0.00009\n",
            "tensor(8.6195e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2875, Task: 4, loss: 0.00009\n",
            "tensor(8.6478e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2875, Task: 5, loss: 0.00009\n",
            "tensor(2.1917e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2875, Task: 6, loss: 0.00002\n",
            "tensor(9.9993e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2875, Task: 7, loss: 0.00001\n",
            "tensor(9.9555e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2875, Task: 8, loss: 0.00001\n",
            "tensor(8.5078e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5841e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2876, Task: 0, loss: 0.00009\n",
            "tensor(8.6429e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2876, Task: 1, loss: 0.00009\n",
            "tensor(8.6087e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2876, Task: 2, loss: 0.00009\n",
            "tensor(8.6248e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2876, Task: 3, loss: 0.00009\n",
            "tensor(8.6187e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2876, Task: 4, loss: 0.00009\n",
            "tensor(8.6471e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2876, Task: 5, loss: 0.00009\n",
            "tensor(2.1918e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2876, Task: 6, loss: 0.00002\n",
            "tensor(1.0002e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2876, Task: 7, loss: 0.00001\n",
            "tensor(9.9588e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2876, Task: 8, loss: 0.00001\n",
            "tensor(8.5091e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5839e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2877, Task: 0, loss: 0.00009\n",
            "tensor(8.6422e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2877, Task: 1, loss: 0.00009\n",
            "tensor(8.6079e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2877, Task: 2, loss: 0.00009\n",
            "tensor(8.6241e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2877, Task: 3, loss: 0.00009\n",
            "tensor(8.6180e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2877, Task: 4, loss: 0.00009\n",
            "tensor(8.6464e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2877, Task: 5, loss: 0.00009\n",
            "tensor(2.1919e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2877, Task: 6, loss: 0.00002\n",
            "tensor(1.0006e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2877, Task: 7, loss: 0.00001\n",
            "tensor(9.9621e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2877, Task: 8, loss: 0.00001\n",
            "tensor(8.5103e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5838e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2878, Task: 0, loss: 0.00009\n",
            "tensor(8.6414e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2878, Task: 1, loss: 0.00009\n",
            "tensor(8.6072e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2878, Task: 2, loss: 0.00009\n",
            "tensor(8.6234e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2878, Task: 3, loss: 0.00009\n",
            "tensor(8.6173e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2878, Task: 4, loss: 0.00009\n",
            "tensor(8.6456e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2878, Task: 5, loss: 0.00009\n",
            "tensor(2.1920e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2878, Task: 6, loss: 0.00002\n",
            "tensor(1.0009e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2878, Task: 7, loss: 0.00001\n",
            "tensor(9.9654e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2878, Task: 8, loss: 0.00001\n",
            "tensor(8.5116e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5836e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2879, Task: 0, loss: 0.00009\n",
            "tensor(8.6407e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2879, Task: 1, loss: 0.00009\n",
            "tensor(8.6064e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2879, Task: 2, loss: 0.00009\n",
            "tensor(8.6226e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2879, Task: 3, loss: 0.00009\n",
            "tensor(8.6165e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2879, Task: 4, loss: 0.00009\n",
            "tensor(8.6449e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2879, Task: 5, loss: 0.00009\n",
            "tensor(2.1922e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2879, Task: 6, loss: 0.00002\n",
            "tensor(1.0012e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2879, Task: 7, loss: 0.00001\n",
            "tensor(9.9687e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2879, Task: 8, loss: 0.00001\n",
            "tensor(8.5129e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5834e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2880, Task: 0, loss: 0.00009\n",
            "tensor(8.6400e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2880, Task: 1, loss: 0.00009\n",
            "tensor(8.6057e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2880, Task: 2, loss: 0.00009\n",
            "tensor(8.6219e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2880, Task: 3, loss: 0.00009\n",
            "tensor(8.6158e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2880, Task: 4, loss: 0.00009\n",
            "tensor(8.6442e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2880, Task: 5, loss: 0.00009\n",
            "tensor(2.1923e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2880, Task: 6, loss: 0.00002\n",
            "tensor(1.0015e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2880, Task: 7, loss: 0.00001\n",
            "tensor(9.9720e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2880, Task: 8, loss: 0.00001\n",
            "tensor(8.5142e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5833e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2881, Task: 0, loss: 0.00009\n",
            "tensor(8.6392e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2881, Task: 1, loss: 0.00009\n",
            "tensor(8.6050e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2881, Task: 2, loss: 0.00009\n",
            "tensor(8.6212e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2881, Task: 3, loss: 0.00009\n",
            "tensor(8.6151e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2881, Task: 4, loss: 0.00009\n",
            "tensor(8.6434e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2881, Task: 5, loss: 0.00009\n",
            "tensor(2.1924e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2881, Task: 6, loss: 0.00002\n",
            "tensor(1.0018e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2881, Task: 7, loss: 0.00001\n",
            "tensor(9.9753e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2881, Task: 8, loss: 0.00001\n",
            "tensor(8.5154e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5831e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2882, Task: 0, loss: 0.00009\n",
            "tensor(8.6385e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2882, Task: 1, loss: 0.00009\n",
            "tensor(8.6043e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2882, Task: 2, loss: 0.00009\n",
            "tensor(8.6204e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2882, Task: 3, loss: 0.00009\n",
            "tensor(8.6143e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2882, Task: 4, loss: 0.00009\n",
            "tensor(8.6427e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2882, Task: 5, loss: 0.00009\n",
            "tensor(2.1925e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2882, Task: 6, loss: 0.00002\n",
            "tensor(1.0021e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2882, Task: 7, loss: 0.00001\n",
            "tensor(9.9786e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2882, Task: 8, loss: 0.00001\n",
            "tensor(8.5167e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5829e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2883, Task: 0, loss: 0.00009\n",
            "tensor(8.6378e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2883, Task: 1, loss: 0.00009\n",
            "tensor(8.6035e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2883, Task: 2, loss: 0.00009\n",
            "tensor(8.6197e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2883, Task: 3, loss: 0.00009\n",
            "tensor(8.6136e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2883, Task: 4, loss: 0.00009\n",
            "tensor(8.6420e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2883, Task: 5, loss: 0.00009\n",
            "tensor(2.1926e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2883, Task: 6, loss: 0.00002\n",
            "tensor(1.0024e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2883, Task: 7, loss: 0.00001\n",
            "tensor(9.9818e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2883, Task: 8, loss: 0.00001\n",
            "tensor(8.5179e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5828e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2884, Task: 0, loss: 0.00009\n",
            "tensor(8.6371e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2884, Task: 1, loss: 0.00009\n",
            "tensor(8.6028e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2884, Task: 2, loss: 0.00009\n",
            "tensor(8.6190e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2884, Task: 3, loss: 0.00009\n",
            "tensor(8.6129e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2884, Task: 4, loss: 0.00009\n",
            "tensor(8.6412e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2884, Task: 5, loss: 0.00009\n",
            "tensor(2.1927e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2884, Task: 6, loss: 0.00002\n",
            "tensor(1.0027e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2884, Task: 7, loss: 0.00001\n",
            "tensor(9.9851e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2884, Task: 8, loss: 0.00001\n",
            "tensor(8.5192e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5826e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2885, Task: 0, loss: 0.00009\n",
            "tensor(8.6363e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2885, Task: 1, loss: 0.00009\n",
            "tensor(8.6021e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2885, Task: 2, loss: 0.00009\n",
            "tensor(8.6182e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2885, Task: 3, loss: 0.00009\n",
            "tensor(8.6122e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2885, Task: 4, loss: 0.00009\n",
            "tensor(8.6405e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2885, Task: 5, loss: 0.00009\n",
            "tensor(2.1928e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2885, Task: 6, loss: 0.00002\n",
            "tensor(1.0030e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2885, Task: 7, loss: 0.00001\n",
            "tensor(9.9884e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2885, Task: 8, loss: 0.00001\n",
            "tensor(8.5205e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5824e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2886, Task: 0, loss: 0.00009\n",
            "tensor(8.6356e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2886, Task: 1, loss: 0.00009\n",
            "tensor(8.6014e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2886, Task: 2, loss: 0.00009\n",
            "tensor(8.6175e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2886, Task: 3, loss: 0.00009\n",
            "tensor(8.6114e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2886, Task: 4, loss: 0.00009\n",
            "tensor(8.6398e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2886, Task: 5, loss: 0.00009\n",
            "tensor(2.1929e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2886, Task: 6, loss: 0.00002\n",
            "tensor(1.0033e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2886, Task: 7, loss: 0.00001\n",
            "tensor(9.9917e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2886, Task: 8, loss: 0.00001\n",
            "tensor(8.5217e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5823e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2887, Task: 0, loss: 0.00009\n",
            "tensor(8.6349e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2887, Task: 1, loss: 0.00009\n",
            "tensor(8.6006e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2887, Task: 2, loss: 0.00009\n",
            "tensor(8.6168e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2887, Task: 3, loss: 0.00009\n",
            "tensor(8.6107e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2887, Task: 4, loss: 0.00009\n",
            "tensor(8.6391e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2887, Task: 5, loss: 0.00009\n",
            "tensor(2.1930e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2887, Task: 6, loss: 0.00002\n",
            "tensor(1.0036e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2887, Task: 7, loss: 0.00001\n",
            "tensor(9.9949e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2887, Task: 8, loss: 0.00001\n",
            "tensor(8.5230e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5821e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2888, Task: 0, loss: 0.00009\n",
            "tensor(8.6342e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2888, Task: 1, loss: 0.00009\n",
            "tensor(8.5999e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2888, Task: 2, loss: 0.00009\n",
            "tensor(8.6161e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2888, Task: 3, loss: 0.00009\n",
            "tensor(8.6100e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2888, Task: 4, loss: 0.00009\n",
            "tensor(8.6383e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2888, Task: 5, loss: 0.00009\n",
            "tensor(2.1931e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2888, Task: 6, loss: 0.00002\n",
            "tensor(1.0039e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2888, Task: 7, loss: 0.00001\n",
            "tensor(9.9982e-06, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2888, Task: 8, loss: 0.00001\n",
            "tensor(8.5242e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5820e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2889, Task: 0, loss: 0.00009\n",
            "tensor(8.6334e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2889, Task: 1, loss: 0.00009\n",
            "tensor(8.5992e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2889, Task: 2, loss: 0.00009\n",
            "tensor(8.6154e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2889, Task: 3, loss: 0.00009\n",
            "tensor(8.6093e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2889, Task: 4, loss: 0.00009\n",
            "tensor(8.6376e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2889, Task: 5, loss: 0.00009\n",
            "tensor(2.1932e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2889, Task: 6, loss: 0.00002\n",
            "tensor(1.0042e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2889, Task: 7, loss: 0.00001\n",
            "tensor(1.0001e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2889, Task: 8, loss: 0.00001\n",
            "tensor(8.5255e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5818e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2890, Task: 0, loss: 0.00009\n",
            "tensor(8.6327e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2890, Task: 1, loss: 0.00009\n",
            "tensor(8.5985e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2890, Task: 2, loss: 0.00009\n",
            "tensor(8.6146e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2890, Task: 3, loss: 0.00009\n",
            "tensor(8.6086e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2890, Task: 4, loss: 0.00009\n",
            "tensor(8.6369e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2890, Task: 5, loss: 0.00009\n",
            "tensor(2.1933e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2890, Task: 6, loss: 0.00002\n",
            "tensor(1.0045e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2890, Task: 7, loss: 0.00001\n",
            "tensor(1.0005e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2890, Task: 8, loss: 0.00001\n",
            "tensor(8.5267e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5816e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2891, Task: 0, loss: 0.00009\n",
            "tensor(8.6320e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2891, Task: 1, loss: 0.00009\n",
            "tensor(8.5977e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2891, Task: 2, loss: 0.00009\n",
            "tensor(8.6139e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2891, Task: 3, loss: 0.00009\n",
            "tensor(8.6078e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2891, Task: 4, loss: 0.00009\n",
            "tensor(8.6362e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2891, Task: 5, loss: 0.00009\n",
            "tensor(2.1934e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2891, Task: 6, loss: 0.00002\n",
            "tensor(1.0048e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2891, Task: 7, loss: 0.00001\n",
            "tensor(1.0008e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2891, Task: 8, loss: 0.00001\n",
            "tensor(8.5280e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5815e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2892, Task: 0, loss: 0.00009\n",
            "tensor(8.6313e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2892, Task: 1, loss: 0.00009\n",
            "tensor(8.5970e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2892, Task: 2, loss: 0.00009\n",
            "tensor(8.6132e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2892, Task: 3, loss: 0.00009\n",
            "tensor(8.6071e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2892, Task: 4, loss: 0.00009\n",
            "tensor(8.6354e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2892, Task: 5, loss: 0.00009\n",
            "tensor(2.1935e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2892, Task: 6, loss: 0.00002\n",
            "tensor(1.0051e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2892, Task: 7, loss: 0.00001\n",
            "tensor(1.0011e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2892, Task: 8, loss: 0.00001\n",
            "tensor(8.5292e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5813e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2893, Task: 0, loss: 0.00009\n",
            "tensor(8.6305e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2893, Task: 1, loss: 0.00009\n",
            "tensor(8.5963e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2893, Task: 2, loss: 0.00009\n",
            "tensor(8.6125e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2893, Task: 3, loss: 0.00009\n",
            "tensor(8.6064e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2893, Task: 4, loss: 0.00009\n",
            "tensor(8.6347e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2893, Task: 5, loss: 0.00009\n",
            "tensor(2.1937e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2893, Task: 6, loss: 0.00002\n",
            "tensor(1.0054e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2893, Task: 7, loss: 0.00001\n",
            "tensor(1.0014e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2893, Task: 8, loss: 0.00001\n",
            "tensor(8.5305e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5811e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2894, Task: 0, loss: 0.00009\n",
            "tensor(8.6298e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2894, Task: 1, loss: 0.00009\n",
            "tensor(8.5956e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2894, Task: 2, loss: 0.00009\n",
            "tensor(8.6118e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2894, Task: 3, loss: 0.00009\n",
            "tensor(8.6057e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2894, Task: 4, loss: 0.00009\n",
            "tensor(8.6340e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2894, Task: 5, loss: 0.00009\n",
            "tensor(2.1938e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2894, Task: 6, loss: 0.00002\n",
            "tensor(1.0057e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2894, Task: 7, loss: 0.00001\n",
            "tensor(1.0018e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2894, Task: 8, loss: 0.00001\n",
            "tensor(8.5317e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5810e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2895, Task: 0, loss: 0.00009\n",
            "tensor(8.6291e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2895, Task: 1, loss: 0.00009\n",
            "tensor(8.5949e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2895, Task: 2, loss: 0.00009\n",
            "tensor(8.6110e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2895, Task: 3, loss: 0.00009\n",
            "tensor(8.6050e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2895, Task: 4, loss: 0.00009\n",
            "tensor(8.6333e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2895, Task: 5, loss: 0.00009\n",
            "tensor(2.1939e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2895, Task: 6, loss: 0.00002\n",
            "tensor(1.0060e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2895, Task: 7, loss: 0.00001\n",
            "tensor(1.0021e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2895, Task: 8, loss: 0.00001\n",
            "tensor(8.5329e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5808e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2896, Task: 0, loss: 0.00009\n",
            "tensor(8.6284e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2896, Task: 1, loss: 0.00009\n",
            "tensor(8.5942e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2896, Task: 2, loss: 0.00009\n",
            "tensor(8.6103e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2896, Task: 3, loss: 0.00009\n",
            "tensor(8.6043e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2896, Task: 4, loss: 0.00009\n",
            "tensor(8.6326e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2896, Task: 5, loss: 0.00009\n",
            "tensor(2.1940e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2896, Task: 6, loss: 0.00002\n",
            "tensor(1.0063e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2896, Task: 7, loss: 0.00001\n",
            "tensor(1.0024e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2896, Task: 8, loss: 0.00001\n",
            "tensor(8.5342e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5807e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2897, Task: 0, loss: 0.00009\n",
            "tensor(8.6277e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2897, Task: 1, loss: 0.00009\n",
            "tensor(8.5935e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2897, Task: 2, loss: 0.00009\n",
            "tensor(8.6096e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2897, Task: 3, loss: 0.00009\n",
            "tensor(8.6035e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2897, Task: 4, loss: 0.00009\n",
            "tensor(8.6319e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2897, Task: 5, loss: 0.00009\n",
            "tensor(2.1941e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2897, Task: 6, loss: 0.00002\n",
            "tensor(1.0066e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2897, Task: 7, loss: 0.00001\n",
            "tensor(1.0027e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2897, Task: 8, loss: 0.00001\n",
            "tensor(8.5354e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5805e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2898, Task: 0, loss: 0.00009\n",
            "tensor(8.6270e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2898, Task: 1, loss: 0.00009\n",
            "tensor(8.5927e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2898, Task: 2, loss: 0.00009\n",
            "tensor(8.6089e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2898, Task: 3, loss: 0.00009\n",
            "tensor(8.6028e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2898, Task: 4, loss: 0.00009\n",
            "tensor(8.6311e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2898, Task: 5, loss: 0.00009\n",
            "tensor(2.1942e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2898, Task: 6, loss: 0.00002\n",
            "tensor(1.0069e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2898, Task: 7, loss: 0.00001\n",
            "tensor(1.0031e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2898, Task: 8, loss: 0.00001\n",
            "tensor(8.5366e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5803e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2899, Task: 0, loss: 0.00009\n",
            "tensor(8.6263e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2899, Task: 1, loss: 0.00009\n",
            "tensor(8.5920e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2899, Task: 2, loss: 0.00009\n",
            "tensor(8.6082e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2899, Task: 3, loss: 0.00009\n",
            "tensor(8.6021e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2899, Task: 4, loss: 0.00009\n",
            "tensor(8.6304e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2899, Task: 5, loss: 0.00009\n",
            "tensor(2.1943e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2899, Task: 6, loss: 0.00002\n",
            "tensor(1.0072e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2899, Task: 7, loss: 0.00001\n",
            "tensor(1.0034e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2899, Task: 8, loss: 0.00001\n",
            "tensor(8.5379e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5802e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2900, Task: 0, loss: 0.00009\n",
            "tensor(8.6256e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2900, Task: 1, loss: 0.00009\n",
            "tensor(8.5913e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2900, Task: 2, loss: 0.00009\n",
            "tensor(8.6075e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2900, Task: 3, loss: 0.00009\n",
            "tensor(8.6014e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2900, Task: 4, loss: 0.00009\n",
            "tensor(8.6297e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2900, Task: 5, loss: 0.00009\n",
            "tensor(2.1944e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2900, Task: 6, loss: 0.00002\n",
            "tensor(1.0075e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2900, Task: 7, loss: 0.00001\n",
            "tensor(1.0037e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2900, Task: 8, loss: 0.00001\n",
            "tensor(8.5391e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5800e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2901, Task: 0, loss: 0.00009\n",
            "tensor(8.6248e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2901, Task: 1, loss: 0.00009\n",
            "tensor(8.5906e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2901, Task: 2, loss: 0.00009\n",
            "tensor(8.6068e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2901, Task: 3, loss: 0.00009\n",
            "tensor(8.6007e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2901, Task: 4, loss: 0.00009\n",
            "tensor(8.6290e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2901, Task: 5, loss: 0.00009\n",
            "tensor(2.1945e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2901, Task: 6, loss: 0.00002\n",
            "tensor(1.0078e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2901, Task: 7, loss: 0.00001\n",
            "tensor(1.0040e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2901, Task: 8, loss: 0.00001\n",
            "tensor(8.5403e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5799e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2902, Task: 0, loss: 0.00009\n",
            "tensor(8.6241e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2902, Task: 1, loss: 0.00009\n",
            "tensor(8.5899e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2902, Task: 2, loss: 0.00009\n",
            "tensor(8.6061e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2902, Task: 3, loss: 0.00009\n",
            "tensor(8.6000e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2902, Task: 4, loss: 0.00009\n",
            "tensor(8.6283e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2902, Task: 5, loss: 0.00009\n",
            "tensor(2.1946e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2902, Task: 6, loss: 0.00002\n",
            "tensor(1.0081e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2902, Task: 7, loss: 0.00001\n",
            "tensor(1.0044e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2902, Task: 8, loss: 0.00001\n",
            "tensor(8.5415e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5797e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2903, Task: 0, loss: 0.00009\n",
            "tensor(8.6234e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2903, Task: 1, loss: 0.00009\n",
            "tensor(8.5892e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2903, Task: 2, loss: 0.00009\n",
            "tensor(8.6054e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2903, Task: 3, loss: 0.00009\n",
            "tensor(8.5993e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2903, Task: 4, loss: 0.00009\n",
            "tensor(8.6276e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2903, Task: 5, loss: 0.00009\n",
            "tensor(2.1947e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2903, Task: 6, loss: 0.00002\n",
            "tensor(1.0084e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2903, Task: 7, loss: 0.00001\n",
            "tensor(1.0047e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2903, Task: 8, loss: 0.00001\n",
            "tensor(8.5427e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5795e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2904, Task: 0, loss: 0.00009\n",
            "tensor(8.6227e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2904, Task: 1, loss: 0.00009\n",
            "tensor(8.5885e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2904, Task: 2, loss: 0.00009\n",
            "tensor(8.6047e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2904, Task: 3, loss: 0.00009\n",
            "tensor(8.5986e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2904, Task: 4, loss: 0.00009\n",
            "tensor(8.6269e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2904, Task: 5, loss: 0.00009\n",
            "tensor(2.1948e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2904, Task: 6, loss: 0.00002\n",
            "tensor(1.0087e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2904, Task: 7, loss: 0.00001\n",
            "tensor(1.0050e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2904, Task: 8, loss: 0.00001\n",
            "tensor(8.5440e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5794e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2905, Task: 0, loss: 0.00009\n",
            "tensor(8.6220e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2905, Task: 1, loss: 0.00009\n",
            "tensor(8.5878e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2905, Task: 2, loss: 0.00009\n",
            "tensor(8.6040e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2905, Task: 3, loss: 0.00009\n",
            "tensor(8.5979e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2905, Task: 4, loss: 0.00009\n",
            "tensor(8.6262e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2905, Task: 5, loss: 0.00009\n",
            "tensor(2.1949e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2905, Task: 6, loss: 0.00002\n",
            "tensor(1.0090e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2905, Task: 7, loss: 0.00001\n",
            "tensor(1.0053e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2905, Task: 8, loss: 0.00001\n",
            "tensor(8.5452e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5792e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2906, Task: 0, loss: 0.00009\n",
            "tensor(8.6213e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2906, Task: 1, loss: 0.00009\n",
            "tensor(8.5871e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2906, Task: 2, loss: 0.00009\n",
            "tensor(8.6033e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2906, Task: 3, loss: 0.00009\n",
            "tensor(8.5972e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2906, Task: 4, loss: 0.00009\n",
            "tensor(8.6255e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2906, Task: 5, loss: 0.00009\n",
            "tensor(2.1951e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2906, Task: 6, loss: 0.00002\n",
            "tensor(1.0093e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2906, Task: 7, loss: 0.00001\n",
            "tensor(1.0056e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2906, Task: 8, loss: 0.00001\n",
            "tensor(8.5464e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5791e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2907, Task: 0, loss: 0.00009\n",
            "tensor(8.6206e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2907, Task: 1, loss: 0.00009\n",
            "tensor(8.5864e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2907, Task: 2, loss: 0.00009\n",
            "tensor(8.6025e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2907, Task: 3, loss: 0.00009\n",
            "tensor(8.5965e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2907, Task: 4, loss: 0.00009\n",
            "tensor(8.6248e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2907, Task: 5, loss: 0.00009\n",
            "tensor(2.1952e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2907, Task: 6, loss: 0.00002\n",
            "tensor(1.0096e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2907, Task: 7, loss: 0.00001\n",
            "tensor(1.0060e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2907, Task: 8, loss: 0.00001\n",
            "tensor(8.5476e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5789e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2908, Task: 0, loss: 0.00009\n",
            "tensor(8.6199e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2908, Task: 1, loss: 0.00009\n",
            "tensor(8.5857e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2908, Task: 2, loss: 0.00009\n",
            "tensor(8.6018e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2908, Task: 3, loss: 0.00009\n",
            "tensor(8.5958e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2908, Task: 4, loss: 0.00009\n",
            "tensor(8.6241e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2908, Task: 5, loss: 0.00009\n",
            "tensor(2.1953e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2908, Task: 6, loss: 0.00002\n",
            "tensor(1.0099e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2908, Task: 7, loss: 0.00001\n",
            "tensor(1.0063e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2908, Task: 8, loss: 0.00001\n",
            "tensor(8.5488e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5788e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2909, Task: 0, loss: 0.00009\n",
            "tensor(8.6192e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2909, Task: 1, loss: 0.00009\n",
            "tensor(8.5850e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2909, Task: 2, loss: 0.00009\n",
            "tensor(8.6011e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2909, Task: 3, loss: 0.00009\n",
            "tensor(8.5951e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2909, Task: 4, loss: 0.00009\n",
            "tensor(8.6234e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2909, Task: 5, loss: 0.00009\n",
            "tensor(2.1954e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2909, Task: 6, loss: 0.00002\n",
            "tensor(1.0102e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2909, Task: 7, loss: 0.00001\n",
            "tensor(1.0066e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2909, Task: 8, loss: 0.00001\n",
            "tensor(8.5500e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5786e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2910, Task: 0, loss: 0.00009\n",
            "tensor(8.6185e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2910, Task: 1, loss: 0.00009\n",
            "tensor(8.5843e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2910, Task: 2, loss: 0.00009\n",
            "tensor(8.6004e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2910, Task: 3, loss: 0.00009\n",
            "tensor(8.5944e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2910, Task: 4, loss: 0.00009\n",
            "tensor(8.6227e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2910, Task: 5, loss: 0.00009\n",
            "tensor(2.1955e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2910, Task: 6, loss: 0.00002\n",
            "tensor(1.0105e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2910, Task: 7, loss: 0.00001\n",
            "tensor(1.0069e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2910, Task: 8, loss: 0.00001\n",
            "tensor(8.5512e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5784e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2911, Task: 0, loss: 0.00009\n",
            "tensor(8.6178e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2911, Task: 1, loss: 0.00009\n",
            "tensor(8.5836e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2911, Task: 2, loss: 0.00009\n",
            "tensor(8.5998e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2911, Task: 3, loss: 0.00009\n",
            "tensor(8.5937e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2911, Task: 4, loss: 0.00009\n",
            "tensor(8.6220e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2911, Task: 5, loss: 0.00009\n",
            "tensor(2.1956e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2911, Task: 6, loss: 0.00002\n",
            "tensor(1.0108e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2911, Task: 7, loss: 0.00001\n",
            "tensor(1.0072e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2911, Task: 8, loss: 0.00001\n",
            "tensor(8.5524e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5783e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2912, Task: 0, loss: 0.00009\n",
            "tensor(8.6171e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2912, Task: 1, loss: 0.00009\n",
            "tensor(8.5829e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2912, Task: 2, loss: 0.00009\n",
            "tensor(8.5991e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2912, Task: 3, loss: 0.00009\n",
            "tensor(8.5930e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2912, Task: 4, loss: 0.00009\n",
            "tensor(8.6213e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2912, Task: 5, loss: 0.00009\n",
            "tensor(2.1957e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2912, Task: 6, loss: 0.00002\n",
            "tensor(1.0111e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2912, Task: 7, loss: 0.00001\n",
            "tensor(1.0076e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2912, Task: 8, loss: 0.00001\n",
            "tensor(8.5536e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5781e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2913, Task: 0, loss: 0.00009\n",
            "tensor(8.6164e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2913, Task: 1, loss: 0.00009\n",
            "tensor(8.5822e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2913, Task: 2, loss: 0.00009\n",
            "tensor(8.5984e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2913, Task: 3, loss: 0.00009\n",
            "tensor(8.5923e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2913, Task: 4, loss: 0.00009\n",
            "tensor(8.6206e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2913, Task: 5, loss: 0.00009\n",
            "tensor(2.1958e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2913, Task: 6, loss: 0.00002\n",
            "tensor(1.0114e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2913, Task: 7, loss: 0.00001\n",
            "tensor(1.0079e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2913, Task: 8, loss: 0.00001\n",
            "tensor(8.5547e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5780e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2914, Task: 0, loss: 0.00009\n",
            "tensor(8.6157e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2914, Task: 1, loss: 0.00009\n",
            "tensor(8.5815e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2914, Task: 2, loss: 0.00009\n",
            "tensor(8.5977e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2914, Task: 3, loss: 0.00009\n",
            "tensor(8.5916e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2914, Task: 4, loss: 0.00009\n",
            "tensor(8.6199e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2914, Task: 5, loss: 0.00009\n",
            "tensor(2.1959e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2914, Task: 6, loss: 0.00002\n",
            "tensor(1.0117e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2914, Task: 7, loss: 0.00001\n",
            "tensor(1.0082e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2914, Task: 8, loss: 0.00001\n",
            "tensor(8.5559e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5778e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2915, Task: 0, loss: 0.00009\n",
            "tensor(8.6150e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2915, Task: 1, loss: 0.00009\n",
            "tensor(8.5808e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2915, Task: 2, loss: 0.00009\n",
            "tensor(8.5970e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2915, Task: 3, loss: 0.00009\n",
            "tensor(8.5909e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2915, Task: 4, loss: 0.00009\n",
            "tensor(8.6192e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2915, Task: 5, loss: 0.00009\n",
            "tensor(2.1960e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2915, Task: 6, loss: 0.00002\n",
            "tensor(1.0120e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2915, Task: 7, loss: 0.00001\n",
            "tensor(1.0085e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2915, Task: 8, loss: 0.00001\n",
            "tensor(8.5571e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5777e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2916, Task: 0, loss: 0.00009\n",
            "tensor(8.6143e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2916, Task: 1, loss: 0.00009\n",
            "tensor(8.5801e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2916, Task: 2, loss: 0.00009\n",
            "tensor(8.5963e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2916, Task: 3, loss: 0.00009\n",
            "tensor(8.5902e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2916, Task: 4, loss: 0.00009\n",
            "tensor(8.6185e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2916, Task: 5, loss: 0.00009\n",
            "tensor(2.1961e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2916, Task: 6, loss: 0.00002\n",
            "tensor(1.0123e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2916, Task: 7, loss: 0.00001\n",
            "tensor(1.0088e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2916, Task: 8, loss: 0.00001\n",
            "tensor(8.5583e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5775e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2917, Task: 0, loss: 0.00009\n",
            "tensor(8.6136e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2917, Task: 1, loss: 0.00009\n",
            "tensor(8.5795e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2917, Task: 2, loss: 0.00009\n",
            "tensor(8.5956e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2917, Task: 3, loss: 0.00009\n",
            "tensor(8.5895e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2917, Task: 4, loss: 0.00009\n",
            "tensor(8.6178e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2917, Task: 5, loss: 0.00009\n",
            "tensor(2.1962e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2917, Task: 6, loss: 0.00002\n",
            "tensor(1.0126e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2917, Task: 7, loss: 0.00001\n",
            "tensor(1.0092e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2917, Task: 8, loss: 0.00001\n",
            "tensor(8.5595e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5773e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2918, Task: 0, loss: 0.00009\n",
            "tensor(8.6130e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2918, Task: 1, loss: 0.00009\n",
            "tensor(8.5788e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2918, Task: 2, loss: 0.00009\n",
            "tensor(8.5949e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2918, Task: 3, loss: 0.00009\n",
            "tensor(8.5888e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2918, Task: 4, loss: 0.00009\n",
            "tensor(8.6171e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2918, Task: 5, loss: 0.00009\n",
            "tensor(2.1963e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2918, Task: 6, loss: 0.00002\n",
            "tensor(1.0129e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2918, Task: 7, loss: 0.00001\n",
            "tensor(1.0095e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2918, Task: 8, loss: 0.00001\n",
            "tensor(8.5607e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5772e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2919, Task: 0, loss: 0.00009\n",
            "tensor(8.6123e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2919, Task: 1, loss: 0.00009\n",
            "tensor(8.5781e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2919, Task: 2, loss: 0.00009\n",
            "tensor(8.5942e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2919, Task: 3, loss: 0.00009\n",
            "tensor(8.5881e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2919, Task: 4, loss: 0.00009\n",
            "tensor(8.6164e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2919, Task: 5, loss: 0.00009\n",
            "tensor(2.1964e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2919, Task: 6, loss: 0.00002\n",
            "tensor(1.0132e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2919, Task: 7, loss: 0.00001\n",
            "tensor(1.0098e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2919, Task: 8, loss: 0.00001\n",
            "tensor(8.5618e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5770e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2920, Task: 0, loss: 0.00009\n",
            "tensor(8.6116e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2920, Task: 1, loss: 0.00009\n",
            "tensor(8.5774e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2920, Task: 2, loss: 0.00009\n",
            "tensor(8.5935e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2920, Task: 3, loss: 0.00009\n",
            "tensor(8.5875e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2920, Task: 4, loss: 0.00009\n",
            "tensor(8.6157e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2920, Task: 5, loss: 0.00009\n",
            "tensor(2.1965e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2920, Task: 6, loss: 0.00002\n",
            "tensor(1.0135e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2920, Task: 7, loss: 0.00001\n",
            "tensor(1.0101e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2920, Task: 8, loss: 0.00001\n",
            "tensor(8.5630e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5769e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2921, Task: 0, loss: 0.00009\n",
            "tensor(8.6109e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2921, Task: 1, loss: 0.00009\n",
            "tensor(8.5767e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2921, Task: 2, loss: 0.00009\n",
            "tensor(8.5928e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2921, Task: 3, loss: 0.00009\n",
            "tensor(8.5868e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2921, Task: 4, loss: 0.00009\n",
            "tensor(8.6151e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2921, Task: 5, loss: 0.00009\n",
            "tensor(2.1966e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2921, Task: 6, loss: 0.00002\n",
            "tensor(1.0138e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2921, Task: 7, loss: 0.00001\n",
            "tensor(1.0104e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2921, Task: 8, loss: 0.00001\n",
            "tensor(8.5642e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5767e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2922, Task: 0, loss: 0.00009\n",
            "tensor(8.6102e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2922, Task: 1, loss: 0.00009\n",
            "tensor(8.5760e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2922, Task: 2, loss: 0.00009\n",
            "tensor(8.5922e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2922, Task: 3, loss: 0.00009\n",
            "tensor(8.5861e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2922, Task: 4, loss: 0.00009\n",
            "tensor(8.6144e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2922, Task: 5, loss: 0.00009\n",
            "tensor(2.1968e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2922, Task: 6, loss: 0.00002\n",
            "tensor(1.0141e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2922, Task: 7, loss: 0.00001\n",
            "tensor(1.0107e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2922, Task: 8, loss: 0.00001\n",
            "tensor(8.5654e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5766e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2923, Task: 0, loss: 0.00009\n",
            "tensor(8.6095e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2923, Task: 1, loss: 0.00009\n",
            "tensor(8.5753e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2923, Task: 2, loss: 0.00009\n",
            "tensor(8.5915e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2923, Task: 3, loss: 0.00009\n",
            "tensor(8.5854e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2923, Task: 4, loss: 0.00009\n",
            "tensor(8.6137e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2923, Task: 5, loss: 0.00009\n",
            "tensor(2.1969e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2923, Task: 6, loss: 0.00002\n",
            "tensor(1.0144e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2923, Task: 7, loss: 0.00001\n",
            "tensor(1.0110e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2923, Task: 8, loss: 0.00001\n",
            "tensor(8.5665e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5764e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2924, Task: 0, loss: 0.00009\n",
            "tensor(8.6088e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2924, Task: 1, loss: 0.00009\n",
            "tensor(8.5747e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2924, Task: 2, loss: 0.00009\n",
            "tensor(8.5908e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2924, Task: 3, loss: 0.00009\n",
            "tensor(8.5847e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2924, Task: 4, loss: 0.00009\n",
            "tensor(8.6130e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2924, Task: 5, loss: 0.00009\n",
            "tensor(2.1970e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2924, Task: 6, loss: 0.00002\n",
            "tensor(1.0146e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2924, Task: 7, loss: 0.00001\n",
            "tensor(1.0114e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2924, Task: 8, loss: 0.00001\n",
            "tensor(8.5677e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5763e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2925, Task: 0, loss: 0.00009\n",
            "tensor(8.6082e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2925, Task: 1, loss: 0.00009\n",
            "tensor(8.5740e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2925, Task: 2, loss: 0.00009\n",
            "tensor(8.5901e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2925, Task: 3, loss: 0.00009\n",
            "tensor(8.5840e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2925, Task: 4, loss: 0.00009\n",
            "tensor(8.6123e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2925, Task: 5, loss: 0.00009\n",
            "tensor(2.1971e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2925, Task: 6, loss: 0.00002\n",
            "tensor(1.0149e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2925, Task: 7, loss: 0.00001\n",
            "tensor(1.0117e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2925, Task: 8, loss: 0.00001\n",
            "tensor(8.5688e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5761e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2926, Task: 0, loss: 0.00009\n",
            "tensor(8.6075e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2926, Task: 1, loss: 0.00009\n",
            "tensor(8.5733e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2926, Task: 2, loss: 0.00009\n",
            "tensor(8.5894e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2926, Task: 3, loss: 0.00009\n",
            "tensor(8.5834e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2926, Task: 4, loss: 0.00009\n",
            "tensor(8.6116e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2926, Task: 5, loss: 0.00009\n",
            "tensor(2.1972e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2926, Task: 6, loss: 0.00002\n",
            "tensor(1.0152e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2926, Task: 7, loss: 0.00001\n",
            "tensor(1.0120e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2926, Task: 8, loss: 0.00001\n",
            "tensor(8.5700e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5760e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2927, Task: 0, loss: 0.00009\n",
            "tensor(8.6068e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2927, Task: 1, loss: 0.00009\n",
            "tensor(8.5726e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2927, Task: 2, loss: 0.00009\n",
            "tensor(8.5888e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2927, Task: 3, loss: 0.00009\n",
            "tensor(8.5827e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2927, Task: 4, loss: 0.00009\n",
            "tensor(8.6110e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2927, Task: 5, loss: 0.00009\n",
            "tensor(2.1973e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2927, Task: 6, loss: 0.00002\n",
            "tensor(1.0155e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2927, Task: 7, loss: 0.00001\n",
            "tensor(1.0123e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2927, Task: 8, loss: 0.00001\n",
            "tensor(8.5711e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5758e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2928, Task: 0, loss: 0.00009\n",
            "tensor(8.6061e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2928, Task: 1, loss: 0.00009\n",
            "tensor(8.5719e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2928, Task: 2, loss: 0.00009\n",
            "tensor(8.5881e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2928, Task: 3, loss: 0.00009\n",
            "tensor(8.5820e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2928, Task: 4, loss: 0.00009\n",
            "tensor(8.6103e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2928, Task: 5, loss: 0.00009\n",
            "tensor(2.1974e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2928, Task: 6, loss: 0.00002\n",
            "tensor(1.0158e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2928, Task: 7, loss: 0.00001\n",
            "tensor(1.0126e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2928, Task: 8, loss: 0.00001\n",
            "tensor(8.5723e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5757e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2929, Task: 0, loss: 0.00009\n",
            "tensor(8.6054e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2929, Task: 1, loss: 0.00009\n",
            "tensor(8.5713e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2929, Task: 2, loss: 0.00009\n",
            "tensor(8.5874e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2929, Task: 3, loss: 0.00009\n",
            "tensor(8.5813e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2929, Task: 4, loss: 0.00009\n",
            "tensor(8.6096e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2929, Task: 5, loss: 0.00009\n",
            "tensor(2.1975e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2929, Task: 6, loss: 0.00002\n",
            "tensor(1.0161e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2929, Task: 7, loss: 0.00001\n",
            "tensor(1.0129e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2929, Task: 8, loss: 0.00001\n",
            "tensor(8.5735e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5755e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2930, Task: 0, loss: 0.00009\n",
            "tensor(8.6048e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2930, Task: 1, loss: 0.00009\n",
            "tensor(8.5706e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2930, Task: 2, loss: 0.00009\n",
            "tensor(8.5867e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2930, Task: 3, loss: 0.00009\n",
            "tensor(8.5807e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2930, Task: 4, loss: 0.00009\n",
            "tensor(8.6089e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2930, Task: 5, loss: 0.00009\n",
            "tensor(2.1976e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2930, Task: 6, loss: 0.00002\n",
            "tensor(1.0164e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2930, Task: 7, loss: 0.00001\n",
            "tensor(1.0132e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2930, Task: 8, loss: 0.00001\n",
            "tensor(8.5746e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5754e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2931, Task: 0, loss: 0.00009\n",
            "tensor(8.6041e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2931, Task: 1, loss: 0.00009\n",
            "tensor(8.5699e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2931, Task: 2, loss: 0.00009\n",
            "tensor(8.5860e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2931, Task: 3, loss: 0.00009\n",
            "tensor(8.5800e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2931, Task: 4, loss: 0.00009\n",
            "tensor(8.6083e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2931, Task: 5, loss: 0.00009\n",
            "tensor(2.1977e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2931, Task: 6, loss: 0.00002\n",
            "tensor(1.0167e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2931, Task: 7, loss: 0.00001\n",
            "tensor(1.0136e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2931, Task: 8, loss: 0.00001\n",
            "tensor(8.5757e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5752e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2932, Task: 0, loss: 0.00009\n",
            "tensor(8.6034e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2932, Task: 1, loss: 0.00009\n",
            "tensor(8.5693e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2932, Task: 2, loss: 0.00009\n",
            "tensor(8.5854e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2932, Task: 3, loss: 0.00009\n",
            "tensor(8.5793e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2932, Task: 4, loss: 0.00009\n",
            "tensor(8.6076e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2932, Task: 5, loss: 0.00009\n",
            "tensor(2.1978e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2932, Task: 6, loss: 0.00002\n",
            "tensor(1.0170e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2932, Task: 7, loss: 0.00001\n",
            "tensor(1.0139e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2932, Task: 8, loss: 0.00001\n",
            "tensor(8.5769e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5750e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2933, Task: 0, loss: 0.00009\n",
            "tensor(8.6027e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2933, Task: 1, loss: 0.00009\n",
            "tensor(8.5686e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2933, Task: 2, loss: 0.00009\n",
            "tensor(8.5847e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2933, Task: 3, loss: 0.00009\n",
            "tensor(8.5786e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2933, Task: 4, loss: 0.00009\n",
            "tensor(8.6069e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2933, Task: 5, loss: 0.00009\n",
            "tensor(2.1979e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2933, Task: 6, loss: 0.00002\n",
            "tensor(1.0173e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2933, Task: 7, loss: 0.00001\n",
            "tensor(1.0142e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2933, Task: 8, loss: 0.00001\n",
            "tensor(8.5780e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5749e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2934, Task: 0, loss: 0.00009\n",
            "tensor(8.6021e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2934, Task: 1, loss: 0.00009\n",
            "tensor(8.5679e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2934, Task: 2, loss: 0.00009\n",
            "tensor(8.5840e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2934, Task: 3, loss: 0.00009\n",
            "tensor(8.5780e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2934, Task: 4, loss: 0.00009\n",
            "tensor(8.6062e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2934, Task: 5, loss: 0.00009\n",
            "tensor(2.1980e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2934, Task: 6, loss: 0.00002\n",
            "tensor(1.0176e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2934, Task: 7, loss: 0.00001\n",
            "tensor(1.0145e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2934, Task: 8, loss: 0.00001\n",
            "tensor(8.5792e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5747e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2935, Task: 0, loss: 0.00009\n",
            "tensor(8.6014e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2935, Task: 1, loss: 0.00009\n",
            "tensor(8.5672e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2935, Task: 2, loss: 0.00009\n",
            "tensor(8.5834e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2935, Task: 3, loss: 0.00009\n",
            "tensor(8.5773e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2935, Task: 4, loss: 0.00009\n",
            "tensor(8.6056e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2935, Task: 5, loss: 0.00009\n",
            "tensor(2.1981e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2935, Task: 6, loss: 0.00002\n",
            "tensor(1.0178e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2935, Task: 7, loss: 0.00001\n",
            "tensor(1.0148e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2935, Task: 8, loss: 0.00001\n",
            "tensor(8.5803e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5746e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2936, Task: 0, loss: 0.00009\n",
            "tensor(8.6007e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2936, Task: 1, loss: 0.00009\n",
            "tensor(8.5666e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2936, Task: 2, loss: 0.00009\n",
            "tensor(8.5827e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2936, Task: 3, loss: 0.00009\n",
            "tensor(8.5766e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2936, Task: 4, loss: 0.00009\n",
            "tensor(8.6049e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2936, Task: 5, loss: 0.00009\n",
            "tensor(2.1982e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2936, Task: 6, loss: 0.00002\n",
            "tensor(1.0181e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2936, Task: 7, loss: 0.00001\n",
            "tensor(1.0151e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2936, Task: 8, loss: 0.00001\n",
            "tensor(8.5814e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5744e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2937, Task: 0, loss: 0.00009\n",
            "tensor(8.6001e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2937, Task: 1, loss: 0.00009\n",
            "tensor(8.5659e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2937, Task: 2, loss: 0.00009\n",
            "tensor(8.5820e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2937, Task: 3, loss: 0.00009\n",
            "tensor(8.5760e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2937, Task: 4, loss: 0.00009\n",
            "tensor(8.6042e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2937, Task: 5, loss: 0.00009\n",
            "tensor(2.1983e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2937, Task: 6, loss: 0.00002\n",
            "tensor(1.0184e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2937, Task: 7, loss: 0.00001\n",
            "tensor(1.0154e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2937, Task: 8, loss: 0.00001\n",
            "tensor(8.5825e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5743e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2938, Task: 0, loss: 0.00009\n",
            "tensor(8.5994e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2938, Task: 1, loss: 0.00009\n",
            "tensor(8.5652e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2938, Task: 2, loss: 0.00009\n",
            "tensor(8.5814e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2938, Task: 3, loss: 0.00009\n",
            "tensor(8.5753e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2938, Task: 4, loss: 0.00009\n",
            "tensor(8.6036e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2938, Task: 5, loss: 0.00009\n",
            "tensor(2.1985e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2938, Task: 6, loss: 0.00002\n",
            "tensor(1.0187e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2938, Task: 7, loss: 0.00001\n",
            "tensor(1.0157e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2938, Task: 8, loss: 0.00001\n",
            "tensor(8.5837e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5741e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2939, Task: 0, loss: 0.00009\n",
            "tensor(8.5987e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2939, Task: 1, loss: 0.00009\n",
            "tensor(8.5646e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2939, Task: 2, loss: 0.00009\n",
            "tensor(8.5807e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2939, Task: 3, loss: 0.00009\n",
            "tensor(8.5746e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2939, Task: 4, loss: 0.00009\n",
            "tensor(8.6029e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2939, Task: 5, loss: 0.00009\n",
            "tensor(2.1986e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2939, Task: 6, loss: 0.00002\n",
            "tensor(1.0190e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2939, Task: 7, loss: 0.00001\n",
            "tensor(1.0160e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2939, Task: 8, loss: 0.00001\n",
            "tensor(8.5848e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5740e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2940, Task: 0, loss: 0.00009\n",
            "tensor(8.5981e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2940, Task: 1, loss: 0.00009\n",
            "tensor(8.5639e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2940, Task: 2, loss: 0.00009\n",
            "tensor(8.5800e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2940, Task: 3, loss: 0.00009\n",
            "tensor(8.5740e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2940, Task: 4, loss: 0.00009\n",
            "tensor(8.6022e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2940, Task: 5, loss: 0.00009\n",
            "tensor(2.1987e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2940, Task: 6, loss: 0.00002\n",
            "tensor(1.0193e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2940, Task: 7, loss: 0.00001\n",
            "tensor(1.0164e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2940, Task: 8, loss: 0.00001\n",
            "tensor(8.5859e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5738e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2941, Task: 0, loss: 0.00009\n",
            "tensor(8.5974e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2941, Task: 1, loss: 0.00009\n",
            "tensor(8.5633e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2941, Task: 2, loss: 0.00009\n",
            "tensor(8.5794e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2941, Task: 3, loss: 0.00009\n",
            "tensor(8.5733e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2941, Task: 4, loss: 0.00009\n",
            "tensor(8.6016e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2941, Task: 5, loss: 0.00009\n",
            "tensor(2.1988e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2941, Task: 6, loss: 0.00002\n",
            "tensor(1.0196e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2941, Task: 7, loss: 0.00001\n",
            "tensor(1.0167e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2941, Task: 8, loss: 0.00001\n",
            "tensor(8.5870e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5737e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2942, Task: 0, loss: 0.00009\n",
            "tensor(8.5967e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2942, Task: 1, loss: 0.00009\n",
            "tensor(8.5626e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2942, Task: 2, loss: 0.00009\n",
            "tensor(8.5787e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2942, Task: 3, loss: 0.00009\n",
            "tensor(8.5726e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2942, Task: 4, loss: 0.00009\n",
            "tensor(8.6009e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2942, Task: 5, loss: 0.00009\n",
            "tensor(2.1989e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2942, Task: 6, loss: 0.00002\n",
            "tensor(1.0198e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2942, Task: 7, loss: 0.00001\n",
            "tensor(1.0170e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2942, Task: 8, loss: 0.00001\n",
            "tensor(8.5881e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5735e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2943, Task: 0, loss: 0.00009\n",
            "tensor(8.5961e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2943, Task: 1, loss: 0.00009\n",
            "tensor(8.5619e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2943, Task: 2, loss: 0.00009\n",
            "tensor(8.5780e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2943, Task: 3, loss: 0.00009\n",
            "tensor(8.5720e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2943, Task: 4, loss: 0.00009\n",
            "tensor(8.6002e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2943, Task: 5, loss: 0.00009\n",
            "tensor(2.1990e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2943, Task: 6, loss: 0.00002\n",
            "tensor(1.0201e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2943, Task: 7, loss: 0.00001\n",
            "tensor(1.0173e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2943, Task: 8, loss: 0.00001\n",
            "tensor(8.5892e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5734e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2944, Task: 0, loss: 0.00009\n",
            "tensor(8.5954e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2944, Task: 1, loss: 0.00009\n",
            "tensor(8.5613e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2944, Task: 2, loss: 0.00009\n",
            "tensor(8.5774e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2944, Task: 3, loss: 0.00009\n",
            "tensor(8.5713e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2944, Task: 4, loss: 0.00009\n",
            "tensor(8.5996e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2944, Task: 5, loss: 0.00009\n",
            "tensor(2.1991e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2944, Task: 6, loss: 0.00002\n",
            "tensor(1.0204e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2944, Task: 7, loss: 0.00001\n",
            "tensor(1.0176e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2944, Task: 8, loss: 0.00001\n",
            "tensor(8.5903e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5732e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2945, Task: 0, loss: 0.00009\n",
            "tensor(8.5948e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2945, Task: 1, loss: 0.00009\n",
            "tensor(8.5606e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2945, Task: 2, loss: 0.00009\n",
            "tensor(8.5767e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2945, Task: 3, loss: 0.00009\n",
            "tensor(8.5707e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2945, Task: 4, loss: 0.00009\n",
            "tensor(8.5989e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2945, Task: 5, loss: 0.00009\n",
            "tensor(2.1992e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2945, Task: 6, loss: 0.00002\n",
            "tensor(1.0207e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2945, Task: 7, loss: 0.00001\n",
            "tensor(1.0179e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2945, Task: 8, loss: 0.00001\n",
            "tensor(8.5915e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5731e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2946, Task: 0, loss: 0.00009\n",
            "tensor(8.5941e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2946, Task: 1, loss: 0.00009\n",
            "tensor(8.5600e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2946, Task: 2, loss: 0.00009\n",
            "tensor(8.5761e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2946, Task: 3, loss: 0.00009\n",
            "tensor(8.5700e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2946, Task: 4, loss: 0.00009\n",
            "tensor(8.5983e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2946, Task: 5, loss: 0.00009\n",
            "tensor(2.1993e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2946, Task: 6, loss: 0.00002\n",
            "tensor(1.0210e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2946, Task: 7, loss: 0.00001\n",
            "tensor(1.0182e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2946, Task: 8, loss: 0.00001\n",
            "tensor(8.5926e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5729e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2947, Task: 0, loss: 0.00009\n",
            "tensor(8.5934e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2947, Task: 1, loss: 0.00009\n",
            "tensor(8.5593e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2947, Task: 2, loss: 0.00009\n",
            "tensor(8.5754e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2947, Task: 3, loss: 0.00009\n",
            "tensor(8.5694e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2947, Task: 4, loss: 0.00009\n",
            "tensor(8.5976e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2947, Task: 5, loss: 0.00009\n",
            "tensor(2.1994e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2947, Task: 6, loss: 0.00002\n",
            "tensor(1.0213e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2947, Task: 7, loss: 0.00001\n",
            "tensor(1.0185e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2947, Task: 8, loss: 0.00001\n",
            "tensor(8.5937e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5728e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2948, Task: 0, loss: 0.00009\n",
            "tensor(8.5928e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2948, Task: 1, loss: 0.00009\n",
            "tensor(8.5586e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2948, Task: 2, loss: 0.00009\n",
            "tensor(8.5748e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2948, Task: 3, loss: 0.00009\n",
            "tensor(8.5687e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2948, Task: 4, loss: 0.00009\n",
            "tensor(8.5969e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2948, Task: 5, loss: 0.00009\n",
            "tensor(2.1995e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2948, Task: 6, loss: 0.00002\n",
            "tensor(1.0216e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2948, Task: 7, loss: 0.00001\n",
            "tensor(1.0188e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2948, Task: 8, loss: 0.00001\n",
            "tensor(8.5948e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5726e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2949, Task: 0, loss: 0.00009\n",
            "tensor(8.5921e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2949, Task: 1, loss: 0.00009\n",
            "tensor(8.5580e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2949, Task: 2, loss: 0.00009\n",
            "tensor(8.5741e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2949, Task: 3, loss: 0.00009\n",
            "tensor(8.5680e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2949, Task: 4, loss: 0.00009\n",
            "tensor(8.5963e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2949, Task: 5, loss: 0.00009\n",
            "tensor(2.1996e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2949, Task: 6, loss: 0.00002\n",
            "tensor(1.0218e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2949, Task: 7, loss: 0.00001\n",
            "tensor(1.0191e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2949, Task: 8, loss: 0.00001\n",
            "tensor(8.5959e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5725e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2950, Task: 0, loss: 0.00009\n",
            "tensor(8.5915e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2950, Task: 1, loss: 0.00009\n",
            "tensor(8.5573e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2950, Task: 2, loss: 0.00009\n",
            "tensor(8.5734e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2950, Task: 3, loss: 0.00009\n",
            "tensor(8.5674e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2950, Task: 4, loss: 0.00009\n",
            "tensor(8.5956e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2950, Task: 5, loss: 0.00009\n",
            "tensor(2.1997e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2950, Task: 6, loss: 0.00002\n",
            "tensor(1.0221e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2950, Task: 7, loss: 0.00001\n",
            "tensor(1.0194e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2950, Task: 8, loss: 0.00001\n",
            "tensor(8.5969e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5723e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2951, Task: 0, loss: 0.00009\n",
            "tensor(8.5908e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2951, Task: 1, loss: 0.00009\n",
            "tensor(8.5567e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2951, Task: 2, loss: 0.00009\n",
            "tensor(8.5728e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2951, Task: 3, loss: 0.00009\n",
            "tensor(8.5667e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2951, Task: 4, loss: 0.00009\n",
            "tensor(8.5950e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2951, Task: 5, loss: 0.00009\n",
            "tensor(2.1998e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2951, Task: 6, loss: 0.00002\n",
            "tensor(1.0224e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2951, Task: 7, loss: 0.00001\n",
            "tensor(1.0197e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2951, Task: 8, loss: 0.00001\n",
            "tensor(8.5980e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5722e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2952, Task: 0, loss: 0.00009\n",
            "tensor(8.5902e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2952, Task: 1, loss: 0.00009\n",
            "tensor(8.5560e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2952, Task: 2, loss: 0.00009\n",
            "tensor(8.5721e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2952, Task: 3, loss: 0.00009\n",
            "tensor(8.5661e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2952, Task: 4, loss: 0.00009\n",
            "tensor(8.5943e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2952, Task: 5, loss: 0.00009\n",
            "tensor(2.1999e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2952, Task: 6, loss: 0.00002\n",
            "tensor(1.0227e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2952, Task: 7, loss: 0.00001\n",
            "tensor(1.0200e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2952, Task: 8, loss: 0.00001\n",
            "tensor(8.5991e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5721e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2953, Task: 0, loss: 0.00009\n",
            "tensor(8.5895e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2953, Task: 1, loss: 0.00009\n",
            "tensor(8.5554e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2953, Task: 2, loss: 0.00009\n",
            "tensor(8.5715e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2953, Task: 3, loss: 0.00009\n",
            "tensor(8.5654e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2953, Task: 4, loss: 0.00009\n",
            "tensor(8.5937e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2953, Task: 5, loss: 0.00009\n",
            "tensor(2.2000e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2953, Task: 6, loss: 0.00002\n",
            "tensor(1.0230e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2953, Task: 7, loss: 0.00001\n",
            "tensor(1.0203e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2953, Task: 8, loss: 0.00001\n",
            "tensor(8.6002e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5719e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2954, Task: 0, loss: 0.00009\n",
            "tensor(8.5889e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2954, Task: 1, loss: 0.00009\n",
            "tensor(8.5547e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2954, Task: 2, loss: 0.00009\n",
            "tensor(8.5708e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2954, Task: 3, loss: 0.00009\n",
            "tensor(8.5648e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2954, Task: 4, loss: 0.00009\n",
            "tensor(8.5930e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2954, Task: 5, loss: 0.00009\n",
            "tensor(2.2001e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2954, Task: 6, loss: 0.00002\n",
            "tensor(1.0233e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2954, Task: 7, loss: 0.00001\n",
            "tensor(1.0206e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2954, Task: 8, loss: 0.00001\n",
            "tensor(8.6013e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5718e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2955, Task: 0, loss: 0.00009\n",
            "tensor(8.5882e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2955, Task: 1, loss: 0.00009\n",
            "tensor(8.5541e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2955, Task: 2, loss: 0.00009\n",
            "tensor(8.5702e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2955, Task: 3, loss: 0.00009\n",
            "tensor(8.5641e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2955, Task: 4, loss: 0.00009\n",
            "tensor(8.5924e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2955, Task: 5, loss: 0.00009\n",
            "tensor(2.2002e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2955, Task: 6, loss: 0.00002\n",
            "tensor(1.0235e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2955, Task: 7, loss: 0.00001\n",
            "tensor(1.0209e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2955, Task: 8, loss: 0.00001\n",
            "tensor(8.6024e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5716e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2956, Task: 0, loss: 0.00009\n",
            "tensor(8.5876e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2956, Task: 1, loss: 0.00009\n",
            "tensor(8.5534e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2956, Task: 2, loss: 0.00009\n",
            "tensor(8.5696e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2956, Task: 3, loss: 0.00009\n",
            "tensor(8.5635e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2956, Task: 4, loss: 0.00009\n",
            "tensor(8.5917e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2956, Task: 5, loss: 0.00009\n",
            "tensor(2.2003e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2956, Task: 6, loss: 0.00002\n",
            "tensor(1.0238e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2956, Task: 7, loss: 0.00001\n",
            "tensor(1.0213e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2956, Task: 8, loss: 0.00001\n",
            "tensor(8.6035e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5715e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2957, Task: 0, loss: 0.00009\n",
            "tensor(8.5869e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2957, Task: 1, loss: 0.00009\n",
            "tensor(8.5528e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2957, Task: 2, loss: 0.00009\n",
            "tensor(8.5689e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2957, Task: 3, loss: 0.00009\n",
            "tensor(8.5628e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2957, Task: 4, loss: 0.00009\n",
            "tensor(8.5911e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2957, Task: 5, loss: 0.00009\n",
            "tensor(2.2004e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2957, Task: 6, loss: 0.00002\n",
            "tensor(1.0241e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2957, Task: 7, loss: 0.00001\n",
            "tensor(1.0216e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2957, Task: 8, loss: 0.00001\n",
            "tensor(8.6045e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5713e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2958, Task: 0, loss: 0.00009\n",
            "tensor(8.5863e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2958, Task: 1, loss: 0.00009\n",
            "tensor(8.5522e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2958, Task: 2, loss: 0.00009\n",
            "tensor(8.5683e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2958, Task: 3, loss: 0.00009\n",
            "tensor(8.5622e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2958, Task: 4, loss: 0.00009\n",
            "tensor(8.5904e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2958, Task: 5, loss: 0.00009\n",
            "tensor(2.2006e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2958, Task: 6, loss: 0.00002\n",
            "tensor(1.0244e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2958, Task: 7, loss: 0.00001\n",
            "tensor(1.0219e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2958, Task: 8, loss: 0.00001\n",
            "tensor(8.6056e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5712e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2959, Task: 0, loss: 0.00009\n",
            "tensor(8.5856e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2959, Task: 1, loss: 0.00009\n",
            "tensor(8.5515e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2959, Task: 2, loss: 0.00009\n",
            "tensor(8.5676e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2959, Task: 3, loss: 0.00009\n",
            "tensor(8.5616e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2959, Task: 4, loss: 0.00009\n",
            "tensor(8.5898e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2959, Task: 5, loss: 0.00009\n",
            "tensor(2.2007e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2959, Task: 6, loss: 0.00002\n",
            "tensor(1.0247e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2959, Task: 7, loss: 0.00001\n",
            "tensor(1.0222e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2959, Task: 8, loss: 0.00001\n",
            "tensor(8.6067e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5710e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2960, Task: 0, loss: 0.00009\n",
            "tensor(8.5850e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2960, Task: 1, loss: 0.00009\n",
            "tensor(8.5509e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2960, Task: 2, loss: 0.00009\n",
            "tensor(8.5670e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2960, Task: 3, loss: 0.00009\n",
            "tensor(8.5609e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2960, Task: 4, loss: 0.00009\n",
            "tensor(8.5891e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2960, Task: 5, loss: 0.00009\n",
            "tensor(2.2008e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2960, Task: 6, loss: 0.00002\n",
            "tensor(1.0249e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2960, Task: 7, loss: 0.00001\n",
            "tensor(1.0225e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2960, Task: 8, loss: 0.00001\n",
            "tensor(8.6077e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5709e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2961, Task: 0, loss: 0.00009\n",
            "tensor(8.5843e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2961, Task: 1, loss: 0.00009\n",
            "tensor(8.5502e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2961, Task: 2, loss: 0.00009\n",
            "tensor(8.5663e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2961, Task: 3, loss: 0.00009\n",
            "tensor(8.5603e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2961, Task: 4, loss: 0.00009\n",
            "tensor(8.5885e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2961, Task: 5, loss: 0.00009\n",
            "tensor(2.2009e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2961, Task: 6, loss: 0.00002\n",
            "tensor(1.0252e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2961, Task: 7, loss: 0.00001\n",
            "tensor(1.0228e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2961, Task: 8, loss: 0.00001\n",
            "tensor(8.6088e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5707e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2962, Task: 0, loss: 0.00009\n",
            "tensor(8.5837e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2962, Task: 1, loss: 0.00009\n",
            "tensor(8.5496e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2962, Task: 2, loss: 0.00009\n",
            "tensor(8.5657e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2962, Task: 3, loss: 0.00009\n",
            "tensor(8.5596e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2962, Task: 4, loss: 0.00009\n",
            "tensor(8.5879e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2962, Task: 5, loss: 0.00009\n",
            "tensor(2.2010e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2962, Task: 6, loss: 0.00002\n",
            "tensor(1.0255e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2962, Task: 7, loss: 0.00001\n",
            "tensor(1.0231e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2962, Task: 8, loss: 0.00001\n",
            "tensor(8.6099e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5706e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2963, Task: 0, loss: 0.00009\n",
            "tensor(8.5831e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2963, Task: 1, loss: 0.00009\n",
            "tensor(8.5490e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2963, Task: 2, loss: 0.00009\n",
            "tensor(8.5651e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2963, Task: 3, loss: 0.00009\n",
            "tensor(8.5590e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2963, Task: 4, loss: 0.00009\n",
            "tensor(8.5872e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2963, Task: 5, loss: 0.00009\n",
            "tensor(2.2011e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2963, Task: 6, loss: 0.00002\n",
            "tensor(1.0258e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2963, Task: 7, loss: 0.00001\n",
            "tensor(1.0234e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2963, Task: 8, loss: 0.00001\n",
            "tensor(8.6109e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5704e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2964, Task: 0, loss: 0.00009\n",
            "tensor(8.5824e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2964, Task: 1, loss: 0.00009\n",
            "tensor(8.5483e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2964, Task: 2, loss: 0.00009\n",
            "tensor(8.5644e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2964, Task: 3, loss: 0.00009\n",
            "tensor(8.5584e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2964, Task: 4, loss: 0.00009\n",
            "tensor(8.5866e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2964, Task: 5, loss: 0.00009\n",
            "tensor(2.2012e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2964, Task: 6, loss: 0.00002\n",
            "tensor(1.0261e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2964, Task: 7, loss: 0.00001\n",
            "tensor(1.0237e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2964, Task: 8, loss: 0.00001\n",
            "tensor(8.6120e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5703e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2965, Task: 0, loss: 0.00009\n",
            "tensor(8.5818e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2965, Task: 1, loss: 0.00009\n",
            "tensor(8.5477e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2965, Task: 2, loss: 0.00009\n",
            "tensor(8.5638e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2965, Task: 3, loss: 0.00009\n",
            "tensor(8.5577e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2965, Task: 4, loss: 0.00009\n",
            "tensor(8.5859e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2965, Task: 5, loss: 0.00009\n",
            "tensor(2.2013e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2965, Task: 6, loss: 0.00002\n",
            "tensor(1.0263e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2965, Task: 7, loss: 0.00001\n",
            "tensor(1.0240e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2965, Task: 8, loss: 0.00001\n",
            "tensor(8.6130e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5702e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2966, Task: 0, loss: 0.00009\n",
            "tensor(8.5811e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2966, Task: 1, loss: 0.00009\n",
            "tensor(8.5470e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2966, Task: 2, loss: 0.00009\n",
            "tensor(8.5631e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2966, Task: 3, loss: 0.00009\n",
            "tensor(8.5571e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2966, Task: 4, loss: 0.00009\n",
            "tensor(8.5853e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2966, Task: 5, loss: 0.00009\n",
            "tensor(2.2014e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2966, Task: 6, loss: 0.00002\n",
            "tensor(1.0266e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2966, Task: 7, loss: 0.00001\n",
            "tensor(1.0243e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2966, Task: 8, loss: 0.00001\n",
            "tensor(8.6141e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5700e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2967, Task: 0, loss: 0.00009\n",
            "tensor(8.5805e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2967, Task: 1, loss: 0.00009\n",
            "tensor(8.5464e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2967, Task: 2, loss: 0.00009\n",
            "tensor(8.5625e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2967, Task: 3, loss: 0.00009\n",
            "tensor(8.5565e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2967, Task: 4, loss: 0.00009\n",
            "tensor(8.5847e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2967, Task: 5, loss: 0.00009\n",
            "tensor(2.2015e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2967, Task: 6, loss: 0.00002\n",
            "tensor(1.0269e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2967, Task: 7, loss: 0.00001\n",
            "tensor(1.0246e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2967, Task: 8, loss: 0.00001\n",
            "tensor(8.6151e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5699e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2968, Task: 0, loss: 0.00009\n",
            "tensor(8.5799e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2968, Task: 1, loss: 0.00009\n",
            "tensor(8.5458e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2968, Task: 2, loss: 0.00009\n",
            "tensor(8.5619e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2968, Task: 3, loss: 0.00009\n",
            "tensor(8.5558e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2968, Task: 4, loss: 0.00009\n",
            "tensor(8.5840e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2968, Task: 5, loss: 0.00009\n",
            "tensor(2.2016e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2968, Task: 6, loss: 0.00002\n",
            "tensor(1.0272e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2968, Task: 7, loss: 0.00001\n",
            "tensor(1.0249e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2968, Task: 8, loss: 0.00001\n",
            "tensor(8.6162e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5697e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2969, Task: 0, loss: 0.00009\n",
            "tensor(8.5792e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2969, Task: 1, loss: 0.00009\n",
            "tensor(8.5452e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2969, Task: 2, loss: 0.00009\n",
            "tensor(8.5612e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2969, Task: 3, loss: 0.00009\n",
            "tensor(8.5552e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2969, Task: 4, loss: 0.00009\n",
            "tensor(8.5834e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2969, Task: 5, loss: 0.00009\n",
            "tensor(2.2017e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2969, Task: 6, loss: 0.00002\n",
            "tensor(1.0274e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2969, Task: 7, loss: 0.00001\n",
            "tensor(1.0252e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2969, Task: 8, loss: 0.00001\n",
            "tensor(8.6172e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5696e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2970, Task: 0, loss: 0.00009\n",
            "tensor(8.5786e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2970, Task: 1, loss: 0.00009\n",
            "tensor(8.5445e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2970, Task: 2, loss: 0.00009\n",
            "tensor(8.5606e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2970, Task: 3, loss: 0.00009\n",
            "tensor(8.5546e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2970, Task: 4, loss: 0.00009\n",
            "tensor(8.5828e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2970, Task: 5, loss: 0.00009\n",
            "tensor(2.2018e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2970, Task: 6, loss: 0.00002\n",
            "tensor(1.0277e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2970, Task: 7, loss: 0.00001\n",
            "tensor(1.0255e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2970, Task: 8, loss: 0.00001\n",
            "tensor(8.6182e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5694e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2971, Task: 0, loss: 0.00009\n",
            "tensor(8.5780e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2971, Task: 1, loss: 0.00009\n",
            "tensor(8.5439e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2971, Task: 2, loss: 0.00009\n",
            "tensor(8.5600e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2971, Task: 3, loss: 0.00009\n",
            "tensor(8.5539e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2971, Task: 4, loss: 0.00009\n",
            "tensor(8.5821e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2971, Task: 5, loss: 0.00009\n",
            "tensor(2.2019e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2971, Task: 6, loss: 0.00002\n",
            "tensor(1.0280e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2971, Task: 7, loss: 0.00001\n",
            "tensor(1.0258e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2971, Task: 8, loss: 0.00001\n",
            "tensor(8.6193e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5693e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2972, Task: 0, loss: 0.00009\n",
            "tensor(8.5774e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2972, Task: 1, loss: 0.00009\n",
            "tensor(8.5433e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2972, Task: 2, loss: 0.00009\n",
            "tensor(8.5594e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2972, Task: 3, loss: 0.00009\n",
            "tensor(8.5533e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2972, Task: 4, loss: 0.00009\n",
            "tensor(8.5815e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2972, Task: 5, loss: 0.00009\n",
            "tensor(2.2020e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2972, Task: 6, loss: 0.00002\n",
            "tensor(1.0283e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2972, Task: 7, loss: 0.00001\n",
            "tensor(1.0261e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2972, Task: 8, loss: 0.00001\n",
            "tensor(8.6203e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5691e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2973, Task: 0, loss: 0.00009\n",
            "tensor(8.5767e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2973, Task: 1, loss: 0.00009\n",
            "tensor(8.5426e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2973, Task: 2, loss: 0.00009\n",
            "tensor(8.5587e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2973, Task: 3, loss: 0.00009\n",
            "tensor(8.5527e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2973, Task: 4, loss: 0.00009\n",
            "tensor(8.5809e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2973, Task: 5, loss: 0.00009\n",
            "tensor(2.2021e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2973, Task: 6, loss: 0.00002\n",
            "tensor(1.0285e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2973, Task: 7, loss: 0.00001\n",
            "tensor(1.0264e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2973, Task: 8, loss: 0.00001\n",
            "tensor(8.6213e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5690e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2974, Task: 0, loss: 0.00009\n",
            "tensor(8.5761e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2974, Task: 1, loss: 0.00009\n",
            "tensor(8.5420e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2974, Task: 2, loss: 0.00009\n",
            "tensor(8.5581e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2974, Task: 3, loss: 0.00009\n",
            "tensor(8.5520e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2974, Task: 4, loss: 0.00009\n",
            "tensor(8.5802e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2974, Task: 5, loss: 0.00009\n",
            "tensor(2.2022e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2974, Task: 6, loss: 0.00002\n",
            "tensor(1.0288e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2974, Task: 7, loss: 0.00001\n",
            "tensor(1.0267e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2974, Task: 8, loss: 0.00001\n",
            "tensor(8.6224e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5689e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2975, Task: 0, loss: 0.00009\n",
            "tensor(8.5755e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2975, Task: 1, loss: 0.00009\n",
            "tensor(8.5414e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2975, Task: 2, loss: 0.00009\n",
            "tensor(8.5575e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2975, Task: 3, loss: 0.00009\n",
            "tensor(8.5514e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2975, Task: 4, loss: 0.00009\n",
            "tensor(8.5796e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2975, Task: 5, loss: 0.00009\n",
            "tensor(2.2023e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2975, Task: 6, loss: 0.00002\n",
            "tensor(1.0291e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2975, Task: 7, loss: 0.00001\n",
            "tensor(1.0270e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2975, Task: 8, loss: 0.00001\n",
            "tensor(8.6234e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5687e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2976, Task: 0, loss: 0.00009\n",
            "tensor(8.5748e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2976, Task: 1, loss: 0.00009\n",
            "tensor(8.5408e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2976, Task: 2, loss: 0.00009\n",
            "tensor(8.5568e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2976, Task: 3, loss: 0.00009\n",
            "tensor(8.5508e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2976, Task: 4, loss: 0.00009\n",
            "tensor(8.5790e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2976, Task: 5, loss: 0.00009\n",
            "tensor(2.2024e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2976, Task: 6, loss: 0.00002\n",
            "tensor(1.0294e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2976, Task: 7, loss: 0.00001\n",
            "tensor(1.0273e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2976, Task: 8, loss: 0.00001\n",
            "tensor(8.6244e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5686e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2977, Task: 0, loss: 0.00009\n",
            "tensor(8.5742e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2977, Task: 1, loss: 0.00009\n",
            "tensor(8.5401e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2977, Task: 2, loss: 0.00009\n",
            "tensor(8.5562e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2977, Task: 3, loss: 0.00009\n",
            "tensor(8.5502e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2977, Task: 4, loss: 0.00009\n",
            "tensor(8.5784e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2977, Task: 5, loss: 0.00009\n",
            "tensor(2.2025e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2977, Task: 6, loss: 0.00002\n",
            "tensor(1.0296e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2977, Task: 7, loss: 0.00001\n",
            "tensor(1.0276e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2977, Task: 8, loss: 0.00001\n",
            "tensor(8.6254e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5684e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2978, Task: 0, loss: 0.00009\n",
            "tensor(8.5736e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2978, Task: 1, loss: 0.00009\n",
            "tensor(8.5395e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2978, Task: 2, loss: 0.00009\n",
            "tensor(8.5556e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2978, Task: 3, loss: 0.00009\n",
            "tensor(8.5495e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2978, Task: 4, loss: 0.00009\n",
            "tensor(8.5777e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2978, Task: 5, loss: 0.00009\n",
            "tensor(2.2026e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2978, Task: 6, loss: 0.00002\n",
            "tensor(1.0299e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2978, Task: 7, loss: 0.00001\n",
            "tensor(1.0279e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2978, Task: 8, loss: 0.00001\n",
            "tensor(8.6264e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5683e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2979, Task: 0, loss: 0.00009\n",
            "tensor(8.5730e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2979, Task: 1, loss: 0.00009\n",
            "tensor(8.5389e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2979, Task: 2, loss: 0.00009\n",
            "tensor(8.5550e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2979, Task: 3, loss: 0.00009\n",
            "tensor(8.5489e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2979, Task: 4, loss: 0.00009\n",
            "tensor(8.5771e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2979, Task: 5, loss: 0.00009\n",
            "tensor(2.2027e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2979, Task: 6, loss: 0.00002\n",
            "tensor(1.0302e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2979, Task: 7, loss: 0.00001\n",
            "tensor(1.0281e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2979, Task: 8, loss: 0.00001\n",
            "tensor(8.6275e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5681e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2980, Task: 0, loss: 0.00009\n",
            "tensor(8.5723e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2980, Task: 1, loss: 0.00009\n",
            "tensor(8.5383e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2980, Task: 2, loss: 0.00009\n",
            "tensor(8.5544e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2980, Task: 3, loss: 0.00009\n",
            "tensor(8.5483e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2980, Task: 4, loss: 0.00009\n",
            "tensor(8.5765e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2980, Task: 5, loss: 0.00009\n",
            "tensor(2.2028e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2980, Task: 6, loss: 0.00002\n",
            "tensor(1.0305e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2980, Task: 7, loss: 0.00001\n",
            "tensor(1.0284e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2980, Task: 8, loss: 0.00001\n",
            "tensor(8.6285e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5680e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2981, Task: 0, loss: 0.00009\n",
            "tensor(8.5717e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2981, Task: 1, loss: 0.00009\n",
            "tensor(8.5377e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2981, Task: 2, loss: 0.00009\n",
            "tensor(8.5537e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2981, Task: 3, loss: 0.00009\n",
            "tensor(8.5477e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2981, Task: 4, loss: 0.00009\n",
            "tensor(8.5759e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2981, Task: 5, loss: 0.00009\n",
            "tensor(2.2029e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2981, Task: 6, loss: 0.00002\n",
            "tensor(1.0307e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2981, Task: 7, loss: 0.00001\n",
            "tensor(1.0287e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2981, Task: 8, loss: 0.00001\n",
            "tensor(8.6295e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5679e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2982, Task: 0, loss: 0.00009\n",
            "tensor(8.5711e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2982, Task: 1, loss: 0.00009\n",
            "tensor(8.5370e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2982, Task: 2, loss: 0.00009\n",
            "tensor(8.5531e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2982, Task: 3, loss: 0.00009\n",
            "tensor(8.5471e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2982, Task: 4, loss: 0.00009\n",
            "tensor(8.5753e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2982, Task: 5, loss: 0.00009\n",
            "tensor(2.2030e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2982, Task: 6, loss: 0.00002\n",
            "tensor(1.0310e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2982, Task: 7, loss: 0.00001\n",
            "tensor(1.0290e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2982, Task: 8, loss: 0.00001\n",
            "tensor(8.6305e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5677e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2983, Task: 0, loss: 0.00009\n",
            "tensor(8.5705e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2983, Task: 1, loss: 0.00009\n",
            "tensor(8.5364e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2983, Task: 2, loss: 0.00009\n",
            "tensor(8.5525e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2983, Task: 3, loss: 0.00009\n",
            "tensor(8.5465e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2983, Task: 4, loss: 0.00009\n",
            "tensor(8.5746e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2983, Task: 5, loss: 0.00009\n",
            "tensor(2.2031e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2983, Task: 6, loss: 0.00002\n",
            "tensor(1.0313e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2983, Task: 7, loss: 0.00001\n",
            "tensor(1.0293e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2983, Task: 8, loss: 0.00001\n",
            "tensor(8.6315e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5676e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2984, Task: 0, loss: 0.00009\n",
            "tensor(8.5699e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2984, Task: 1, loss: 0.00009\n",
            "tensor(8.5358e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2984, Task: 2, loss: 0.00009\n",
            "tensor(8.5519e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2984, Task: 3, loss: 0.00009\n",
            "tensor(8.5458e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2984, Task: 4, loss: 0.00009\n",
            "tensor(8.5740e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2984, Task: 5, loss: 0.00009\n",
            "tensor(2.2032e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2984, Task: 6, loss: 0.00002\n",
            "tensor(1.0316e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2984, Task: 7, loss: 0.00001\n",
            "tensor(1.0296e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2984, Task: 8, loss: 0.00001\n",
            "tensor(8.6325e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5674e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2985, Task: 0, loss: 0.00009\n",
            "tensor(8.5693e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2985, Task: 1, loss: 0.00009\n",
            "tensor(8.5352e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2985, Task: 2, loss: 0.00009\n",
            "tensor(8.5513e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2985, Task: 3, loss: 0.00009\n",
            "tensor(8.5452e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2985, Task: 4, loss: 0.00009\n",
            "tensor(8.5734e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2985, Task: 5, loss: 0.00009\n",
            "tensor(2.2034e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2985, Task: 6, loss: 0.00002\n",
            "tensor(1.0318e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2985, Task: 7, loss: 0.00001\n",
            "tensor(1.0299e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2985, Task: 8, loss: 0.00001\n",
            "tensor(8.6335e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5673e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2986, Task: 0, loss: 0.00009\n",
            "tensor(8.5686e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2986, Task: 1, loss: 0.00009\n",
            "tensor(8.5346e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2986, Task: 2, loss: 0.00009\n",
            "tensor(8.5507e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2986, Task: 3, loss: 0.00009\n",
            "tensor(8.5446e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2986, Task: 4, loss: 0.00009\n",
            "tensor(8.5728e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2986, Task: 5, loss: 0.00009\n",
            "tensor(2.2035e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2986, Task: 6, loss: 0.00002\n",
            "tensor(1.0321e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2986, Task: 7, loss: 0.00001\n",
            "tensor(1.0302e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2986, Task: 8, loss: 0.00001\n",
            "tensor(8.6345e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5672e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2987, Task: 0, loss: 0.00009\n",
            "tensor(8.5680e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2987, Task: 1, loss: 0.00009\n",
            "tensor(8.5340e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2987, Task: 2, loss: 0.00009\n",
            "tensor(8.5500e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2987, Task: 3, loss: 0.00009\n",
            "tensor(8.5440e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2987, Task: 4, loss: 0.00009\n",
            "tensor(8.5722e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2987, Task: 5, loss: 0.00009\n",
            "tensor(2.2036e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2987, Task: 6, loss: 0.00002\n",
            "tensor(1.0324e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2987, Task: 7, loss: 0.00001\n",
            "tensor(1.0305e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2987, Task: 8, loss: 0.00001\n",
            "tensor(8.6355e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5670e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2988, Task: 0, loss: 0.00009\n",
            "tensor(8.5674e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2988, Task: 1, loss: 0.00009\n",
            "tensor(8.5334e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2988, Task: 2, loss: 0.00009\n",
            "tensor(8.5494e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2988, Task: 3, loss: 0.00009\n",
            "tensor(8.5434e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2988, Task: 4, loss: 0.00009\n",
            "tensor(8.5716e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2988, Task: 5, loss: 0.00009\n",
            "tensor(2.2037e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2988, Task: 6, loss: 0.00002\n",
            "tensor(1.0326e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2988, Task: 7, loss: 0.00001\n",
            "tensor(1.0308e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2988, Task: 8, loss: 0.00001\n",
            "tensor(8.6364e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5669e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2989, Task: 0, loss: 0.00009\n",
            "tensor(8.5668e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2989, Task: 1, loss: 0.00009\n",
            "tensor(8.5327e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2989, Task: 2, loss: 0.00009\n",
            "tensor(8.5488e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2989, Task: 3, loss: 0.00009\n",
            "tensor(8.5428e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2989, Task: 4, loss: 0.00009\n",
            "tensor(8.5710e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2989, Task: 5, loss: 0.00009\n",
            "tensor(2.2038e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2989, Task: 6, loss: 0.00002\n",
            "tensor(1.0329e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2989, Task: 7, loss: 0.00001\n",
            "tensor(1.0311e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2989, Task: 8, loss: 0.00001\n",
            "tensor(8.6374e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5667e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2990, Task: 0, loss: 0.00009\n",
            "tensor(8.5662e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2990, Task: 1, loss: 0.00009\n",
            "tensor(8.5321e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2990, Task: 2, loss: 0.00009\n",
            "tensor(8.5482e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2990, Task: 3, loss: 0.00009\n",
            "tensor(8.5422e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2990, Task: 4, loss: 0.00009\n",
            "tensor(8.5703e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2990, Task: 5, loss: 0.00009\n",
            "tensor(2.2039e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2990, Task: 6, loss: 0.00002\n",
            "tensor(1.0332e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2990, Task: 7, loss: 0.00001\n",
            "tensor(1.0314e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2990, Task: 8, loss: 0.00001\n",
            "tensor(8.6384e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5666e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2991, Task: 0, loss: 0.00009\n",
            "tensor(8.5656e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2991, Task: 1, loss: 0.00009\n",
            "tensor(8.5315e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2991, Task: 2, loss: 0.00009\n",
            "tensor(8.5476e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2991, Task: 3, loss: 0.00009\n",
            "tensor(8.5416e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2991, Task: 4, loss: 0.00009\n",
            "tensor(8.5697e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2991, Task: 5, loss: 0.00009\n",
            "tensor(2.2040e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2991, Task: 6, loss: 0.00002\n",
            "tensor(1.0334e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2991, Task: 7, loss: 0.00001\n",
            "tensor(1.0317e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2991, Task: 8, loss: 0.00001\n",
            "tensor(8.6394e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5664e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2992, Task: 0, loss: 0.00009\n",
            "tensor(8.5650e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2992, Task: 1, loss: 0.00009\n",
            "tensor(8.5309e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2992, Task: 2, loss: 0.00009\n",
            "tensor(8.5470e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2992, Task: 3, loss: 0.00009\n",
            "tensor(8.5409e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2992, Task: 4, loss: 0.00009\n",
            "tensor(8.5691e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2992, Task: 5, loss: 0.00009\n",
            "tensor(2.2041e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2992, Task: 6, loss: 0.00002\n",
            "tensor(1.0337e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2992, Task: 7, loss: 0.00001\n",
            "tensor(1.0320e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2992, Task: 8, loss: 0.00001\n",
            "tensor(8.6404e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5663e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2993, Task: 0, loss: 0.00009\n",
            "tensor(8.5644e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2993, Task: 1, loss: 0.00009\n",
            "tensor(8.5303e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2993, Task: 2, loss: 0.00009\n",
            "tensor(8.5464e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2993, Task: 3, loss: 0.00009\n",
            "tensor(8.5403e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2993, Task: 4, loss: 0.00009\n",
            "tensor(8.5685e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2993, Task: 5, loss: 0.00009\n",
            "tensor(2.2042e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2993, Task: 6, loss: 0.00002\n",
            "tensor(1.0340e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2993, Task: 7, loss: 0.00001\n",
            "tensor(1.0323e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2993, Task: 8, loss: 0.00001\n",
            "tensor(8.6413e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5662e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2994, Task: 0, loss: 0.00009\n",
            "tensor(8.5638e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2994, Task: 1, loss: 0.00009\n",
            "tensor(8.5297e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2994, Task: 2, loss: 0.00009\n",
            "tensor(8.5458e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2994, Task: 3, loss: 0.00009\n",
            "tensor(8.5397e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2994, Task: 4, loss: 0.00009\n",
            "tensor(8.5679e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2994, Task: 5, loss: 0.00009\n",
            "tensor(2.2043e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2994, Task: 6, loss: 0.00002\n",
            "tensor(1.0343e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2994, Task: 7, loss: 0.00001\n",
            "tensor(1.0325e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2994, Task: 8, loss: 0.00001\n",
            "tensor(8.6423e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5660e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2995, Task: 0, loss: 0.00009\n",
            "tensor(8.5632e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2995, Task: 1, loss: 0.00009\n",
            "tensor(8.5291e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2995, Task: 2, loss: 0.00009\n",
            "tensor(8.5452e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2995, Task: 3, loss: 0.00009\n",
            "tensor(8.5391e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2995, Task: 4, loss: 0.00009\n",
            "tensor(8.5673e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2995, Task: 5, loss: 0.00009\n",
            "tensor(2.2044e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2995, Task: 6, loss: 0.00002\n",
            "tensor(1.0345e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2995, Task: 7, loss: 0.00001\n",
            "tensor(1.0328e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2995, Task: 8, loss: 0.00001\n",
            "tensor(8.6433e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5659e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2996, Task: 0, loss: 0.00009\n",
            "tensor(8.5626e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2996, Task: 1, loss: 0.00009\n",
            "tensor(8.5285e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2996, Task: 2, loss: 0.00009\n",
            "tensor(8.5446e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2996, Task: 3, loss: 0.00009\n",
            "tensor(8.5385e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2996, Task: 4, loss: 0.00009\n",
            "tensor(8.5667e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2996, Task: 5, loss: 0.00009\n",
            "tensor(2.2045e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2996, Task: 6, loss: 0.00002\n",
            "tensor(1.0348e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2996, Task: 7, loss: 0.00001\n",
            "tensor(1.0331e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2996, Task: 8, loss: 0.00001\n",
            "tensor(8.6443e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5658e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2997, Task: 0, loss: 0.00009\n",
            "tensor(8.5620e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2997, Task: 1, loss: 0.00009\n",
            "tensor(8.5279e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2997, Task: 2, loss: 0.00009\n",
            "tensor(8.5440e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2997, Task: 3, loss: 0.00009\n",
            "tensor(8.5379e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2997, Task: 4, loss: 0.00009\n",
            "tensor(8.5661e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2997, Task: 5, loss: 0.00009\n",
            "tensor(2.2046e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2997, Task: 6, loss: 0.00002\n",
            "tensor(1.0351e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2997, Task: 7, loss: 0.00001\n",
            "tensor(1.0334e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2997, Task: 8, loss: 0.00001\n",
            "tensor(8.6452e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5656e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2998, Task: 0, loss: 0.00009\n",
            "tensor(8.5613e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2998, Task: 1, loss: 0.00009\n",
            "tensor(8.5273e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2998, Task: 2, loss: 0.00009\n",
            "tensor(8.5434e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2998, Task: 3, loss: 0.00009\n",
            "tensor(8.5373e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2998, Task: 4, loss: 0.00009\n",
            "tensor(8.5655e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2998, Task: 5, loss: 0.00009\n",
            "tensor(2.2047e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2998, Task: 6, loss: 0.00002\n",
            "tensor(1.0353e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2998, Task: 7, loss: 0.00001\n",
            "tensor(1.0337e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2998, Task: 8, loss: 0.00001\n",
            "tensor(8.6462e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5655e-05, grad_fn=<DivBackward0>)\n",
            "Epoch: 2999, Task: 0, loss: 0.00009\n",
            "tensor(8.5607e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2999, Task: 1, loss: 0.00009\n",
            "tensor(8.5267e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2999, Task: 2, loss: 0.00009\n",
            "tensor(8.5428e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2999, Task: 3, loss: 0.00009\n",
            "tensor(8.5367e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2999, Task: 4, loss: 0.00009\n",
            "tensor(8.5649e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2999, Task: 5, loss: 0.00009\n",
            "tensor(2.2048e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2999, Task: 6, loss: 0.00002\n",
            "tensor(1.0356e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2999, Task: 7, loss: 0.00001\n",
            "tensor(1.0340e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch: 2999, Task: 8, loss: 0.00001\n",
            "tensor(8.6471e-05, grad_fn=<MseLossBackward0>)\n",
            "tensor(5.5653e-05, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import learn2learn as l2l\n",
        "epochs = 3000\n",
        "learning_rate = 0.01\n",
        "meta_learning_rate = 0.005\n",
        "adaptation_steps = 1\n",
        "input_dim = 1\n",
        "hidden_dim = 2\n",
        "layer_dim = 1  # ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER\n",
        "output_dim = 1\n",
        "dropout = 0.2\n",
        "encoder = GRUModel(input_dim, hidden_dim, layer_dim, output_dim, dropout)\n",
        "output_layer = nn.Linear(1, 1)\n",
        "maml = l2l.algorithms.MAML(output_layer, lr=learning_rate, first_order=False)\n",
        "opt = optim.Adam(list(maml.parameters()) + list(encoder.parameters()), lr=meta_learning_rate)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "for iteration in range(epochs):\n",
        "    opt.zero_grad()\n",
        "    iteration_error = 0.0\n",
        "    for task in range(9):\n",
        "        learner = maml.clone()\n",
        "        x_spt = trainX[task]\n",
        "        y_spt = trainY[task]\n",
        "        x_qry = trainX[task+1]\n",
        "        y_qry = trainY[task+1]\n",
        "        # Fast adapt\n",
        "        for _ in range(adaptation_steps):\n",
        "            pred = learner(encoder(x_spt))\n",
        "            error = loss_fn(pred, y_spt)\n",
        "            learner.adapt(error)\n",
        "            print(\"Epoch: %d, Task: %d, loss: %1.5f\" % (iteration, task, error.item()))\n",
        "\n",
        "        pred = learner(encoder(x_qry))\n",
        "        evaluation_error = loss_fn(pred, y_qry)\n",
        "        print(evaluation_error)\n",
        "        iteration_error += evaluation_error\n",
        "    # Meta-update the model parameters\n",
        "    iteration_error /= 10\n",
        "    print(iteration_error)\n",
        "    iteration_error.backward()   \n",
        "    opt.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataX.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl3-VFFan7pt",
        "outputId": "5416b98a-fe3d-4182-eaa4-b9532f6387d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2995881, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "da"
      ],
      "metadata": {
        "id": "LbFukJRPoMqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#epoch2000\n",
        "learner.eval()\n",
        "train_predict = learner(encoder(dataX))\n",
        "data_predict = train_predict.data.numpy()\n",
        "dataY_plot = dataY.data.numpy()\n",
        "#data_predict=data_predict.reshape(1, -1)\n",
        "data_predict = sc.inverse_transform(data_predict)\n",
        "dataY_plot = sc.inverse_transform(dataY_plot)\n",
        "\n",
        "plt.axvline(x=train_size, c='r', linestyle='--')\n",
        "\n",
        "plt.plot(dataY_plot)\n",
        "plt.plot(data_predict)\n",
        "plt.suptitle('Time-Series Prediction')\n",
        "plt.show()\n",
        "import math\n",
        "trainScore = math.sqrt(mean_squared_error(dataY_plot, data_predict))\n",
        "print('Train Score: %.2f RMSE' % (trainScore))\n",
        "#testScore = math.sqrt(mean_squared_error(testY, test_predict))\n",
        "#print('Test Score: %.2f RMSE' % (testScore))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "1PbuUZgvperv",
        "outputId": "47c76864-a91a-40c8-8d9c-4ae763179a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Score: 0.01 RMSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#epoch3000\n",
        "from math import sqrt\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "print(\"mean_absolute_error:\",mean_absolute_error(dataY_plot, data_predict))\n",
        "\n",
        "print(\"mean_squared_error:\",mean_squared_error(dataY_plot, data_predict))\n",
        "\n",
        "print(\"rmse:\",sqrt(mean_squared_error(dataY_plot, data_predict)))\n",
        "\n",
        "print(\"r2 score:\",r2_score(dataY_plot, data_predict))\n",
        "print(\"mape_sk\", mean_absolute_percentage_error(dataY_plot, data_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RupIn8yuzAE0",
        "outputId": "0bceed1a-d4d7-46e0-e1de-66089ca9ac13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_absolute_error: 0.005499317\n",
            "mean_squared_error: 7.6931094e-05\n",
            "rmse: 0.008771037204619327\n",
            "r2 score: 0.7806747064422572\n",
            "mape_sk 319178370.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lLLmi3qQzx0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ro8WbpwbD0AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#epoch2000\n",
        "learner.eval()\n",
        "test_predict = learner(encoder(testX))\n",
        "test_predict = test_predict.data.numpy()\n",
        "testY_plot = testY.data.numpy()\n",
        "#data_predict=data_predict.reshape(1, -1)\n",
        "test_predict = sc.inverse_transform(test_predict)\n",
        "testY_plot = sc.inverse_transform(testY_plot)\n",
        "\n",
        "#plt.axvline(x=train_size, c='r', linestyle='--')\n",
        "\n",
        "plt.plot(testY_plot)\n",
        "plt.plot(test_predict)\n",
        "plt.suptitle('Time-Series Prediction')\n",
        "plt.show()\n",
        "import math\n",
        "testScore = math.sqrt(mean_squared_error(testY_plot, test_predict))\n",
        "print('Train Score: %.2f RMSE' % (testScore))\n",
        "#testScore = math.sqrt(mean_squared_error(testY, test_predict))\n",
        "#print('Test Score: %.2f RMSE' % (testScore))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "BUnzb0pCztiw",
        "outputId": "55e9169b-a256-4f17-fef5-79c373215e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Score: 0.01 RMSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#epoch2000\n",
        "from math import sqrt\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "print(\"mean_absolute_error:\",mean_absolute_error(testY_plot, test_predict))\n",
        "\n",
        "print(\"mean_squared_error:\",mean_squared_error(testY_plot, test_predict))\n",
        "\n",
        "print(\"rmse:\",sqrt(mean_squared_error(testY_plot, test_predict)))\n",
        "\n",
        "print(\"r2 score:\",r2_score(testY_plot, test_predict))\n",
        "print(\"mape_sk\", mean_absolute_percentage_error(testY_plot, test_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a02Q2TCz2Ar",
        "outputId": "c4790831-c946-430d-fdd8-dcbe3754ab2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_absolute_error: 0.0055458033\n",
            "mean_squared_error: 0.00010659892\n",
            "rmse: 0.010324675295427627\n",
            "r2 score: 0.8714369292896955\n",
            "mape_sk 1064026560.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(learner,\"/content/gdrive/My Drive/thesis/grulearner0421_10task+1_epoch2000_10_length=1batch=1.pkl\")\n",
        "joblib.dump(encoder,\"/content/gdrive/My Drive/thesis/gruencoder0421_10task+1_epoch2000_10_length=1batch=1.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDx0nJPMRXIS",
        "outputId": "ab1bcbcb-db35-45a3-feae-f9fd3fc02c03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/My Drive/thesis/gruencoder0421_10task+1_epoch2000_10_length=1batch=1.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Im0iORM3bvoJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "V1 MAMLGRU10task+1epoch2000_length=1_batch=1_0421",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
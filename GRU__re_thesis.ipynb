{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from google.colab import drive\n",
        "from array import array\n",
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "drive.mount('/content/gdrive') # 此處需要登入google帳號\n",
        "data = pd.read_csv(\"/content/gdrive/My Drive/thesis/thesisdataset/millan_average13_629_final.csv\")\n",
        "data.shape"
      ],
      "metadata": {
        "id": "7xWuYrDl8Ic2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = pd.read_csv(\"/content/gdrive/My Drive/thesis/thesisdataset/taiwan_average37_83_final.csv\")\n",
        "data2.shape"
      ],
      "metadata": {
        "id": "m_EI9olj8JsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data3 = pd.read_csv(\"/content/gdrive/My Drive/thesis/thesisdataset/finland_average_47_786_final.csv\")\n",
        "data3.shape"
      ],
      "metadata": {
        "id": "6Izd3MZW8K-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "3SP3GJuU8M5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-G6HNxymideM"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data)\n",
        "dataset = df.internet.values.astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIFXDSJn4OR_"
      },
      "outputs": [],
      "source": [
        "df2 = pd.DataFrame(data2)\n",
        "dataset2 = df2.load.values.astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = pd.DataFrame(data3)\n",
        "dataset3 = df3.Internet.values.astype(float)"
      ],
      "metadata": {
        "id": "gNfgwNtVdVgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "by9uRhPK4XYy"
      },
      "outputs": [],
      "source": [
        "dataset1000=np.append(dataset2, dataset3)\n",
        "dataset1000=np.append(dataset1000, dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1000.shape"
      ],
      "metadata": {
        "id": "87q6J0Dj8O4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1000=dataset1000.reshape(-1,1)\n",
        "dataset1000.shape"
      ],
      "metadata": {
        "id": "H0wRuC4T8Q1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e44j-Ux74Mgp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "def sliding_windows(data, seq_length):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-1):\n",
        "        _x = data[i:(i+seq_length)]\n",
        "        _y = data[i+seq_length]\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return np.array(x),np.array(y)\n",
        "\n",
        "sc = MinMaxScaler()\n",
        "dataset1000 = sc.fit_transform(dataset1000)\n",
        "\n",
        "seq_length = 1\n",
        "x, y = sliding_windows(dataset1000, seq_length)\n",
        "train_size = 1516090\n",
        "# test_size = 898761\n",
        "#train_size = int(len(y) * 0.7)\n",
        "test_size = len(y) - train_size\n",
        "\n",
        "dataX = Variable(torch.Tensor(np.array(x)))\n",
        "dataY = Variable(torch.Tensor(np.array(y)))\n",
        "\n",
        "trainX = Variable(torch.Tensor(np.array(x[0:train_size])))\n",
        "trainY = Variable(torch.Tensor(np.array(y[0:train_size])))\n",
        "\n",
        "testX = Variable(torch.Tensor(np.array(x[train_size:len(x)])))\n",
        "testY = Variable(torch.Tensor(np.array(y[train_size:len(y)])))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainX.shape)\n",
        "print(trainY.shape)\n",
        "print(testX.shape)\n",
        "print(testY.shape)"
      ],
      "metadata": {
        "id": "PEnfMwmn8VR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXz37vSL5m9E"
      },
      "outputs": [],
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
        "        super(GRUModel, self).__init__()\n",
        "\n",
        "        # Defining the number of layers and the nodes in each layer\n",
        "        self.layer_dim = layer_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # GRU layers\n",
        "        self.gru = nn.GRU(\n",
        "            input_dim, hidden_dim, layer_dim, batch_first=True\n",
        "        )\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initializing hidden state for first input with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
        "\n",
        "        # Forward propagation by passing in the input and hidden state into the model\n",
        "        out, _ = self.gru(x, h0.detach())\n",
        "\n",
        "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
        "        # so that it can fit into the fully connected layer\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "torch.manual_seed(24)\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "seed=24\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# Remove randomness (may be slower on Tesla GPUs) \n",
        "# https://pytorch.org/docs/stable/notes/randomness.html\n",
        "if seed == 24:\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "LJ-QXM4y8nZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "input_dim = 1\n",
        "hidden_dim = 2\n",
        "layer_dim = 1 \n",
        "output_dim = 1\n",
        "\n",
        "gru = GRUModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
        "\n",
        "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
        "optimizer = torch.optim.Adam(gru.parameters(), lr=learning_rate)\n",
        "#optimizer = torch.optim.SGD(lstm.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    outputs = gru(trainX)\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # obtain the loss function\n",
        "    loss = criterion(outputs, trainY)\n",
        "    \n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "    if epoch % 100 == 0:\n",
        "      print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
      ],
      "metadata": {
        "id": "gNq4BQ3u8pDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9\n",
        "gru.eval()\n",
        "test_predict = gru(testX)\n",
        "\n",
        "test_predict = test_predict.data.numpy()\n",
        "testY_plot = testY.data.numpy()\n",
        "\n",
        "test_predict = sc.inverse_transform(test_predict)\n",
        "testY_plot = sc.inverse_transform(testY_plot)\n",
        "\n",
        "#plt.axvline(x=train_size, c='r', linestyle='--')\n",
        "\n",
        "plt.plot(testY_plot,color='blue',label='True Value')\n",
        "plt.plot(test_predict,color='red',label='Predicted Value')\n",
        "plt.suptitle('GRU Internet Traffic Prediction')\n",
        "plt.show()\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "\n",
        "print(\"mean_absolute_error:\",mean_absolute_error(testY_plot, test_predict))\n",
        "\n",
        "print(\"mean_squared_error:\",mean_squared_error(testY_plot, test_predict))\n",
        "\n",
        "print(\"rmse:\",sqrt(mean_squared_error(testY_plot, test_predict)))\n",
        "\n",
        "print(\"r2 score:\",r2_score(testY_plot, test_predict))\n",
        "print(\"mape_sk\", mean_absolute_percentage_error(testY_plot, test_predict))"
      ],
      "metadata": {
        "id": "alIDCnIJ8r1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(gru,\"/content/gdrive/My Drive/re_thesis/re_thesis_test/model_test_2/gru.pkl\")\n",
        "joblib.dump(gru,\"/content/gdrive/My Drive/re_thesis/re_thesis_test/model_test_2/gru_0610.pkl\")"
      ],
      "metadata": {
        "id": "_SXP9HI79vHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VcNt6M7u-DSF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "GRU _re_thesis",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}